{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same as Exp6 but with MaskedRoBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from collections import defaultdict\n",
    "from scipy import spatial\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"InputTestSet-Reviews48_Ann.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>PID</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Sent</th>\n",
       "      <th>MComp</th>\n",
       "      <th>Cat</th>\n",
       "      <th>SubCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The authors propose to use k-DPP to select a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>This paper covers the related work nicely, wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The rest of the paper are also clearly written.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>However, I have some concerns about the propos...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>- It is not clear how to define the kernel, th...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID              PID     Dec  \\\n",
       "0    0  2019_SJf_XhCqKm  Reject   \n",
       "1    1  2019_SJf_XhCqKm  Reject   \n",
       "2    2  2019_SJf_XhCqKm  Reject   \n",
       "3    3  2019_SJf_XhCqKm  Reject   \n",
       "4    4  2019_SJf_XhCqKm  Reject   \n",
       "\n",
       "                                                Sent  MComp  Cat SubCat  \n",
       "0  The authors propose to use k-DPP to select a s...      0  NaN    NaN  \n",
       "1  This paper covers the related work nicely, wit...      0  NaN    NaN  \n",
       "2    The rest of the paper are also clearly written.      0  NaN    NaN  \n",
       "3  However, I have some concerns about the propos...      0  NaN    NaN  \n",
       "4  - It is not clear how to define the kernel, th...      0  NaN    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict = {}\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    pid = df.loc[i][\"PID\"]\n",
    "    if not pid in gt_dict:\n",
    "        gt_dict[pid] = {\"dec\": df.loc[i][\"Dec\"], \"mcomp\": set(), \"not_mcomp\": set()}\n",
    "    if df.loc[i][\"MComp\"] == 1:\n",
    "        gt_dict[pid][\"mcomp\"].add(df.loc[i][\"UID\"])\n",
    "    else:\n",
    "        gt_dict[pid][\"not_mcomp\"].add(df.loc[i][\"UID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accept': [48, 644], 'Reject': [69, 744]}\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {\"Accept\": [0, 0], \"Reject\": [0, 0]}\n",
    "\n",
    "for k, v in gt_dict.items():\n",
    "    #print(len(v[\"mcomp\"]), len(v[\"not_mcomp\"]), v[\"dec\"])\n",
    "    stats_dict[v[\"dec\"]][0] += len(v[\"mcomp\"])\n",
    "    stats_dict[v[\"dec\"]][1] += len(v[\"not_mcomp\"])\n",
    "    \n",
    "print(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSet length: 32\n",
      " ['2019_SJf_XhCqKm', '2017_Bk0MRI5lg', '2020_SyevYxHtDB', '2018_rJBiunlAW', '2020_rkltE0VKwH', '2018_Hki-ZlbA-', '2019_BJx0sjC5FX', '2020_r1e_FpNFDr', '2020_B1lsXREYvr', '2018_SkZxCk-0Z', '2019_rJzoujRct7', '2018_HkfXMz-Ab', '2017_BJ9fZNqle', '2019_SyxZJn05YX', '2017_B1ckMDqlg', '2017_HJ0NvFzxl', '2017_S1_pAu9xl', '2018_SyYYPdg0-', '2017_BJAA4wKxg', '2019_HyVxPsC9tm', '2019_HylTBhA5tQ', '2019_B1l08oAct7', '2018_H135uzZ0-', '2017_H1oyRlYgg', '2017_r1y1aawlg', '2020_r1eX1yrKwB', '2020_Byg79h4tvB', '2019_H1lFZnR5YX', '2020_BkeWw6VFwr', '2018_HyHmGyZCZ', '2018_HyUNwulC-', '2020_HkgsPhNYPS']\n"
     ]
    }
   ],
   "source": [
    "test_set = list(gt_dict.keys())\n",
    "print(\"TestSet length: %d\\n\"%len(test_set), test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_SJf_XhCqKm     {39, 17, 20, 27, 28, 30}\n",
      "2017_Bk0MRI5lg      {48, 57}\n",
      "2020_SyevYxHtDB     {76, 87}\n",
      "2018_rJBiunlAW      {108, 110, 112, 113, 124, 126}\n",
      "2020_rkltE0VKwH     {160, 155, 184, 159}\n",
      "2018_Hki-ZlbA-      {267, 235, 236, 271}\n",
      "2019_BJx0sjC5FX     {292, 287}\n",
      "2020_r1e_FpNFDr     {312, 322, 315, 308}\n",
      "2020_B1lsXREYvr     {376, 401}\n",
      "2018_SkZxCk-0Z      {449, 443, 445, 486}\n",
      "2019_rJzoujRct7     {518, 519}\n",
      "2018_HkfXMz-Ab      {573, 566}\n",
      "2017_BJ9fZNqle      {627, 623, 615}\n",
      "2019_SyxZJn05YX     {672, 673, 657, 669, 671}\n",
      "2017_B1ckMDqlg      {714, 707}\n",
      "2017_HJ0NvFzxl      {739}\n",
      "2017_S1_pAu9xl      {792, 809, 810, 806}\n",
      "2018_SyYYPdg0-      {834, 867, 868, 869, 870, 872, 873, 844, 830}\n",
      "2017_BJAA4wKxg      {884}\n",
      "2019_HyVxPsC9tm     {931, 933, 905, 909, 912, 913, 919, 926}\n",
      "2019_HylTBhA5tQ     {972, 950}\n",
      "2019_B1l08oAct7     {994, 996, 1064, 1004, 1007, 1044, 1047, 1048, 1055}\n",
      "2018_H135uzZ0-      {1072, 1079}\n",
      "2017_H1oyRlYgg      set()\n",
      "2017_r1y1aawlg      {1125, 1162, 1100, 1102, 1168}\n",
      "2020_r1eX1yrKwB     {1177, 1202, 1212}\n",
      "2020_Byg79h4tvB     {1243, 1268}\n",
      "2019_H1lFZnR5YX     {1281, 1316, 1284, 1318, 1289, 1331, 1333, 1279}\n",
      "2020_BkeWw6VFwr     {1347, 1373}\n",
      "2018_HyHmGyZCZ      {1406, 1421, 1390, 1426}\n",
      "2018_HyUNwulC-      {1451, 1452}\n",
      "2020_HkgsPhNYPS     {1504, 1464, 1497, 1500, 1502}\n"
     ]
    }
   ],
   "source": [
    "for k in test_set:\n",
    "    print('{:20}{}'.format(k, gt_dict[k][\"mcomp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_for_test = defaultdict(list)\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    pid = df.loc[i][\"PID\"]\n",
    "    test_sent_raw = str(df.loc[i][\"Sent\"])\n",
    "    \n",
    "    # Replace URLs with [URL]\n",
    "    test_sent_raw = re.sub(r'http[s]?://[a-zA-z\\.\\-/0-9~]*', \"[URL]\", test_sent_raw)\n",
    "    test_sent_raw = re.sub(r'papers.nips.cc/paper/[a-zA-z\\.\\-/0-9~]*', \"[URL]\", test_sent_raw)\n",
    "    test_sent_raw = re.sub(r'arxiv.org/[a-zA-z\\.\\-/0-9~]*', \"[URL]\", test_sent_raw)\n",
    "    \n",
    "    sents_for_test[pid].append((df.loc[i][\"UID\"], test_sent_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>PID</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Sent</th>\n",
       "      <th>MComp</th>\n",
       "      <th>Cat</th>\n",
       "      <th>SubCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>2020_ryen_CEFwr</td>\n",
       "      <td>Reject</td>\n",
       "      <td>It extends this approach by introducing an add...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>2018_H1LAqMbRW</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Experimentally, the results are rather weak co...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>2017_HyTqHL5xg</td>\n",
       "      <td>Accept</td>\n",
       "      <td>The experiments are interesting but I'm still ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146</td>\n",
       "      <td>2017_HyTqHL5xg</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Section 2.2 says they do the latter in the int...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>2017_ByToKu9ll</td>\n",
       "      <td>Reject</td>\n",
       "      <td>4)This paper proposed an improved version of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID              PID     Dec  \\\n",
       "0  243  2020_ryen_CEFwr  Reject   \n",
       "1  179   2018_H1LAqMbRW  Reject   \n",
       "2  157   2017_HyTqHL5xg  Accept   \n",
       "3  146   2017_HyTqHL5xg  Accept   \n",
       "4   90   2017_ByToKu9ll  Reject   \n",
       "\n",
       "                                                Sent  MComp   Cat SubCat  \n",
       "0  It extends this approach by introducing an add...      0  None   None  \n",
       "1  Experimentally, the results are rather weak co...      0  None   None  \n",
       "2  The experiments are interesting but I'm still ...      0  None   None  \n",
       "3  Section 2.2 says they do the latter in the int...      0  None   None  \n",
       "4  4)This paper proposed an improved version of t...      0  None   None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_excel(\"InputTrainSet-Reviews7_Ann.xlsx\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"MComp\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = {\"mcomp\": [], \"non_mcomp\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, df_train.shape[0]):\n",
    "    pid = df_train.loc[i][\"PID\"]\n",
    "    train_sent_raw = str(df_train.loc[i][\"Sent\"])\n",
    "    \n",
    "    type_comp = df_train.loc[i][\"MComp\"]\n",
    "    \n",
    "    if type_comp == 1:\n",
    "        train_sets[\"mcomp\"].append(train_sent_raw)\n",
    "    else:\n",
    "        train_sets[\"non_mcomp\"].append(train_sent_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 270)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sets[\"mcomp\"]), len(train_sets[\"non_mcomp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"entities_dict_smaller\", \"r\") as f:\n",
    "    entity_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Material', 'Method', 'Metric', 'Task'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(entity_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('convolutional neural networks', 'Method'),\n",
       " ('convnets', 'Method'),\n",
       " ('recognition', 'Task'),\n",
       " ('visual recognition tasks', 'Task'),\n",
       " ('age estimation', 'Task'),\n",
       " ('head pose estimation', 'Task'),\n",
       " ('multi - label classification', 'Task'),\n",
       " ('semantic segmentation', 'Task'),\n",
       " ('classification', 'Task'),\n",
       " ('deep convnets', 'Method'),\n",
       " ('dldl', 'Method'),\n",
       " ('feature learning', 'Task'),\n",
       " ('deep learning', 'Method'),\n",
       " ('image classification', 'Task'),\n",
       " ('deep learning methods', 'Method'),\n",
       " ('image classification tasks', 'Task'),\n",
       " ('human pose estimation', 'Task'),\n",
       " ('convnet', 'Method'),\n",
       " ('recognition tasks', 'Task'),\n",
       " ('ensemble', 'Method')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(entity_dict.items())[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784\n"
     ]
    }
   ],
   "source": [
    "entity_key_map = {}\n",
    "for i in entity_dict:\n",
    "    s = re.sub('[^0-9a-zA-Z,:;.?!\\- ]+', '', i)\n",
    "    while s.find(\"  \") > -1:\n",
    "        s = s.replace(\"  \", \" \")\n",
    "    if len(s) > 2:\n",
    "        cl = re.sub('[^0-9a-zA-Z ]+', '', i)\n",
    "        while cl.find(\"  \") > -1:\n",
    "            cl = cl.replace(\"  \", \" \")\n",
    "        entity_key_map[cl.strip()] = i\n",
    "print(len(entity_key_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "coun = 0\n",
    "for i in entity_dict:\n",
    "    if len(i) < 5:\n",
    "        coun +=1\n",
    "#         print(i)\n",
    "print(coun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('convolutional neural networks', 'convolutional neural networks'),\n",
       " ('convnets', 'convnets'),\n",
       " ('recognition', 'recognition'),\n",
       " ('visual recognition tasks', 'visual recognition tasks'),\n",
       " ('age estimation', 'age estimation')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(entity_key_map.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Method': 1191, 'Task': 289, 'Metric': 158, 'Material': 165})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(entity_dict.values())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(c)\n",
    "reverse_map = defaultdict(list)\n",
    "\n",
    "for k, v in entity_dict.items():\n",
    "    reverse_map[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in reverse_map[\"Task\"]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MNIST\" in entity_key_map, \"mnist\" in entity_key_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. RoBERTa trained on SciLit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy-transformers            0.6.2\n",
      "tokenizers                    0.7.0\n",
      "transformers                  2.9.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.7 list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./trained_lm/MaskedRoBERTa/\")\n",
    "model = AutoModel.from_pretrained(\"./trained_lm/MaskedRoBERTa/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_using_roberta(text):\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_entities(sentence, replace_with_dataset=True):\n",
    "    cleaned_sent = re.sub('[^0-9a-zA-Z,:;.?!\\- ]+', ' ', sentence)\n",
    "    while cleaned_sent.find(\"  \") > -1:\n",
    "        cleaned_sent = cleaned_sent.replace(\"  \", \" \")\n",
    "    \n",
    "    entity_key_map_keys = list(entity_key_map.keys()) # As we will be dunamically adding entries to this dict an dthat will throw an error.\n",
    "    entities_found = []\n",
    "    for i in entity_key_map_keys:\n",
    "        if cleaned_sent.find(\" \" + i + \" \") > -1:\n",
    "            entities_found.append(i)\n",
    "        elif cleaned_sent.lower().find(\" \" + i + \" \") > -1:\n",
    "            found_idx = cleaned_sent.lower().find(\" \" + i + \" \")\n",
    "            entity_dict[cleaned_sent[found_idx:found_idx+len(\" \" + i + \" \")]] = entity_dict[i]\n",
    "            entity_key_map[cleaned_sent[found_idx:found_idx+len(\" \" + i + \" \")]] = entity_key_map[i]\n",
    "    \n",
    "    entities_found.sort(key=lambda s: len(s))\n",
    "    len_sorted_entities = entities_found.copy()\n",
    "    \n",
    "    subset_entities = []\n",
    "    # Remove subset entities (eg: Among cnn and 3-layer-cnn, prefer the latter)\n",
    "    for fe in len_sorted_entities:\n",
    "        for other_ent in len_sorted_entities:\n",
    "            if fe != other_ent and other_ent.find(fe) > -1:\n",
    "                subset_entities.append(fe)\n",
    "                break\n",
    "    for se in subset_entities:\n",
    "        len_sorted_entities.remove(se)\n",
    "    for maxents in len_sorted_entities:\n",
    "        mask_name = \" \" + entity_dict[entity_key_map[i]].lower() + \" \"\n",
    "        if replace_with_dataset:\n",
    "            if mask_name == \" material \":\n",
    "                mask_name = \" dataset \"\n",
    "        cleaned_sent = cleaned_sent.replace(\" \" + maxents + \" \", mask_name)\n",
    "    words_cleaned = nltk.word_tokenize(cleaned_sent)\n",
    "    dups_removed = [v for i, v in enumerate(words_cleaned) if i == 0 or v != words_cleaned[i-1]]\n",
    "    new_dup_removed_sent = \" \".join(dups_removed)\n",
    "    return new_dup_removed_sent.strip()\n",
    "\n",
    "#     #print(cleaned_sent)\n",
    "#     for i in entity_key_map:\n",
    "#         if cleaned_sent.find(\" \" + i + \" \") > -1:\n",
    "#             #print(\"Substituting ent: {} with mask: {}\".format(i, entity_dict[entity_key_map[i]].lower()))\n",
    "#             cleaned_sent = cleaned_sent.replace(i, entity_dict[entity_key_map[i]].lower())\n",
    "#     return cleaned_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "sp_toks = [\"result\", \"method\", \"task\", \"dataset\", \"metric\", \"baseline\", \"fair\", \"unfair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks_using_spacy_dp(conssentence, replace_with_dataset=True):\n",
    "    \n",
    "    conssentence = mask_entities(conssentence, replace_with_dataset)\n",
    "#     print(conssentence)\n",
    "    doc = nlp(conssentence)\n",
    "    verb_subtree = []\n",
    "\n",
    "    for s in doc.sents:\n",
    "#         find_special_tokens = {\"compar\": [], \"result\": [], \"method\": [], \"technique\": [], \"task\": [], \"dataset\": [], \"material\": [], \"metric\": []}\n",
    "        find_special_tokens = {\"compar\": [], \"result\": [], \"method\": [], \"baseline\": [], \"task\": [], \n",
    "                               \"dataset\": [],  \"metric\": [], \"unfair\": [], \"fair\": []}\n",
    "\n",
    "        for tok in s:\n",
    "\n",
    "            if tok.text.lower().startswith(\"compar\"):\n",
    "                find_special_tokens[\"compar\"].append(tok)\n",
    "            else:\n",
    "                for k in sp_toks:\n",
    "                    if tok.text.lower().startswith(k):\n",
    "                        find_special_tokens[k].append(tok)\n",
    "                        break\n",
    "\n",
    "        verb_tokens = []\n",
    "        if find_special_tokens[\"compar\"]:\n",
    "            for t in find_special_tokens[\"compar\"]:\n",
    "#                     verb_subtree.append(t.subtree)\n",
    "                if t == s.root:\n",
    "                    simplified_sent = \"\"\n",
    "                    for chh in t.lefts:\n",
    "                        simplified_sent = simplified_sent + \" \" + chh.text\n",
    "                    simplified_sent = simplified_sent + \" \" + t.text\n",
    "                    for chh in t.rights:\n",
    "                        simplified_sent = simplified_sent + \" \" + chh.text\n",
    "#                         print(\"SIMP: \", simplified_sent)\n",
    "                    verb_subtree.append(simplified_sent)\n",
    "                else:\n",
    "                    verb_subtree.append(t.subtree)\n",
    "        else:\n",
    "            for k in sp_toks:\n",
    "                for i in find_special_tokens[k]:\n",
    "                    local_vt = []\n",
    "                    for j in i.ancestors:\n",
    "                        if j.pos_ == \"NOUN\":\n",
    "                            local_vt.append(j)\n",
    "                    if not local_vt:\n",
    "                        for j in i.ancestors:\n",
    "                            if j.pos_ == \"VERB\":\n",
    "                                local_vt.append(j)\n",
    "                    verb_tokens = verb_tokens + local_vt\n",
    "\n",
    "\n",
    "            for i in verb_tokens:\n",
    "                verb_subtree.append(i.subtree)\n",
    "\n",
    "    eecc = []\n",
    "    for i in verb_subtree:\n",
    "        if type(i) == str:\n",
    "            eecc.append(i)\n",
    "        else:\n",
    "            local_chunk = \"\"\n",
    "            for lcaltok in i:\n",
    "                local_chunk = local_chunk + \" \" + lcaltok.text\n",
    "            eecc.append(local_chunk)\n",
    "#     if not eecc:\n",
    "#         print(conssentence)\n",
    "    return list(set(eecc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing vectors of the initial training pool of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool_roberta_vecs = {\"mcomp\": [], \"non_mcomp\": []}\n",
    "single_train_pool_roberta_vecs = {\"mcomp\": [], \"non_mcomp\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_sets[\"mcomp\"]:\n",
    "    mcomp_chunks_from_sent = extract_chunks_using_spacy_dp(i)\n",
    "    if mcomp_chunks_from_sent:\n",
    "        final_chunks = mcomp_chunks_from_sent\n",
    "    else:\n",
    "        final_chunks = [i]\n",
    "    \n",
    "    for single_chunk in final_chunks:\n",
    "        vec = embed_text_using_roberta(single_chunk.strip()).mean(1).detach().numpy()\n",
    "        train_pool_roberta_vecs[\"mcomp\"].append(vec/norm(vec))\n",
    "    \n",
    "    collated_chunk = \" \".join(final_chunks)\n",
    "    vec = embed_text_using_roberta(collated_chunk.strip()).mean(1).detach().numpy()\n",
    "    single_train_pool_roberta_vecs[\"mcomp\"].append(vec/norm(vec))\n",
    "\n",
    "\n",
    "for i in train_sets[\"non_mcomp\"]:\n",
    "    mcomp_chunks_from_sent = extract_chunks_using_spacy_dp(i)\n",
    "    if mcomp_chunks_from_sent:\n",
    "        final_chunks = mcomp_chunks_from_sent\n",
    "    else:\n",
    "        final_chunks = [i]\n",
    "    \n",
    "    for single_chunk in final_chunks:\n",
    "        vec = embed_text_using_roberta(single_chunk.strip()).mean(1).detach().numpy()\n",
    "        train_pool_roberta_vecs[\"non_mcomp\"].append(vec/norm(vec))\n",
    "    \n",
    "    collated_chunk = \" \".join(final_chunks)\n",
    "    vec = embed_text_using_roberta(collated_chunk.strip()).mean(1).detach().numpy()\n",
    "    single_train_pool_roberta_vecs[\"non_mcomp\"].append(vec/norm(vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_vectors = defaultdict(dict)\n",
    "skip_uids = []\n",
    "\n",
    "for pid in gt_dict:\n",
    "    roberta_vectors[pid] = {}\n",
    "    \n",
    "    for mcs in gt_dict[pid][\"mcomp\"]:\n",
    "        try:\n",
    "            mcomp_chunks_from_sent = extract_chunks_using_spacy_dp(df.loc[mcs][\"Sent\"])\n",
    "            if mcomp_chunks_from_sent:\n",
    "                final_chunks = mcomp_chunks_from_sent\n",
    "            else:\n",
    "                final_chunks = [df.loc[mcs][\"Sent\"]]\n",
    "            \n",
    "            roberta_vectors[pid][mcs] = []\n",
    "            for single_chunk in final_chunks:\n",
    "                vec = embed_text_using_roberta(single_chunk.strip()).mean(1).detach().numpy()\n",
    "                roberta_vectors[pid][mcs].append(vec / norm(vec))\n",
    "        except Exception as ex:\n",
    "            print(pid, mcs, df.loc[mcs][\"Sent\"])\n",
    "            skip_uids.append(mcs)\n",
    "    \n",
    "    for mcs in gt_dict[pid][\"not_mcomp\"]:\n",
    "        try:\n",
    "            mcomp_chunks_from_sent = extract_chunks_using_spacy_dp(df.loc[mcs][\"Sent\"])\n",
    "            if mcomp_chunks_from_sent:\n",
    "                final_chunks = mcomp_chunks_from_sent\n",
    "            else:\n",
    "                final_chunks = [df.loc[mcs][\"Sent\"]]\n",
    "            \n",
    "            roberta_vectors[pid][mcs] = []\n",
    "            for single_chunk in final_chunks:\n",
    "                vec = embed_text_using_roberta(single_chunk.strip()).mean(1).detach().numpy()\n",
    "                roberta_vectors[pid][mcs].append(vec / norm(vec))\n",
    "        except Exception as ex:\n",
    "            print(pid, mcs, df.loc[mcs][\"Sent\"])\n",
    "            skip_uids.append(mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcomp_sentences = {}\n",
    "not_mcomp_sentences = {}\n",
    "\n",
    "for pid in gt_dict:\n",
    "    for mcs in gt_dict[pid][\"mcomp\"]:\n",
    "        if not mcs in skip_uids:\n",
    "            mcomp_sentences[mcs] = pid\n",
    "    for mcs in gt_dict[pid][\"not_mcomp\"]:\n",
    "        if not mcs in skip_uids:\n",
    "            not_mcomp_sentences[mcs] = pid\n",
    "print(len(mcomp_sentences), len(not_mcomp_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sim_with_mcomp = defaultdict(dict)\n",
    "mean_sim_with_not_mcomp = defaultdict(dict)\n",
    "max_sim_with_mcomp = defaultdict(dict)\n",
    "max_sim_with_not_mcomp = defaultdict(dict)\n",
    "\n",
    "mean_at_k = [\"1\", \"3\", \"5\", \"7\", \"10\", \"26\"]\n",
    "\n",
    "\n",
    "for sid in mcomp_sentences:\n",
    "    \n",
    "    # 1. With other training set mcomp sentences\n",
    "    temp_list = []    \n",
    "    for init_train_vec in train_pool_roberta_vecs[\"mcomp\"]:\n",
    "        for cvec2 in roberta_vectors[mcomp_sentences[sid]][sid]:\n",
    "            temp_list.append(np.inner(init_train_vec, cvec2)[0][0])\n",
    "        \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    mean_sim_with_mcomp[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    max_sim_with_mcomp[sid][\"max\"] = max(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        mean_sim_with_mcomp[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "#         max_sim_with_mcomp[sid][\"max_{}\".format(vv)] = max(sorted_temp_list[0:int(vv)])\n",
    "    \n",
    "    \n",
    "    # 2. With other training set non_mcomp sentences\n",
    "    temp_list = []    \n",
    "    for init_train_vec in train_pool_roberta_vecs[\"non_mcomp\"]:\n",
    "        for cvec2 in roberta_vectors[mcomp_sentences[sid]][sid]:\n",
    "            temp_list.append(np.inner(init_train_vec, cvec2)[0][0])\n",
    "        \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    mean_sim_with_not_mcomp[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    max_sim_with_not_mcomp[sid][\"max\"] = max(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        mean_sim_with_not_mcomp[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "#         max_sim_with_not_mcomp[sid][\"max_{}\".format(vv)] = max(sorted_temp_list[0:int(vv)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for sid in not_mcomp_sentences:\n",
    "    \n",
    "    # 1. With other training set mcomp sentences\n",
    "    temp_list = []    \n",
    "    for init_train_vec in train_pool_roberta_vecs[\"mcomp\"]:\n",
    "        for cvec2 in roberta_vectors[not_mcomp_sentences[sid]][sid]:\n",
    "            temp_list.append(np.inner(init_train_vec, cvec2)[0][0])\n",
    "        \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    mean_sim_with_mcomp[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    max_sim_with_mcomp[sid][\"max\"] = max(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        mean_sim_with_mcomp[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "#         max_sim_with_mcomp[sid][\"max_{}\".format(vv)] = max(sorted_temp_list[0:int(vv)])\n",
    "    \n",
    "    \n",
    "    # 2. With other training set non_mcomp sentences\n",
    "    temp_list = []    \n",
    "    for init_train_vec in train_pool_roberta_vecs[\"non_mcomp\"]:\n",
    "        for cvec2 in roberta_vectors[not_mcomp_sentences[sid]][sid]:\n",
    "            temp_list.append(np.inner(init_train_vec, cvec2)[0][0])\n",
    "        \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    mean_sim_with_not_mcomp[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    max_sim_with_not_mcomp[sid][\"max\"] = max(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        mean_sim_with_not_mcomp[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "#         max_sim_with_not_mcomp[sid][\"max_{}\".format(vv)] = max(sorted_temp_list[0:int(vv)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(sent_sim_dict, k=10, sim_type=\"max\", mean_at=1):\n",
    "    \"\"\"mean_at can take values: 1, 3, 5, 7, 10, 26\"\"\"\n",
    "    \n",
    "    if sim_type == \"max\":\n",
    "        sorted_sims = sorted(sent_sim_dict.items(), key=lambda x: x[1][\"max\"], reverse=True)\n",
    "        top_k_sorted_sims = sorted_sims[0:k]\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for i in top_k_sorted_sims:\n",
    "            if df.loc[i[0]][\"MComp\"] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        return tp/(tp+fp)\n",
    "            \n",
    "    elif sim_type == \"mean\":\n",
    "        sorted_sims = sorted(sent_sim_dict.items(), key=lambda x: x[1][\"mean_\"+str(mean_at)], reverse=True)\n",
    "        top_k_sorted_sims = sorted_sims[0:k]\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for i in top_k_sorted_sims:\n",
    "            if df.loc[i[0]][\"MComp\"] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        return tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(sent_sim_dict, k=10, sim_type=\"max\", mean_at=1):\n",
    "    if sim_type == \"max\":\n",
    "        sorted_sims = sorted(sent_sim_dict.items(), key=lambda x: x[1][\"max\"], reverse=True)\n",
    "        top_k_sorted_sims = sorted_sims[0:k]\n",
    "        tp = 0\n",
    "        for i in top_k_sorted_sims:\n",
    "            if df.loc[i[0]][\"MComp\"] == 1:\n",
    "                tp += 1\n",
    "        return tp/min(k, 117)\n",
    "            \n",
    "    elif sim_type == \"mean\":\n",
    "        sorted_sims = sorted(sent_sim_dict.items(), key=lambda x: x[1][\"mean_\"+str(mean_at)], reverse=True)\n",
    "        top_k_sorted_sims = sorted_sims[0:k]\n",
    "        tp = 0\n",
    "        for i in top_k_sorted_sims:\n",
    "            if df.loc[i[0]][\"MComp\"] == 1:\n",
    "                tp += 1\n",
    "        return tp/min(k, 117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on max similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P and R based on max similarity with initial pool of \n",
      "meaningful sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20   </td><td style=\"text-align: right;\">50   </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.9</td><td style=\"text-align: right;\"> 0.75</td><td style=\"text-align: right;\"> 0.48</td><td style=\"text-align: right;\">  0.35</td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.28</td><td style=\"text-align: right;\">  0.26</td><td style=\"text-align: right;\">  0.21</td><td style=\"text-align: right;\">  0.17</td><td style=\"text-align: right;\">  0.15</td><td style=\"text-align: right;\">  0.14</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td><td style=\"text-align: right;\">700   </td><td style=\"text-align: right;\">800   </td><td style=\"text-align: right;\">900   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1200   </td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.36</td><td style=\"text-align: right;\">  0.44</td><td style=\"text-align: right;\">  0.53</td><td style=\"text-align: right;\">  0.58</td><td style=\"text-align: right;\">  0.63</td><td style=\"text-align: right;\">  0.69</td><td style=\"text-align: right;\">  0.76</td><td style=\"text-align: right;\">  0.82</td><td style=\"text-align: right;\">  0.86</td><td style=\"text-align: right;\">   0.91</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"P and R based on max similarity with initial pool of \\nmeaningful sentences:\")\n",
    "\n",
    "patk = [1, 10, 20, 50, 100, 117, 150, 200, 300, 400, 500, 600]\n",
    "res_table = [[\"Precision at:\"] + patk, [\"Val\"]]\n",
    "\n",
    "for k in patk:\n",
    "    v1 = precision_at_k(max_sim_with_mcomp, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1, 2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "\n",
    "\n",
    "\n",
    "ratk = [117, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1388]\n",
    "res_table = [[\"Recall at:\"] + ratk, [\"Val\"]]\n",
    "\n",
    "for k in ratk:\n",
    "    v1 = recall_at_k(max_sim_with_mcomp, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1,2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on mean similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P and R based on avg similarity with initial pool of \n",
      "meaningful sentences:\n",
      "\n",
      "\n",
      "Avg of top 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20   </td><td style=\"text-align: right;\">50   </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.9</td><td style=\"text-align: right;\"> 0.75</td><td style=\"text-align: right;\"> 0.48</td><td style=\"text-align: right;\">  0.35</td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.28</td><td style=\"text-align: right;\">  0.26</td><td style=\"text-align: right;\">  0.21</td><td style=\"text-align: right;\">  0.17</td><td style=\"text-align: right;\">  0.15</td><td style=\"text-align: right;\">  0.14</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td><td style=\"text-align: right;\">700   </td><td style=\"text-align: right;\">800   </td><td style=\"text-align: right;\">900   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1200   </td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.36</td><td style=\"text-align: right;\">  0.44</td><td style=\"text-align: right;\">  0.53</td><td style=\"text-align: right;\">  0.58</td><td style=\"text-align: right;\">  0.63</td><td style=\"text-align: right;\">  0.69</td><td style=\"text-align: right;\">  0.76</td><td style=\"text-align: right;\">  0.82</td><td style=\"text-align: right;\">  0.86</td><td style=\"text-align: right;\">   0.91</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Avg of top 5:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20  </td><td style=\"text-align: right;\">50  </td><td style=\"text-align: right;\">100  </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.8</td><td style=\"text-align: right;\"> 0.7</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">  0.4</td><td style=\"text-align: right;\">  0.38</td><td style=\"text-align: right;\">  0.33</td><td style=\"text-align: right;\">  0.27</td><td style=\"text-align: right;\">  0.22</td><td style=\"text-align: right;\">  0.18</td><td style=\"text-align: right;\">  0.15</td><td style=\"text-align: right;\">  0.14</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600  </td><td style=\"text-align: right;\">700   </td><td style=\"text-align: right;\">800   </td><td style=\"text-align: right;\">900   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1200   </td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.38</td><td style=\"text-align: right;\">  0.42</td><td style=\"text-align: right;\">  0.46</td><td style=\"text-align: right;\">  0.56</td><td style=\"text-align: right;\">  0.61</td><td style=\"text-align: right;\">  0.66</td><td style=\"text-align: right;\">  0.7</td><td style=\"text-align: right;\">  0.74</td><td style=\"text-align: right;\">  0.82</td><td style=\"text-align: right;\">  0.85</td><td style=\"text-align: right;\">   0.91</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Avg of top 10:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20   </td><td style=\"text-align: right;\">50   </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.4</td><td style=\"text-align: right;\"> 0.45</td><td style=\"text-align: right;\"> 0.46</td><td style=\"text-align: right;\">  0.39</td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.32</td><td style=\"text-align: right;\">  0.28</td><td style=\"text-align: right;\">  0.24</td><td style=\"text-align: right;\">  0.19</td><td style=\"text-align: right;\">  0.16</td><td style=\"text-align: right;\">  0.14</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td><td style=\"text-align: right;\">700   </td><td style=\"text-align: right;\">800  </td><td style=\"text-align: right;\">900   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1200   </td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.41</td><td style=\"text-align: right;\">  0.49</td><td style=\"text-align: right;\">  0.62</td><td style=\"text-align: right;\">  0.65</td><td style=\"text-align: right;\">  0.67</td><td style=\"text-align: right;\">  0.71</td><td style=\"text-align: right;\">  0.75</td><td style=\"text-align: right;\">  0.8</td><td style=\"text-align: right;\">  0.88</td><td style=\"text-align: right;\">   0.94</td><td style=\"text-align: right;\">   0.98</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Avg of top 26:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20  </td><td style=\"text-align: right;\">50  </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150  </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400  </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.1</td><td style=\"text-align: right;\"> 0.2</td><td style=\"text-align: right;\"> 0.2</td><td style=\"text-align: right;\">  0.25</td><td style=\"text-align: right;\">  0.28</td><td style=\"text-align: right;\">  0.3</td><td style=\"text-align: right;\">  0.28</td><td style=\"text-align: right;\">  0.23</td><td style=\"text-align: right;\">  0.2</td><td style=\"text-align: right;\">  0.17</td><td style=\"text-align: right;\">  0.16</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600  </td><td style=\"text-align: right;\">700   </td><td style=\"text-align: right;\">800   </td><td style=\"text-align: right;\">900   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1200   </td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.28</td><td style=\"text-align: right;\">  0.38</td><td style=\"text-align: right;\">  0.49</td><td style=\"text-align: right;\">  0.58</td><td style=\"text-align: right;\">  0.69</td><td style=\"text-align: right;\">  0.74</td><td style=\"text-align: right;\">  0.8</td><td style=\"text-align: right;\">  0.84</td><td style=\"text-align: right;\">  0.88</td><td style=\"text-align: right;\">  0.92</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">   0.98</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"P and R based on avg similarity with initial pool of \\nmeaningful sentences:\\n\\n\")\n",
    "\n",
    "\n",
    "mean_at_j = [1, 5, 10, 26]\n",
    "\n",
    "for jjj in mean_at_j:\n",
    "    print(\"Avg of top {}:\".format(jjj))\n",
    "\n",
    "    patk = [1, 10, 20, 50, 100, 117, 150, 200, 300, 400, 500, 600]\n",
    "    res_table = [[\"Precision at:\"] + patk, [\"Val\"]]\n",
    "\n",
    "    for k in patk:\n",
    "        v1 = precision_at_k(mean_sim_with_mcomp, k, sim_type=\"mean\", mean_at=jjj) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "        res_table[1].append(round(v1, 2))\n",
    "\n",
    "    display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "\n",
    "\n",
    "\n",
    "    ratk = [117, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1388]\n",
    "    res_table = [[\"Recall at:\"] + ratk, [\"Val\"]]\n",
    "\n",
    "    for k in ratk:\n",
    "        v1 = recall_at_k(mean_sim_with_mcomp, k, sim_type=\"mean\", mean_at=jjj) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "        res_table[1].append(round(v1,2))\n",
    "\n",
    "    display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIff of max similarity of meaningful and non-meaningful sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_max = {}\n",
    "preserve_non_negative_max = {}\n",
    "\n",
    "for x in max_sim_with_mcomp:\n",
    "    diff_max_sim_for_x = max_sim_with_mcomp[x][\"max\"] - max_sim_with_not_mcomp[x][\"max\"]\n",
    "    diff_max[x] = {\"max\": diff_max_sim_for_x}\n",
    "    \n",
    "    if diff_max_sim_for_x > 0:\n",
    "        preserve_non_negative_max[x] = {\"max\": max_sim_with_mcomp[x][\"max\"]}\n",
    "    else:\n",
    "        preserve_non_negative_max[x] = {\"max\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P and R based on diff of max sim with initial pool of \n",
      " meaningful & non meaningful sents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20  </td><td style=\"text-align: right;\">50   </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200  </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.6</td><td style=\"text-align: right;\"> 0.6</td><td style=\"text-align: right;\"> 0.54</td><td style=\"text-align: right;\">  0.39</td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.3</td><td style=\"text-align: right;\">  0.25</td><td style=\"text-align: right;\">  0.21</td><td style=\"text-align: right;\">  0.18</td><td style=\"text-align: right;\">  0.16</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600   </td><td style=\"text-align: right;\">700   </td><td style=\"text-align: right;\">800   </td><td style=\"text-align: right;\">900   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1200   </td><td style=\"text-align: right;\">1388   </td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.44</td><td style=\"text-align: right;\">  0.51</td><td style=\"text-align: right;\">  0.64</td><td style=\"text-align: right;\">  0.72</td><td style=\"text-align: right;\">  0.75</td><td style=\"text-align: right;\">  0.82</td><td style=\"text-align: right;\">  0.82</td><td style=\"text-align: right;\">  0.85</td><td style=\"text-align: right;\">  0.89</td><td style=\"text-align: right;\">   0.89</td><td style=\"text-align: right;\">   0.93</td><td style=\"text-align: right;\">   0.97</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"P and R based on diff of max sim with initial pool of \\n meaningful & non meaningful sents:\")\n",
    "\n",
    "patk = [1, 10, 20, 50, 100, 117, 150, 200, 300, 400, 500, 600]\n",
    "res_table = [[\"Precision at:\"] + patk, [\"Val\"]]\n",
    "\n",
    "for k in patk:\n",
    "    v1 = precision_at_k(diff_max, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1, 2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "\n",
    "\n",
    "\n",
    "ratk = [117, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1388]\n",
    "res_table = [[\"Recall at:\"] + ratk, [\"Val\"]]\n",
    "\n",
    "for k in ratk:\n",
    "    v1 = recall_at_k(diff_max, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1,2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P and R based on preserving non-neg max sim with initial pool of \n",
      " meaningful & non meaningful sents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20  </td><td style=\"text-align: right;\">50  </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600  </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.9</td><td style=\"text-align: right;\"> 0.7</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">  0.41</td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.48</td><td style=\"text-align: right;\">  0.39</td><td style=\"text-align: right;\">  0.29</td><td style=\"text-align: right;\">  0.23</td><td style=\"text-align: right;\">  0.2</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300</td><td style=\"text-align: right;\">400</td><td style=\"text-align: right;\">500</td><td style=\"text-align: right;\">600</td><td style=\"text-align: right;\">700</td><td style=\"text-align: right;\">800</td><td style=\"text-align: right;\">900</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">1200</td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.44</td><td style=\"text-align: right;\">  0.83</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"P and R based on preserving non-neg max sim with initial pool of \\n meaningful & non meaningful sents:\")\n",
    "\n",
    "patk = [1, 10, 20, 50, 100, 117, 150, 200, 300, 400, 500, 600]\n",
    "res_table = [[\"Precision at:\"] + patk, [\"Val\"]]\n",
    "\n",
    "for k in patk:\n",
    "    v1 = precision_at_k(preserve_non_negative_max, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1, 2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "\n",
    "\n",
    "\n",
    "ratk = [117, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1388]\n",
    "res_table = [[\"Recall at:\"] + ratk, [\"Val\"]]\n",
    "\n",
    "for k in ratk:\n",
    "    v1 = recall_at_k(preserve_non_negative_max, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1,2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P and R based on preserving non-neg max sim with initial pool of \n",
      " meaningful & non meaningful sents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Precision at:</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">10  </td><td style=\"text-align: right;\">20  </td><td style=\"text-align: right;\">50  </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300   </td><td style=\"text-align: right;\">400   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">600  </td></tr>\n",
       "<tr><td>Val          </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 0.9</td><td style=\"text-align: right;\"> 0.7</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">  0.41</td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.34</td><td style=\"text-align: right;\">  0.48</td><td style=\"text-align: right;\">  0.39</td><td style=\"text-align: right;\">  0.29</td><td style=\"text-align: right;\">  0.23</td><td style=\"text-align: right;\">  0.2</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Recall at:</td><td style=\"text-align: right;\">117   </td><td style=\"text-align: right;\">150   </td><td style=\"text-align: right;\">200   </td><td style=\"text-align: right;\">300</td><td style=\"text-align: right;\">400</td><td style=\"text-align: right;\">500</td><td style=\"text-align: right;\">600</td><td style=\"text-align: right;\">700</td><td style=\"text-align: right;\">800</td><td style=\"text-align: right;\">900</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">1200</td><td style=\"text-align: right;\">1388</td></tr>\n",
       "<tr><td>Val       </td><td style=\"text-align: right;\">  0.37</td><td style=\"text-align: right;\">  0.44</td><td style=\"text-align: right;\">  0.83</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"P and R based on preserving non-neg max sim with initial pool of \\n meaningful & non meaningful sents:\")\n",
    "\n",
    "patk = [1, 10, 20, 50, 100, 117, 150, 200, 300, 400, 500, 600]\n",
    "res_table = [[\"Precision at:\"] + patk, [\"Val\"]]\n",
    "\n",
    "for k in patk:\n",
    "    v1 = precision_at_k(preserve_non_negative_max, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1, 2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "\n",
    "\n",
    "\n",
    "ratk = [117, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1388]\n",
    "res_table = [[\"Recall at:\"] + ratk, [\"Val\"]]\n",
    "\n",
    "for k in ratk:\n",
    "    v1 = recall_at_k(preserve_non_negative_max, k) #round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(round(v1,2))\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
