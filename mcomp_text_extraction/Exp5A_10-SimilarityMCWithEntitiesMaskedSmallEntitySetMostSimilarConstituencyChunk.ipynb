{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from collections import defaultdict\n",
    "from scipy import spatial\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This exp. is done using the test sentence only. Doesn't take into account the train IP set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"InputTestSet-Reviews48_Ann.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>PID</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Sent</th>\n",
       "      <th>MComp</th>\n",
       "      <th>Cat</th>\n",
       "      <th>SubCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The authors propose to use k-DPP to select a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>This paper covers the related work nicely, wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The rest of the paper are also clearly written.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>However, I have some concerns about the propos...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019_SJf_XhCqKm</td>\n",
       "      <td>Reject</td>\n",
       "      <td>- It is not clear how to define the kernel, th...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID              PID     Dec  \\\n",
       "0    0  2019_SJf_XhCqKm  Reject   \n",
       "1    1  2019_SJf_XhCqKm  Reject   \n",
       "2    2  2019_SJf_XhCqKm  Reject   \n",
       "3    3  2019_SJf_XhCqKm  Reject   \n",
       "4    4  2019_SJf_XhCqKm  Reject   \n",
       "\n",
       "                                                Sent  MComp  Cat SubCat  \n",
       "0  The authors propose to use k-DPP to select a s...      0  NaN    NaN  \n",
       "1  This paper covers the related work nicely, wit...      0  NaN    NaN  \n",
       "2    The rest of the paper are also clearly written.      0  NaN    NaN  \n",
       "3  However, I have some concerns about the propos...      0  NaN    NaN  \n",
       "4  - It is not clear how to define the kernel, th...      0  NaN    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict = {}\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    pid = df.loc[i][\"PID\"]\n",
    "    if not pid in gt_dict:\n",
    "        gt_dict[pid] = {\"dec\": df.loc[i][\"Dec\"], \"mcomp\": set(), \"not_mcomp\": set()}\n",
    "    if df.loc[i][\"MComp\"] == 1:\n",
    "        gt_dict[pid][\"mcomp\"].add(df.loc[i][\"UID\"])\n",
    "    else:\n",
    "        gt_dict[pid][\"not_mcomp\"].add(df.loc[i][\"UID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accept': [48, 644], 'Reject': [69, 744]}\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {\"Accept\": [0, 0], \"Reject\": [0, 0]}\n",
    "\n",
    "for k, v in gt_dict.items():\n",
    "    #print(len(v[\"mcomp\"]), len(v[\"not_mcomp\"]), v[\"dec\"])\n",
    "    stats_dict[v[\"dec\"]][0] += len(v[\"mcomp\"])\n",
    "    stats_dict[v[\"dec\"]][1] += len(v[\"not_mcomp\"])\n",
    "    \n",
    "print(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSet length: 32\n",
      " ['2019_SJf_XhCqKm', '2017_Bk0MRI5lg', '2020_SyevYxHtDB', '2018_rJBiunlAW', '2020_rkltE0VKwH', '2018_Hki-ZlbA-', '2019_BJx0sjC5FX', '2020_r1e_FpNFDr', '2020_B1lsXREYvr', '2018_SkZxCk-0Z', '2019_rJzoujRct7', '2018_HkfXMz-Ab', '2017_BJ9fZNqle', '2019_SyxZJn05YX', '2017_B1ckMDqlg', '2017_HJ0NvFzxl', '2017_S1_pAu9xl', '2018_SyYYPdg0-', '2017_BJAA4wKxg', '2019_HyVxPsC9tm', '2019_HylTBhA5tQ', '2019_B1l08oAct7', '2018_H135uzZ0-', '2017_H1oyRlYgg', '2017_r1y1aawlg', '2020_r1eX1yrKwB', '2020_Byg79h4tvB', '2019_H1lFZnR5YX', '2020_BkeWw6VFwr', '2018_HyHmGyZCZ', '2018_HyUNwulC-', '2020_HkgsPhNYPS']\n"
     ]
    }
   ],
   "source": [
    "test_set = list(gt_dict.keys())\n",
    "print(\"TestSet length: %d\\n\"%len(test_set), test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_SJf_XhCqKm     {39, 17, 20, 27, 28, 30}\n",
      "2017_Bk0MRI5lg      {48, 57}\n",
      "2020_SyevYxHtDB     {76, 87}\n",
      "2018_rJBiunlAW      {108, 110, 112, 113, 124, 126}\n",
      "2020_rkltE0VKwH     {160, 155, 184, 159}\n",
      "2018_Hki-ZlbA-      {267, 235, 236, 271}\n",
      "2019_BJx0sjC5FX     {292, 287}\n",
      "2020_r1e_FpNFDr     {312, 322, 315, 308}\n",
      "2020_B1lsXREYvr     {376, 401}\n",
      "2018_SkZxCk-0Z      {449, 443, 445, 486}\n",
      "2019_rJzoujRct7     {518, 519}\n",
      "2018_HkfXMz-Ab      {573, 566}\n",
      "2017_BJ9fZNqle      {627, 623, 615}\n",
      "2019_SyxZJn05YX     {672, 673, 657, 669, 671}\n",
      "2017_B1ckMDqlg      {714, 707}\n",
      "2017_HJ0NvFzxl      {739}\n",
      "2017_S1_pAu9xl      {792, 809, 810, 806}\n",
      "2018_SyYYPdg0-      {834, 867, 868, 869, 870, 872, 873, 844, 830}\n",
      "2017_BJAA4wKxg      {884}\n",
      "2019_HyVxPsC9tm     {931, 933, 905, 909, 912, 913, 919, 926}\n",
      "2019_HylTBhA5tQ     {972, 950}\n",
      "2019_B1l08oAct7     {994, 996, 1064, 1004, 1007, 1044, 1047, 1048, 1055}\n",
      "2018_H135uzZ0-      {1072, 1079}\n",
      "2017_H1oyRlYgg      set()\n",
      "2017_r1y1aawlg      {1125, 1162, 1100, 1102, 1168}\n",
      "2020_r1eX1yrKwB     {1177, 1202, 1212}\n",
      "2020_Byg79h4tvB     {1243, 1268}\n",
      "2019_H1lFZnR5YX     {1281, 1316, 1284, 1318, 1289, 1331, 1333, 1279}\n",
      "2020_BkeWw6VFwr     {1347, 1373}\n",
      "2018_HyHmGyZCZ      {1406, 1421, 1390, 1426}\n",
      "2018_HyUNwulC-      {1451, 1452}\n",
      "2020_HkgsPhNYPS     {1504, 1464, 1497, 1500, 1502}\n"
     ]
    }
   ],
   "source": [
    "for k in test_set:\n",
    "    print('{:20}{}'.format(k, gt_dict[k][\"mcomp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_for_test = defaultdict(list)\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    pid = df.loc[i][\"PID\"]\n",
    "    sents_for_test[pid].append((df.loc[i][\"UID\"], df.loc[i][\"Sent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"entities_dict_smaller\", \"r\") as f:\n",
    "    entity_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Material', 'Method', 'Metric', 'Task'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(entity_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('convolutional neural networks', 'Method'),\n",
       " ('convnets', 'Method'),\n",
       " ('recognition', 'Task'),\n",
       " ('visual recognition tasks', 'Task'),\n",
       " ('age estimation', 'Task'),\n",
       " ('head pose estimation', 'Task'),\n",
       " ('multi - label classification', 'Task'),\n",
       " ('semantic segmentation', 'Task'),\n",
       " ('classification', 'Task'),\n",
       " ('deep convnets', 'Method'),\n",
       " ('dldl', 'Method'),\n",
       " ('feature learning', 'Task'),\n",
       " ('deep learning', 'Method'),\n",
       " ('image classification', 'Task'),\n",
       " ('deep learning methods', 'Method'),\n",
       " ('image classification tasks', 'Task'),\n",
       " ('human pose estimation', 'Task'),\n",
       " ('convnet', 'Method'),\n",
       " ('recognition tasks', 'Task'),\n",
       " ('ensemble', 'Method')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(entity_dict.items())[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784\n"
     ]
    }
   ],
   "source": [
    "entity_key_map = {}\n",
    "for i in entity_dict:\n",
    "    s = re.sub('[^0-9a-zA-Z,:;.?!\\- ]+', '', i)\n",
    "    while s.find(\"  \") > -1:\n",
    "        s = s.replace(\"  \", \" \")\n",
    "    if len(s) > 2:\n",
    "        cl = re.sub('[^0-9a-zA-Z ]+', '', i)\n",
    "        while cl.find(\"  \") > -1:\n",
    "            cl = cl.replace(\"  \", \" \")\n",
    "        entity_key_map[cl.strip()] = i\n",
    "print(len(entity_key_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "coun = 0\n",
    "for i in entity_dict:\n",
    "    if len(i) < 5:\n",
    "        coun +=1\n",
    "#         print(i)\n",
    "print(coun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('convolutional neural networks', 'convolutional neural networks'),\n",
       " ('convnets', 'convnets'),\n",
       " ('recognition', 'recognition'),\n",
       " ('visual recognition tasks', 'visual recognition tasks'),\n",
       " ('age estimation', 'age estimation')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(entity_key_map.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Method': 1191, 'Task': 289, 'Metric': 158, 'Material': 165})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(entity_dict.values())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(c)\n",
    "reverse_map = defaultdict(list)\n",
    "\n",
    "for k, v in entity_dict.items():\n",
    "    reverse_map[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in reverse_map[\"Task\"]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MNIST\" in entity_key_map, \"mnist\" in entity_key_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. RoBERTa trained on SciLit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy-transformers            0.6.2\r\n",
      "tokenizers                    0.7.0\r\n",
      "transformers                  2.9.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip3.7 list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./trained_lm/CLMLModelRoBerta/\")\n",
    "model = AutoModel.from_pretrained(\"./trained_lm/CLMLModelRoBerta/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_using_roberta(text):\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_entities(sentence, replace_with_dataset=True):\n",
    "    cleaned_sent = re.sub('[^0-9a-zA-Z,:;.?!\\- ]+', ' ', sentence)\n",
    "    while cleaned_sent.find(\"  \") > -1:\n",
    "        cleaned_sent = cleaned_sent.replace(\"  \", \" \")\n",
    "    \n",
    "    entity_key_map_keys = list(entity_key_map.keys()) # As we will be dunamically adding entries to this dict an dthat will throw an error.\n",
    "    entities_found = []\n",
    "    for i in entity_key_map_keys:\n",
    "        if cleaned_sent.find(\" \" + i + \" \") > -1:\n",
    "            entities_found.append(i)\n",
    "        elif cleaned_sent.lower().find(\" \" + i + \" \") > -1:\n",
    "            found_idx = cleaned_sent.lower().find(\" \" + i + \" \")\n",
    "            entity_dict[cleaned_sent[found_idx:found_idx+len(\" \" + i + \" \")]] = entity_dict[i]\n",
    "            entity_key_map[cleaned_sent[found_idx:found_idx+len(\" \" + i + \" \")]] = entity_key_map[i]\n",
    "    \n",
    "    entities_found.sort(key=lambda s: len(s))\n",
    "    len_sorted_entities = entities_found.copy()\n",
    "    \n",
    "    subset_entities = []\n",
    "    # Remove subset entities (eg: Among cnn and 3-layer-cnn, prefer the latter)\n",
    "    for fe in len_sorted_entities:\n",
    "        for other_ent in len_sorted_entities:\n",
    "            if fe != other_ent and other_ent.find(fe) > -1:\n",
    "                subset_entities.append(fe)\n",
    "                break\n",
    "    for se in subset_entities:\n",
    "        len_sorted_entities.remove(se)\n",
    "    for maxents in len_sorted_entities:\n",
    "        mask_name = \" \" + entity_dict[entity_key_map[i]].lower() + \" \"\n",
    "        if replace_with_dataset:\n",
    "            if mask_name == \" material \":\n",
    "                mask_name = \" dataset \"\n",
    "        cleaned_sent = cleaned_sent.replace(\" \" + maxents + \" \", mask_name)\n",
    "    words_cleaned = nltk.word_tokenize(cleaned_sent)\n",
    "    dups_removed = [v for i, v in enumerate(words_cleaned) if i == 0 or v != words_cleaned[i-1]]\n",
    "    new_dup_removed_sent = \" \".join(dups_removed)\n",
    "    return new_dup_removed_sent.strip()\n",
    "\n",
    "#     #print(cleaned_sent)\n",
    "#     for i in entity_key_map:\n",
    "#         if cleaned_sent.find(\" \" + i + \" \") > -1:\n",
    "#             #print(\"Substituting ent: {} with mask: {}\".format(i, entity_dict[entity_key_map[i]].lower()))\n",
    "#             cleaned_sent = cleaned_sent.replace(i, entity_dict[entity_key_map[i]].lower())\n",
    "#     return cleaned_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the BO-PET test , the best method is to take risks . This leads to substantial improvement in results .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"In the BO-PET test*, the best method is to take\\ risks. This leads to substantial improvement in results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"this is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "sp_toks = [\"result\", \"method\", \"task\", \"dataset\", \"metric\", \"baseline\", \"fair\", \"unfair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks_using_spacy_dp(conssentence, replace_with_dataset=True):\n",
    "    \n",
    "    conssentence = mask_entities(conssentence, replace_with_dataset)\n",
    "#     print(conssentence)\n",
    "    doc = nlp(conssentence)\n",
    "    verb_subtree = []\n",
    "\n",
    "    for s in doc.sents:\n",
    "#         find_special_tokens = {\"compar\": [], \"result\": [], \"method\": [], \"technique\": [], \"task\": [], \"dataset\": [], \"material\": [], \"metric\": []}\n",
    "        find_special_tokens = {\"compar\": [], \"result\": [], \"method\": [], \"baseline\": [], \"task\": [], \n",
    "                               \"dataset\": [],  \"metric\": [], \"unfair\": [], \"fair\": []}\n",
    "\n",
    "        for tok in s:\n",
    "\n",
    "            if tok.text.lower().startswith(\"compar\"):\n",
    "                find_special_tokens[\"compar\"].append(tok)\n",
    "            else:\n",
    "                for k in sp_toks:\n",
    "                    if tok.text.lower().startswith(k):\n",
    "                        find_special_tokens[k].append(tok)\n",
    "                        break\n",
    "\n",
    "        verb_tokens = []\n",
    "        if find_special_tokens[\"compar\"]:\n",
    "            for t in find_special_tokens[\"compar\"]:\n",
    "#                     verb_subtree.append(t.subtree)\n",
    "                if t == s.root:\n",
    "                    simplified_sent = \"\"\n",
    "                    for chh in t.lefts:\n",
    "                        simplified_sent = simplified_sent + \" \" + chh.text\n",
    "                    simplified_sent = simplified_sent + \" \" + t.text\n",
    "                    for chh in t.rights:\n",
    "                        simplified_sent = simplified_sent + \" \" + chh.text\n",
    "#                         print(\"SIMP: \", simplified_sent)\n",
    "                    verb_subtree.append(simplified_sent)\n",
    "                else:\n",
    "                    verb_subtree.append(t.subtree)\n",
    "        else:\n",
    "            for k in sp_toks:\n",
    "                for i in find_special_tokens[k]:\n",
    "                    local_vt = []\n",
    "                    for j in i.ancestors:\n",
    "                        if j.pos_ == \"NOUN\":\n",
    "                            local_vt.append(j)\n",
    "                    if not local_vt:\n",
    "                        for j in i.ancestors:\n",
    "                            if j.pos_ == \"VERB\":\n",
    "                                local_vt.append(j)\n",
    "                    verb_tokens = verb_tokens + local_vt\n",
    "\n",
    "\n",
    "            for i in verb_tokens:\n",
    "                verb_subtree.append(i.subtree)\n",
    "\n",
    "    eecc = []\n",
    "    for i in verb_subtree:\n",
    "        if type(i) == str:\n",
    "            eecc.append(i)\n",
    "        else:\n",
    "            local_chunk = \"\"\n",
    "            for lcaltok in i:\n",
    "                local_chunk = local_chunk + \" \" + lcaltok.text\n",
    "            eecc.append(local_chunk)\n",
    "#     if not eecc:\n",
    "#         print(conssentence)\n",
    "    return list(set(eecc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' more large - scale experiments on image related tasks',\n",
       " ' the practicability of the method']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"It would be interesting to explore the practicability of the method on more large-scale experiments on image related tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' comparison to SOTA']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"The experimental validation is also not extensive since comparison to SOTA is not included.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_words_spacy(conssentence):\n",
    "    \n",
    "    doc = nlp(conssentence)\n",
    "    final_sentence = []\n",
    "    \n",
    "    for s in doc.sents:\n",
    "        for tok in s:\n",
    "            if not tok.is_stop:\n",
    "                final_sentence.append(tok.text)\n",
    "    return final_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    final_list = []\n",
    "    for i in l:\n",
    "        if type(i) == list:\n",
    "            final_list += flatten_list(i)\n",
    "        else:\n",
    "            final_list.append(i)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_subtree_chunks(subtree_chunks, depth_to_split, dict_len_st):\n",
    "    final_chunks_sent = [] \n",
    "    \n",
    "    for stchunk in subtree_chunks:\n",
    "#         print(\"Stchunk: \", stchunk)\n",
    "#         print(len(stchunk[0].leaves()), stchunk[0].leaves())\n",
    "\n",
    "        if len(stchunk[0].leaves()) > 6:\n",
    "            subsubtrees = list(stchunk[0].subtrees())\n",
    "            fnlsubsub_len5_words = []\n",
    "            new_subdepth_to_split = depth_to_split+1\n",
    "            for sss in subsubtrees:\n",
    "                if str(sss) in dict_len_st and dict_len_st[str(sss)] == new_subdepth_to_split:\n",
    "#                     print(\"SSS: \", sss)\n",
    "                    fnlsubsub_len5_words.append(return_subtree_chunks([(sss, new_subdepth_to_split)], new_subdepth_to_split, dict_len_st))\n",
    "\n",
    "            for subchunk in fnlsubsub_len5_words:\n",
    "                final_chunks_sent.append(subchunk)\n",
    "        else:\n",
    "            final_chunks_sent.append(\" \".join(stchunk[0].leaves()))\n",
    "    \n",
    "    return final_chunks_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp = StanfordCoreNLP(\"/home/shruti/Documents/DataNLP/stanford-corenlp-4.1.0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constituency_chunks(sent):\n",
    "    corenlp = StanfordCoreNLP(\"/home/shruti/Documents/DataNLP/stanford-corenlp-4.1.0/\")\n",
    "    parse_str = corenlp.parse(sent)\n",
    "    nltk_tree = Tree.fromstring(parse_str)\n",
    "    \n",
    "#     print(nltk_tree)\n",
    "    \n",
    "    subtrees_list = list(nltk_tree.subtrees())\n",
    "    subtrees_tpos = nltk_tree.treepositions()\n",
    "    for i in range(0, len(nltk_tree.leaves())):\n",
    "        tp_leaf = nltk_tree.leaf_treeposition(i)\n",
    "        subtrees_tpos.remove(tp_leaf)\n",
    "    \n",
    "    dict_len_st = {}\n",
    "    depth_of_subtree = []\n",
    "    for _, i in enumerate(subtrees_list):\n",
    "        depth_of_subtree.append((i, len(subtrees_tpos[_])))\n",
    "        dict_len_st[str(i)] = len(subtrees_tpos[_])\n",
    "    \n",
    "    cdepths = []\n",
    "    for d in depth_of_subtree:\n",
    "        cdepths.append(d[1])\n",
    "    depth_counter = Counter(cdepths)\n",
    "    sorted_depths = sorted(list(depth_counter.keys()))\n",
    "#     print(sorted(depth_counter.items(), key=lambda x: x[0]))\n",
    "    \n",
    "    depth_to_split = None\n",
    "#     print(sorted_depths) \n",
    "    for sd in sorted_depths:\n",
    "        if depth_counter[sd] == 3:\n",
    "            depth_to_split = 3\n",
    "        elif depth_counter[sd] > 3:\n",
    "            depth_to_split = sd\n",
    "            break\n",
    "#     if depth_to_split == None or depth_to_split == 4:\n",
    "#         print(\"Depth to split: {}\".format(depth_to_split))\n",
    "        \n",
    "#     print(\"depth: \", depth_to_split)\n",
    "    \n",
    "    subtree_chunks = []\n",
    "    for i in depth_of_subtree:\n",
    "        if i[1] == depth_to_split:\n",
    "            subtree_chunks.append(i)\n",
    "    \n",
    "    final_chunks_sent = []\n",
    "    \n",
    "    final_chunks_sent = return_subtree_chunks(subtree_chunks, depth_to_split, dict_len_st)\n",
    "    \n",
    "# #     for tt in subtree_chunks:\n",
    "# #         print(tt)\n",
    "    \n",
    "#     for stchunk in subtree_chunks:\n",
    "#         print(len(stchunk[0].leaves()), stchunk[0].leaves())\n",
    "# #         print(stchunk)\n",
    "#         if len(stchunk[0].leaves()) > 5:\n",
    "#             subsubtrees = list(stchunk[0].subtrees())\n",
    "#             fnlsubsub = []\n",
    "#             new_subdepth_to_split = depth_to_split+1\n",
    "#             new_subdepths = []\n",
    "#             for sss in subsubtrees:\n",
    "#                 new_subdepths.append(dict_len_st[str(sss)])\n",
    "#             new_subdepths = sorted(new_subdepths)\n",
    "#             new_subdepth_to_split = new_subdepths[len(new_subdepths)//2]\n",
    "#             for sss in subsubtrees:\n",
    "#                 if str(sss) in dict_len_st and dict_len_st[str(sss)] == new_subdepth_to_split:\n",
    "#                     fnlsubsub.append(sss)\n",
    "#             for subchunk in fnlsubsub:\n",
    "#                 final_chunks_sent.append(\" \".join(subchunk.leaves()))\n",
    "#         else:\n",
    "#             final_chunks_sent.append(\" \".join(stchunk[0].leaves()))\n",
    "# #         final_chunks_sent.append(\" \".join(stchunk[0].leaves()))\n",
    "    corenlp.close()\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    final_chunks = flatten_list(final_chunks_sent)\n",
    "    stopwords_removed_chunks = []\n",
    "    for chunk in final_chunks:\n",
    "        if chunk in stop_words:\n",
    "            stopwords_removed_chunks.append(chunk)\n",
    "    return stopwords_removed_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) 2018_Hki-ZlbA- 238 * I don’t know if the notation in the Equation in the paragraph describing Carlini & Wagner comes from the original paper, but the inner max would be easier to read as \\max_{i \\neq t} \\{Z(x’)_i \\}\n",
      "* Page 3 “Neural network verification”: I dont agree with the statement that neural networks commonly are trained on “a small set of inputs”.\n",
      "Expecting value: line 1 column 1 (char 0) 2018_Hki-ZlbA- 250 I therefore find the authors' statement on page 3 disturbing: \"... they are trained over a small set of inputs, and can then perform well, in general, on previously-unseen inputs\" -- which seems false (with high probability over all possible worlds).\n",
      "Expecting value: line 1 column 1 (char 0) 2020_r1e_FpNFDr 355 By the standard argument of the statistical learning theory (such as Theorem A.4), we can typically bound the generalization error by $O(B\\sqrt{D/N})$ where $B$ is the infimum of Lipschitz constant of hypotheses, $D$ is the intrinsic dimension of the hypothesis class, and $N$ is the sample size.\n",
      "Expecting value: line 1 column 1 (char 0) 2020_r1e_FpNFDr 362 However, I think it is too aggressive to conclude it from Figure 3 because the decreasing trend in the value of $\\|K-K_0\\|_\\sigma$ is found only around $2\\times 10^6\\leq W \\leq 3\\times 10^6$.\n",
      "Expecting value: line 1 column 1 (char 0) 2020_r1e_FpNFDr 366 - page 3, section 2., theorem 2.1\n",
      " - I think we should replace $\\log(\\lambda n)$ and $\\log(\\lambda)$ in equations with $\\log(\\beta \\lambda n)$ and $\\log(\\beta \\lambda)$, respectively.\n",
      "Expecting value: line 1 column 1 (char 0) 2018_HkfXMz-Ab 554 Examples are given where appropriate in a clear and coherent manner\n",
      " • Problem statement well defined mathematically and understandable for a broad audience\n",
      " • Mentioning of failures and limitations demonstrates a realistic view on the project\n",
      " • Complexity and time analysis provided\n",
      " • Paper written so that it's easy for a reader to implement the methods\n",
      " • Detailed descriptions of all instantiations even parameters and comparison methods\n",
      " • System specified\n",
      " • Validation method specified\n",
      " • Data and repository, as well as cleaning process provided\n",
      " • Every figure and plot is well explained and interpreted\n",
      " • Large successful evaluation section provided\n",
      " • Many different evaluation measures defined to measure different properties of the project\n",
      " • Different observability modes\n",
      " • Evaluation against most compatible methods from other sources \n",
      " • Results are in line with hypothesis\n",
      " • Thorough appendix clearing any open questions \n",
      " \n",
      "It would have been good to have a summary/conclusion/future work section\n",
      " \n",
      "SUMMARY: ACCEPT.\n",
      "Expecting value: line 1 column 1 (char 0) 2018_HkfXMz-Ab 580 This paper has many strengths:\n",
      "1) The writing is clear, and the paper is well-motivated\n",
      "2) The proposed algorithm is described in excellent detail, which is essential to reproducibility\n",
      "3) As stated previously, the approach is validated with a large number of real Android projects\n",
      "4) The fact that the language generated is non-trivial (Java-like) is a substantial plus\n",
      "5) Good discussion of limitations\n",
      "Overall, this paper is a valuable addition to the empirical software engineering community, and a nice break from more traditional approaches of learning abstract syntax trees.\n",
      "Expecting value: line 1 column 1 (char 0) 2017_BJ9fZNqle 602 The original abstract is overly strong in its assertion that a unimodal latent prior p(z) cannot fit a multimodal marginal int_z p(x|z)p(x)dz with a DNN response model p(x|z) (\"it cannot possibly capture more complex aspects of the data distribution\", \"critical restriction\", etc).\n",
      "Expecting value: line 1 column 1 (char 0) 2017_BJ9fZNqle 607 There are 3 types of multimodality at play here: multimodality in the observed marginal distribution p(x), which can be captured by any deep latent Gaussian model, multimodality in the prior p(z), which makes sense in some situations (eg: a model of MNIST digits could have 10 prior modes corresponding to latent codes for each digit class), and multimodality in the posterior z for a given observation x_i, q(z_i|x_i).\n",
      "'int' object has no attribute 'encode' 2019_HyVxPsC9tm 938 2\n",
      "'int' object has no attribute 'encode' 2019_HyVxPsC9tm 940 3\n",
      "Expecting value: line 1 column 1 (char 0) 2019_B1l08oAct7 994 (1)  A deep BNN to show that the cumulative error is negligible as the number of the hidden layers increases \n",
      "(2)  Small latent dimension since CLT may not hold\n",
      "(3)  A heavy-tailed variational distribution since the second moment may not be finite \n",
      "(4)  Other nonlinear activations since the Gaussian approximation may not be accurate due to (generalized) Berry-Esseen theorem\n",
      "(5) A BNN with skip connections  since a Bayesian multiplayer perceptron with skip connections is also a feed-forward BNN\n",
      " \n",
      "Among these cases, I am eager to see some results on a deep thin BNN.\n",
      "Expecting value: line 1 column 1 (char 0) 2019_B1l08oAct7 996 Furthermore, I would like to see some empirical comparison on real-world datasets between DVI and MCVI under a *fixed* prior since such comparison demonstrates the approximation accuracy of DVI and rule out the confounding factor introduced by the empirical Bayes approach.\n",
      "Expecting value: line 1 column 1 (char 0) 2017_r1y1aawlg 1102 Although I do like the paper on the whole, to really convince me that main objective -- ie that **iterative** improvement is beneficial -- has been satifactorily demonstrated it would be necessary to include stronger baselines - and in particular, to show that an iterative refinement scheme can really improve over a system closely matched to the attention-based model, both when used in isolation and when used in system combination with a PBMT system, and to demonstrate that the PBMT system is not simply acting as a regulariser for the attention-based model.\n",
      "Expecting value: line 1 column 1 (char 0) 2017_r1y1aawlg 1122 The idea of iterative refinement has been proposed in other problems that have complex output spaces, for example the DRAW model of Gregor et al and the conditional adversarial network models used to refine images proposed recently by Isola et al In NLP, there have been several (stochastic) hill climbing approaches that have been proposed, such as the work on parsing by Zhang and Lei et al (2014) who use random initial guesses and then do greedy hill climbing using a series of local refinements, the structured prediction cascades of Weiss and Taskar (2009) (not to mention general coarse-to-fine modeling strategies).\n",
      "Expecting value: line 1 column 1 (char 0) 2020_Byg79h4tvB 1253 Additional Feedback:\n",
      "- missing references on sim2real UDA: \"DADA: Depth-aware Domain Adaptation in Semantic Segmentation\" (Vu et al, ICCV'19), \"SPIGAN: Privileged Adversarial Learning from Simulation\" (Lee et al, ICLR'19)\n",
      "## Post rebuttal update\n",
      "I would like to thank the authors for replying to our questions.\n",
      "Expecting value: line 1 column 1 (char 0) 2020_Byg79h4tvB 1269 details:\n",
      "- terminology: \"intra-class\" is better than \"within class\"\n",
      "- separate citations: eg: entropy minimization, mean-teacher, and virtual adversarial training, have been successfully applied to UDA (Vu et al, 2019; French et al, 2018; Shu et al, 2018) -> entropy minimization (Vu et al, 2019), mean-teacher (French et al, 2018), and virtual adversarial training (Shu et al, 2018), have been successfully applied to UDA\n",
      "- confusion: At the last of Section 3.2, it says \\hat{f}=M^{T}p. But in Equation 9, \\hat{f} and M^{T}p are concatenated, which is confusing: why do you concatenate two identical vectors?\n",
      "Expecting value: line 1 column 1 (char 0) 2020_Byg79h4tvB 1270 - Implementation Details: Section 4.1, paragraph 4: \\lambda^{f}_{adv} =5e-3, \\lambda^{f}_{adv} and \\lambda^{p}_{adv} increase from 0 to 1.\n",
      "'int' object has no attribute 'encode' 2018_HyHmGyZCZ 1425 2\n"
     ]
    }
   ],
   "source": [
    "roberta_vectors = defaultdict(dict)\n",
    "skip_uids = []\n",
    "\n",
    "for pid in gt_dict:\n",
    "    roberta_vectors[pid] = {}\n",
    "    \n",
    "    for mcs in gt_dict[pid][\"mcomp\"]:\n",
    "        try:\n",
    "            mcomp_chunks_from_sent = get_constituency_chunks(df.loc[mcs][\"Sent\"])\n",
    "            if mcomp_chunks_from_sent:\n",
    "                final_chunks = mcomp_chunks_from_sent\n",
    "            else:\n",
    "                final_chunks = [df.loc[mcs][\"Sent\"]]\n",
    "            \n",
    "            roberta_vectors[pid][mcs] = []\n",
    "            for single_chunk in final_chunks:\n",
    "                vec = embed_text_using_roberta(single_chunk.strip()).mean(1).detach().numpy()\n",
    "                roberta_vectors[pid][mcs].append(vec / norm(vec))\n",
    "        except Exception as ex:\n",
    "            print(ex, pid, mcs, df.loc[mcs][\"Sent\"])\n",
    "            skip_uids.append(mcs)\n",
    "    \n",
    "    for mcs in gt_dict[pid][\"not_mcomp\"]:\n",
    "        try:\n",
    "            mcomp_chunks_from_sent = get_constituency_chunks(df.loc[mcs][\"Sent\"])\n",
    "            if mcomp_chunks_from_sent:\n",
    "                final_chunks = mcomp_chunks_from_sent\n",
    "            else:\n",
    "                final_chunks = [df.loc[mcs][\"Sent\"]]\n",
    "            \n",
    "            roberta_vectors[pid][mcs] = []\n",
    "            for single_chunk in final_chunks:\n",
    "                vec = embed_text_using_roberta(single_chunk.strip()).mean(1).detach().numpy()\n",
    "                roberta_vectors[pid][mcs].append(vec / norm(vec))\n",
    "        except Exception as ex:\n",
    "            print(ex, pid, mcs, df.loc[mcs][\"Sent\"])\n",
    "            skip_uids.append(mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 1372\n"
     ]
    }
   ],
   "source": [
    "mcomp_sentences = {}\n",
    "not_mcomp_sentences = {}\n",
    "\n",
    "for pid in gt_dict:\n",
    "    for mcs in gt_dict[pid][\"mcomp\"]:\n",
    "        if not mcs in skip_uids:\n",
    "            mcomp_sentences[mcs] = pid\n",
    "    for mcs in gt_dict[pid][\"not_mcomp\"]:\n",
    "        if not mcs in skip_uids:\n",
    "            not_mcomp_sentences[mcs] = pid\n",
    "print(len(mcomp_sentences), len(not_mcomp_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_with_mcomp = defaultdict(dict)\n",
    "sim_with_not_mcomp = defaultdict(dict)\n",
    "sim_with_notmcomp_paper_sents = defaultdict(dict)\n",
    "\n",
    "mean_at_k = [\"1\", \"3\", \"5\", \"7\", \"10\", \"20\", \"30\", \"50\", \"100\", \"500\", \"1000\", \"1380\"]\n",
    "\n",
    "for sid in mcomp_sentences:\n",
    "    \n",
    "    # 1. With other mcomp sentences\n",
    "    temp_list = []    \n",
    "    for osid in mcomp_sentences:\n",
    "        if osid != sid:\n",
    "            for cvec1 in roberta_vectors[mcomp_sentences[osid]][osid]:\n",
    "                for cvec2 in roberta_vectors[mcomp_sentences[sid]][sid]:\n",
    "                    temp_list.append(np.inner(cvec1, cvec2)[0][0])\n",
    "    \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    sim_with_mcomp[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        sim_with_mcomp[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "\n",
    "    \n",
    "    # 2. With other not_mcomp_sentences\n",
    "    temp_list = []\n",
    "    for osid in not_mcomp_sentences:\n",
    "        for cvec1 in roberta_vectors[not_mcomp_sentences[osid]][osid]:\n",
    "            for cvec2 in roberta_vectors[mcomp_sentences[sid]][sid]:\n",
    "                temp_list.append(np.inner(cvec1, cvec2)[0][0])\n",
    "    \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    sim_with_not_mcomp[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        sim_with_not_mcomp[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "\n",
    "    \n",
    "    # 3. With not_mcomp_sentences of the same paper\n",
    "    temp_list = []    \n",
    "    for osid in not_mcomp_sentences:\n",
    "        if not_mcomp_sentences[osid] == mcomp_sentences[sid]:\n",
    "            for cvec1 in roberta_vectors[not_mcomp_sentences[osid]][osid]:\n",
    "                for cvec2 in roberta_vectors[mcomp_sentences[sid]][sid]:\n",
    "                    temp_list.append(np.inner(cvec1, cvec2)[0][0])\n",
    "    \n",
    "    sorted_temp_list = sorted(temp_list, reverse=True)\n",
    "    sim_with_notmcomp_paper_sents[sid][\"mean\"] = np.mean(sorted_temp_list)\n",
    "    for vv in mean_at_k:\n",
    "        sim_with_notmcomp_paper_sents[sid][\"mean_{}\".format(vv)] = np.mean(sorted_temp_list[0:int(vv)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_sim_plot\n",
    "diff12 = {\"all\": []}\n",
    "for vv in mean_at_k:\n",
    "    diff12[str(vv)] = []\n",
    "\n",
    "diff13 = {\"all\": []}\n",
    "for vv in mean_at_k:\n",
    "    diff13[str(vv)] = []\n",
    "\n",
    "for sid in sim_with_mcomp:\n",
    "    diff12[\"all\"].append(sim_with_mcomp[sid][\"mean\"] - sim_with_not_mcomp[sid][\"mean\"])\n",
    "    diff13[\"all\"].append(sim_with_mcomp[sid][\"mean\"] - sim_with_notmcomp_paper_sents[sid][\"mean\"])\n",
    "    \n",
    "    for vv in mean_at_k:\n",
    "        diff12[str(vv)].append(sim_with_mcomp[sid][\"mean_{}\".format(vv)] - sim_with_not_mcomp[sid][\"mean_{}\".format(vv)])\n",
    "        diff13[str(vv)].append(sim_with_mcomp[sid][\"mean_{}\".format(vv)] - sim_with_notmcomp_paper_sents[sid][\"mean_{}\".format(vv)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of the most similar constituency chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td></td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">20</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">100</td><td style=\"text-align: right;\">500</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">1380</td></tr>\n",
       "<tr><td></td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td></td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">3   </td><td style=\"text-align: right;\">5   </td><td style=\"text-align: right;\">7   </td><td style=\"text-align: right;\">10   </td><td style=\"text-align: right;\">20   </td><td style=\"text-align: right;\">30   </td><td style=\"text-align: right;\">50   </td><td style=\"text-align: right;\">100   </td><td style=\"text-align: right;\">500   </td><td style=\"text-align: right;\">1000   </td><td style=\"text-align: right;\">1380   </td></tr>\n",
       "<tr><td></td><td style=\"text-align: right;\">0.11</td><td style=\"text-align: right;\">0.25</td><td style=\"text-align: right;\">0.33</td><td style=\"text-align: right;\">0.36</td><td style=\"text-align: right;\"> 0.55</td><td style=\"text-align: right;\"> 0.77</td><td style=\"text-align: right;\"> 0.87</td><td style=\"text-align: right;\"> 0.91</td><td style=\"text-align: right;\">  0.98</td><td style=\"text-align: right;\">  0.93</td><td style=\"text-align: right;\">   0.91</td><td style=\"text-align: right;\">   0.89</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With dataset as mask\n",
    "res_table = [[\"\"] + mean_at_k, [\"\"]]\n",
    "\n",
    "for val in mean_at_k:\n",
    "    v1 = round(sum(i > 0 for i in diff12[val])/len(diff12[val]), 2)\n",
    "    res_table[1].append(v1)\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))\n",
    "\n",
    "# With dataset as mask\n",
    "res_table = [[\"\"] + mean_at_k, [\"\"]]\n",
    "\n",
    "for val in mean_at_k:\n",
    "    v1 = round(sum(i > 0 for i in diff13[val])/len(diff13[val]), 2)\n",
    "    res_table[1].append(v1)\n",
    "\n",
    "display(HTML(tabulate.tabulate(res_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse chunks after masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_chunks = {\"mcs\": [], \"nmcs\": []}\n",
    "\n",
    "for pid in gt_dict:\n",
    "    for mcs in gt_dict[pid][\"mcomp\"]:\n",
    "        try:\n",
    "            mcomp_chunks_from_sent = extract_chunks_using_spacy_dp(df.loc[mcs][\"Sent\"])\n",
    "            if mcomp_chunks_from_sent:\n",
    "                final_chunk = \". \".join(mcomp_chunks_from_sent)\n",
    "            else:\n",
    "                final_chunk = df.loc[mcs][\"Sent\"]\n",
    "            \n",
    "            masked_chunks[\"mcs\"].append((df.loc[mcs][\"Sent\"], final_chunk))\n",
    "        except Exception as ex:\n",
    "            continue\n",
    "    \n",
    "    for mcs in gt_dict[pid][\"not_mcomp\"]:\n",
    "        try:\n",
    "            mcomp_chunks_from_sent = extract_chunks_using_spacy_dp(df.loc[mcs][\"Sent\"])\n",
    "            if mcomp_chunks_from_sent:\n",
    "                final_chunk = \". \".join(mcomp_chunks_from_sent)\n",
    "            else:\n",
    "                final_chunk = df.loc[mcs][\"Sent\"]\n",
    "            masked_chunks[\"nmcs\"].append((df.loc[mcs][\"Sent\"], final_chunk))\n",
    "        except Exception as ex:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' comparison']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The authors propose k-DPP as an open loop oblivious to the evaluation of configurations method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search , uniform random search , low-discrepancy Sobol sequences , BO-TPE Bayesian optimization using tree-structured Parzen estimator by Bergstra et al 2011 .'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' comparison']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' comparison']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).',\n",
       "  ' comparison'),\n",
       " ('Second, their study only applies to a small number like 3-6 hyperparameters with a small k=20) The real challenge lies in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al (http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf) and Snoek et al (https://arxiv.org/pdf/1502.05700.pdf) that is essential for this kind of empirical study.',\n",
       "  ' a small number like 3 - 6 metric with a small k 20.  lies , authors do not compare against'),\n",
       " ('COMMENTS ON THE CHANGES SINCE THE LAST YEAR\\nI am not convinced by the comparison with Spearmint added by the authors since the previous version.',\n",
       "  ' the comparison with Spearmint added by the authors since the previous version')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_chunks[\"mcs\"][2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The authors propose k-DPP as an open loop oblivious to the evaluation of configurations method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search , uniform random search , low-discrepancy Sobol sequences , BO-TPE Bayesian optimization using tree-structured Parzen estimator by Bergstra et al 2011 .'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Third , the authors do not compare against some relevant , recent work , e.g. , Springenberg et al http : aad.informatik.uni-freiburg.de papers 16-NIPS-BOHamiANN.pdf and Snoek et al https : arxiv.org pdf 1502.05700.pdf that is essential for this kind of empirical study .'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al (http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf) and Snoek et al (https://arxiv.org/pdf/1502.05700.pdf) that is essential for this kind of empirical study.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mask_entities(sentence, replace_with_dataset=False):\n",
    "# #     cleaned_sent = re.sub('[^0-9a-zA-Z ]+', ' ', sentence)\n",
    "#     cleaned_sent = sentence\n",
    "#     while cleaned_sent.find(\"  \") > -1:\n",
    "#         cleaned_sent = cleaned_sent.replace(\"  \", \" \")\n",
    "    \n",
    "#     entities_found = []\n",
    "#     for i in entity_key_map:\n",
    "#         if cleaned_sent.find(\" \" + i + \" \") > -1:\n",
    "#             entities_found.append(i)\n",
    "    \n",
    "#     entities_found.sort(key=lambda s: len(s))\n",
    "#     len_sorted_entities = entities_found.copy()\n",
    "    \n",
    "#     subset_entities = []\n",
    "#     # Remove subset entities (eg: Among cnn and 3-layer-cnn, prefer the latter)\n",
    "#     for fe in len_sorted_entities:\n",
    "#         for other_ent in len_sorted_entities:\n",
    "#             if fe != other_ent and other_ent.find(fe) > -1:\n",
    "#                 subset_entities.append(fe)\n",
    "#                 break\n",
    "#     for se in subset_entities:\n",
    "#         len_sorted_entities.remove(se)\n",
    "#     for maxents in len_sorted_entities:\n",
    "#         mask_name = entity_dict[entity_key_map[i]].lower()\n",
    "#         if replace_with_dataset:\n",
    "#             if mask_name == \"material\":\n",
    "#                 mask_name = \"dataset\"\n",
    "#         cleaned_sent = cleaned_sent.replace(maxents, mask_name)\n",
    "#     words_cleaned = nltk.word_tokenize(cleaned_sent)\n",
    "#     dups_removed = [v for i, v in enumerate(words_cleaned) if i == 0 or v != words_cleaned[i-1]]\n",
    "#     new_dup_removed_sent = \" \".join(dups_removed)\n",
    "#     return new_dup_removed_sent.strip()\n",
    "\n",
    "# #     #print(cleaned_sent)\n",
    "# #     for i in entity_key_map:\n",
    "# #         if cleaned_sent.find(\" \" + i + \" \") > -1:\n",
    "# #             #print(\"Substituting ent: {} with mask: {}\".format(i, entity_dict[entity_key_map[i]].lower()))\n",
    "# #             cleaned_sent = cleaned_sent.replace(i, entity_dict[entity_key_map[i]].lower())\n",
    "# #     return cleaned_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse meaningful sentences that are more similar to NMCS in comparison to MCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_sim_with_mcomp = defaultdict(list)\n",
    "ana_sim_with_not_mcomp = defaultdict(list)\n",
    "\n",
    "\n",
    "mean_at_k = [\"1\", \"3\", \"5\", \"7\", \"10\", \"20\", \"30\", \"50\", \"100\", \"500\", \"1000\", \"1380\"]\n",
    "\n",
    "for sid in mcomp_sentences:\n",
    "    \n",
    "    # 1. With other mcomp sentences\n",
    "    temp_list = []    \n",
    "    for osid in mcomp_sentences:\n",
    "        if osid != sid:\n",
    "            temp_list.append((osid, np.inner(roberta_vectors[mcomp_sentences[osid]][osid], roberta_vectors[mcomp_sentences[sid]][sid])[0][0]))\n",
    "    \n",
    "    sorted_temp_list = sorted(temp_list, key=lambda x: x[1], reverse=True)\n",
    "    ana_sim_with_mcomp[sid] = sorted_temp_list\n",
    "\n",
    "    \n",
    "    # 2. With other not_mcomp_sentences\n",
    "    temp_list = []\n",
    "    for osid in not_mcomp_sentences:\n",
    "        temp_list.append((osid, np.inner(roberta_vectors[not_mcomp_sentences[osid]][osid], roberta_vectors[mcomp_sentences[sid]][sid])[0][0]))\n",
    "    \n",
    "    sorted_temp_list = sorted(temp_list, key=lambda x: x[1], reverse=True)\n",
    "    ana_sim_with_not_mcomp[sid] = sorted_temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_sentences_at_k = defaultdict(list)\n",
    "unproblematic_sentences_at_k = defaultdict(list)\n",
    "vv = 1\n",
    "\n",
    "for sid in sim_with_mcomp:\n",
    "    sim_diff = (sim_with_mcomp[sid][\"mean_{}\".format(vv)] - sim_with_not_mcomp[sid][\"mean_{}\".format(vv)])\n",
    "    if sim_diff < 0:\n",
    "        problematic_sentences_at_k[vv].append((sid,-1.0* sim_diff))\n",
    "    else:\n",
    "        unproblematic_sentences_at_k[vv].append((sid, sim_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(113, 0.1638484001159668),\n",
       " (1464, 0.12271469831466675),\n",
       " (931, 0.1226879358291626),\n",
       " (950, 0.12097209692001343),\n",
       " (1318, 0.10917872190475464)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1\n",
    "sorted_problematic_sentences_at_1 = sorted(problematic_sentences_at_k[k], key=lambda x: x[1], reverse=True)\n",
    "sorted(problematic_sentences_at_k[k], key=lambda x: x[1], reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 1\n",
    "# sorted_problematic_sentences_at_3 = sorted(problematic_sentences_at_k[3], key=lambda x: x[1], reverse=True)\n",
    "# sorted(problematic_sentences_at_k[3], key=lambda x: x[1], reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_problematic_sentences_at_3[0:3], sorted_problematic_sentences_at_3[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_unproblematic_sentences_at_3 = sorted(unproblematic_sentences_at_k[3], key=lambda x: x[1], reverse=True)\n",
    "# sorted_unproblematic_sentences_at_3[0:4], sorted_unproblematic_sentences_at_3[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sent:  The experimental results are very good for document modeling, but without ablation analysis against the baseline it is hard to see why they should be with such a small modification in G-NVDM.\n",
      "\n",
      "Meaningful comparison sentences: \n",
      "[(124, 0.74430156)]\n",
      "What is left is the gated incremental pooling operation; but to show that this operation is beneficial when added to autoregressive CNNs, a thorough comparison with an autoregressive CNN baseline is necessary.\n",
      "\n",
      "Non Meaningful comparison sentence: \n",
      "[(842, 0.8440055)]\n",
      "Paper Weaknesses:\n",
      "- The evaluation of the model is not great: (1) It would be interesting to combine bedroom and kitchen images and train jointly to see what it learns.\n",
      "\n",
      "\n",
      "\n",
      "Test sent:  The paper does not consider the more recent and highly relevant Moosavi-Dezfooli et al “Universal Adversarial Perturbations” CVPR 2017.\n",
      "\n",
      "Meaningful comparison sentences: \n",
      "[(1202, 0.5903547)]\n",
      "- I am concerned about whether the proposed method works well with harder datasets such as Office-Home dataset, because each class data are modeled by a simple Gaussian distribution in the proposed method.\n",
      "\n",
      "Non Meaningful comparison sentence: \n",
      "[(989, 0.6897952)]\n",
      "This paper is interesting since most of the existing works focus on Monte Carlo variational inference.\n",
      "\n",
      "\n",
      "\n",
      "Test sent:  Indeed, unsurprisingly, the authors note that \"the probability of correctly labelling a word as a mistake remains low (62%)\" - this admittedly beats a random-chance baseline, but is not compared to something more meaningful, such as simply contrasting the existing system with a more powerful convolutional model and labelling all discrepancies as mistakes.\n",
      "\n",
      "Meaningful comparison sentences: \n",
      "[(869, 0.60373676)]\n",
      "An additional problem is that performance is not compared to any external prior work.\n",
      "\n",
      "Non Meaningful comparison sentence: \n",
      "[(732, 0.69845736)]\n",
      "The preliminary results do not tell us yet if the highly complex graph-based differentiable memory has more learning or generalization capacity than other approaches.\n",
      "\n",
      "\n",
      "\n",
      "Test sent:  - State of the art is not well-studied in the paper.\n",
      "\n",
      "Meaningful comparison sentences: \n",
      "[(110, 0.63996166)]\n",
      "On the negative side, the authors present the results without fully referencing and acknowledging state-of-the-art.\n",
      "\n",
      "Non Meaningful comparison sentence: \n",
      "[(230, 0.7335436)]\n",
      "The network analysed here does not reach the state-of-the-art on MNIST from almost two decades ago.\n",
      "\n",
      "\n",
      "\n",
      "Test sent:  Minor comments:\n",
      "- I believe one should not compare the distance shown between the left and right columns of Figure 3 as they are obtained from two different models.\n",
      "\n",
      "Meaningful comparison sentences: \n",
      "[(615, 0.64030004)]\n",
      "Overall, the very strong improvements on the text modeling task over NVDM seem hard to understand, and I would like to see an ablation analysis of all the differences between that model and the proposed one.\n",
      "\n",
      "Non Meaningful comparison sentence: \n",
      "[(1388, 0.729555)]\n",
      "2)What is the value of k in Figure 3 and Figure 4?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sorted_problematic_sentences_at_1[5:10]:\n",
    "    print(\"Test sent: \", df.loc[s[0]][\"Sent\"])\n",
    "    \n",
    "    print(\"\\nMeaningful comparison sentences: \")\n",
    "    print(ana_sim_with_mcomp[s[0]][0:1])\n",
    "    for i in ana_sim_with_mcomp[s[0]][0:1]:\n",
    "        print(df.loc[i[0]][\"Sent\"])\n",
    "    \n",
    "    print(\"\\nNon Meaningful comparison sentence: \")\n",
    "    print(ana_sim_with_not_mcomp[s[0]][0:1])\n",
    "    for i in ana_sim_with_not_mcomp[s[0]][0:1]:\n",
    "        print(df.loc[i[0]][\"Sent\"])\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Minor comments : - I believe one should not compare the metric shown between the left and right columns of Figure 3 as they are obtained from two different models .'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"Minor comments:- I believe one should not compare the distance shown between the left and right columns of Figure 3 as they are obtained from two different models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' one should not compare the metric shown between the left and right columns of Figure 3 as they are obtained from two different models']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"Minor comments:- I believe one should not compare the distance shown between the left and right columns of Figure 3 as they are obtained from two different models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Although I do like the paper on the whole , to really convince me that main objective -- ie that iterative improvement is beneficial -- has been satifactorily demonstrated it would be necessary to include stronger baselines - and in particular , to show that an metric scheme can really improve over a system closely matched to the attention-based model , both when used in isolation and when used in system combination with a PBMT system , and to demonstrate that the PBMT system is not simply acting as a regulariser for the attention-based model .'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"Although I do like the paper on the whole, to really convince me that main objective -- ie that **iterative** improvement is beneficial -- has been satifactorily demonstrated it would be necessary to include stronger baselines - and in particular, to show that an iterative refinement scheme can really improve over a system closely matched to the attention-based model, both when used in isolation and when used in system combination with a PBMT system, and to demonstrate that the PBMT system is not simply acting as a regulariser for the attention-based model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' an metric scheme']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"Although I do like the paper on the whole, to really convince me that main objective -- ie that **iterative** improvement is beneficial -- has been satifactorily demonstrated it would be necessary to include stronger baselines - and in particular, to show that an iterative refinement scheme can really improve over a system closely matched to the attention-based model, both when used in isolation and when used in system combination with a PBMT system, and to demonstrate that the PBMT system is not simply acting as a regulariser for the attention-based model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In summary , while I think the paper is interesting , I suspect that the applicability of this technique is possibly limited at present , and I m unsure how much we can really read into the findings of the paper when the experiments are based on MNIST alone .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_entities(\"In summary, while I think the paper is interesting, I suspect that the applicability of this technique is possibly limited at present, and I'm unsure how much we can really read into the findings of the paper when the experiments are based on MNIST alone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' to compare a label - noise semi - supervised method with other label - noise only methods',\n",
       " ' perturbation consistency or other semi - supervised metric']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_chunks_using_spacy_dp(\"However, it's not completely fair to compare a label-noise + semi-supervised method with other label-noise only methods... As a matter of fact, you don't need to apply perturbation consistency (or other semi-supervised) regularization after identifying the training data with incorrect labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
