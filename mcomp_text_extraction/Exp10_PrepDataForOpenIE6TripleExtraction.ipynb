{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(\"InputTestSet-Reviews48_Ann_NEW.xlsx\")\n",
    "df_train = pd.read_excel(\"InputTrainSet-Reviews7_Ann.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1505, 7), (296, 7))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data to feed to OpenIE6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of train set: 296\n",
      "Len of test set: 1505\n"
     ]
    }
   ],
   "source": [
    "test_sentences = []\n",
    "train_sentences = []\n",
    "\n",
    "\n",
    "for i in range(0, df_train.shape[0]):\n",
    "    uid = df_train.loc[i][\"UID\"]\n",
    "    train_sentences.append(str(df_train.loc[i][\"Sent\"]).replace(\"\\n\", \" \"))\n",
    "print(\"Len of train set: {}\".format(len(train_sentences)))\n",
    "\n",
    "\n",
    "for i in range(0, df_test.shape[0]):\n",
    "    uid = df_test.loc[i][\"UID\"]\n",
    "    test_sentences.append(str(df_test.loc[i][\"Sent\"]).replace(\"\\n\", \" \"))\n",
    "print(\"Len of test set: {}\".format(len(test_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input_train_sentences.txt\", \"w\") as f:\n",
    "    for i in train_sentences:\n",
    "        f.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 input_train_sentences.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l input_train_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input_test_sentences.txt\", \"w\") as f:\n",
    "    for i in test_sentences:\n",
    "        f.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1505 input_test_sentences.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l input_test_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It extends this approach by introducing an additional separation of foreground and background in the image.\r\n",
      "Experimentally, the results are rather weak compared to pure model-free agents.\r\n",
      "The experiments are interesting but I'm still not completely convinced by the regression results in Figure 3, namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function.\r\n",
      "Section 2.2 says they do the latter in the interest of solving control-related tasks, but I’m not clear why this follows.\r\n",
      "4)This paper proposed an improved version of the AEC algorithm.\r\n",
      "Network sizes, learning rates, decay schedules, initialisations etc.\r\n",
      "4)evaluates different f within MCTS for MiniRTS.\r\n",
      "Because f is not good?\r\n",
      "The methods proposed here are not all too original, RAD was proposed by Li et al, distillation was proposed in Goodfellow et al's \"Explaining and harnessing adversarial examples\", stacked autoencoders were proposed by Szegedy et al's \"Intriguing Properties of Neural Networks\".\r\n",
      "Then, one has to carefully balance the approximation quality from one layer to the next and essentially union bound the results over all layers and all sampled points.\r\n",
      "Major Comments: I find the paper to not be lacking in exposition and clarity.\r\n",
      "Is there a reason SVAEs don’t meet all the desiderata mentioned at the end of the Introduction?\r\n",
      "5 sub-network are used to model pose, appearance, foreground, background, and decoders.\r\n",
      "Only the state-reconstruction error is shown now.\r\n",
      "The main contribution of the paper are the analytical derivative of the solution to the DARE.\r\n",
      "Their methods let the network focus more on the foreground to regress the landmark and improve state-of-the-art performance on landmark regression (unsupervised.\r\n",
      "2)why the video prediction only on KTH.\r\n",
      "After rereading I'm not sure I understand why the coordinates should be combined in a 3x3 checkerboard as said in Figure 5a.\r\n",
      "The paper: 1)describes how to train strong agents that might have learned an informative latent representation of the observed state-space.\r\n",
      "The paper proposes to use a pretrained model-free RL agent to extract the developed state representation and further re-use it for learning forward model of the environment and planning.\r\n",
      "It is unclear if the proposed techniques will perform provide improvements over a well-tuned baseline for some realistic tasks, or are they suitable only for toy problems.\r\n",
      "2)Section 3.3 (the 'additional' attack) is a interesting investigation.\r\n",
      "However, there are still lots of details missing for the training of the whole network even with the supplementary.\r\n",
      "- The analysis seems to be sound (apart from the issues discussed below) - The experimental results look promising, at least in the limited setup.\r\n",
      "Approximate inference is performed over these innovation variables, rather the states.\r\n",
      "Which forward model is trained from which model-free agent?\r\n",
      "The paper documents a series of experiments on making models robust against adversarial examples.\r\n",
      "5)are the learned landmark all unimodal?\r\n",
      "Doesn’t this support the argument about need in stochastic prediction?\r\n",
      "In the vein of recent work on learning “ticking” behaviour for LSTMs such as Phased LSTM, this paper proposes to add additional data independent gates to LSTM units that are defined as Gaussian functions of time indices.\r\n",
      "- The paper devotes a lot of space (sect 4.1) on details of learning and behavior of the model-free agents X.\r\n",
      "Although the final result about the defense methods is negative, its results are still inspiring.\r\n",
      "The idea of learning a model based on the features from a model-free agent seems novel but lacks significance in that the results are not very compelling (see below).\r\n",
      "This seems rather trivial to achieve.\r\n",
      "The idea of pre-stabilization is interesting, and seems related to this paper: [URL] **** After Author Response **** Thanks for the response, I am raising my score to weak accept.\r\n",
      "In all experiments, g-LSTM converges faster.\r\n",
      "Additionally, it is proposed that one can reduce the amount of computations performed by the network by adding a computation budget term to the optimized loss that encouraged the cells to update less often.\r\n",
      "I assume it's similar to what AlphaGo does, but right now it's not clear at all how everything is put together.\r\n",
      "A major advantage of the newly introduced Gaussian-gated LSTM (g-LSTM; I suggest using a capital G for Gauss, e.g., GgLSTM).\r\n",
      "Are the author exploring the phenomenon of retraining off one algorithm and then evaluating adversarial images derived on another?\r\n",
      "Too much components in the design make this work hard to follow.\r\n",
      "It would be great if you could provide some more details about the steps you took to verify that your internal baseline is indeed comparable to previous work (eg: Lorenz 2019).\r\n",
      "Overall, RAD and distillation have the best performances, but none of the methods can really resist the 'additional' attack from cg or adam.\r\n",
      "The paper establishes experimental evidence that the RAD framework provides the best defense mechanism against adversarial attacks which makes the introduction of the improved autoencoder mechanism less appealing.\r\n",
      "The testbed used is MiniRTS, a simulation environemnt for 1v1 RTS.\r\n",
      "H36M is also a video-based dataset.\r\n",
      "Since the main contribution of this paper seems to be evaluating the efficacy of RAD, AEC and IAEC, I would suggest that the authors provide more discussion and exposition.\r\n",
      "They use the latent state representation to learn a model for planning, which performs slightly better than a random baseline (win rate ~25%).\r\n",
      "The parametrization introduced in Phased LSTMs allows the memory cells and outputs of LSTMs to be updated periodically.\r\n",
      "Minor comments: Page 3: Equation (3) is also non-convex.\r\n",
      "As a step in this non-convex direction, this paper provides a nice investigation in the convex LTI case.\r\n",
      "1)what are the details of the color jitter process?\r\n",
      "- Interesting evaluation of which input features are important for the model-free algorithm, such as base HP ratio and the amount of resources available.\r\n",
      "Forecasting the future suffers from buildup / propagation of prediction errors, hence the paper uses multi-step errors to stabilize learning.\r\n",
      "cons: 1)The work was framed as an easier-to-optimize alternative to the time-based gating mechanism introduced in phased LSTMs, which takes a parametrization form that is much harder to learn, the gating mechanism covered by the new model gLSTM however, is much more limited.\r\n",
      "The experiments show interesting results on illustrative toy examples.\r\n",
      "The pre-stabilising controller reformulation is a neat trick.\r\n",
      "The paper shows how to use the Discrete-time Algebraic Riccati Equation (DARE) to provide infinite horizon stability & optimality to differentiable MPC learning.\r\n",
      "I also could find the details on how figure 1 was produced.\r\n",
      "all appear to be fixed, so one can not be sure of the “real” performance or convergence behavior of the models.\r\n",
      "So the non-convexity of Equation (2) should not be the motivation of Equation (3).\r\n",
      "It would be interesting to see if this can improve the results.\r\n",
      "3)Without further explanations and analyses about the experimental results, the contribution of the paper seems limited.\r\n",
      "The paper provides a theoretical characterization of the problem setting, which shows that prior work on differentiable MPC learning may lead to unstable controllers without the proposed augmentations using DARE.\r\n",
      "Can the authors elaborate?\r\n",
      "The performance of the modified g-LSTM is compared to LSTM on the Addition, sequential MNIST and sequential CIFAR-10 tasks.\r\n",
      "2)How is the forward model / value function used in MCTS?\r\n",
      "The implication in the abstract and introduction (at least as I interpreted it) is that the learned model would outperform a model-free method, but upon reading the rest of the paper I was disappointed to learn that in reality it drastically underperforms.\r\n",
      "The second concern is about the results on CelebA presented in Figure 6 in the Appendix: It looks like the background net reconstructs almost the entire image.\r\n",
      "I consider this to be a well-executed paper which brings together the main ideas from the coreset literature and shows one avenue of establishing provable results.\r\n",
      "It seems a bit odd that the foreground is so focused on the central part of the face.\r\n",
      "Their main result is stated as Theorem 4.\r\n",
      "The authors argue that g-LSTM results in better performance and has faster convergence on these tasks.\r\n",
      "- In Figure 3b, it is not clear to me what the difference between the red and blue curves is.\r\n",
      "It would be interesting to see the histogram/distribution of the weights per layer and at an aggregate level for the datasets used.\r\n",
      "Pro: - I commend the authors for a clean and polished writeup.\r\n",
      "The experiments are on toy examples, but show promise.\r\n",
      "For instance, on CelebA your baseline seems to fall short of Lorenz 2019, which may suggest that your substantial looking improvement on BBC Pose is indeed due to more favorable cropping.\r\n",
      "Is mini-RTS a deterministic environment?\r\n",
      "With this additional gate, the network can skip updating the states by closing the time-gate, as a result enabling longer memory persistence, and better gradient flow.\r\n",
      "This requires a much more thorough evaluation.\r\n",
      "Strengths: + Nicely motivates the approach of separating foreground and background + Fewer landmarks are needed than in previous work + Approach seems beneficial for video prediction + Clear and well written + Detailed description of architecture and training\r\n",
      "Weaknesses: - The changes and improvements feel somewhat incremental - Some uncertainty about the solidity of the evaluation/comparability with baselines Results on CelebA somewhat weak Overall the paper is well written, easy to follow, presents a straightforward extension of previous work and appears to show an improvement.\r\n",
      "gLSTMs on the other hand only allows updates within a single window over the entire sequence; As a result, one would expect phased LSTM to outperform gLSTM on tasks with periodical temporal dependencies;  2) The empirical results are not convincing enough.\r\n",
      "Detailed: - What are the right prediction tasks that ensure the latent space captures enough of the forward model?\r\n"
     ]
    }
   ],
   "source": [
    "!head -85 input_train_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read back the OpenIE6 triples data from txt files into dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/singh_shruti/workspace/meaningful_comparison/meaningful-comparison/mcomp_text_extraction'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy back files\n",
    "! cp ~/workspace/meaningful_comparison/openie6_from_lexico/openie6/mc_test_svo_predictions.txt ./\n",
    "! cp ~/workspace/meaningful_comparison/openie6_from_lexico/openie6/mc_train_svo_predictions.txt ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4418 mc_test_svo_predictions.txt\n",
      "878 mc_train_svo_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l mc_test_svo_predictions.txt\n",
    "!wc -l mc_train_svo_predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors propose to use k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting.\r\n",
      "0.90: (The authors; propose to use k-DPP to select; a set of diverse parameters)\r\n",
      "\r\n",
      "This paper covers the related work nicely, with details on both closed loop and open loop methods.\r\n",
      "0.51: (This paper; covers nicely,; the related work)\r\n",
      "\r\n",
      "The rest of the paper are also clearly written.\r\n",
      "0.58: (The rest of the paper; are also clearly written.; )\r\n",
      "\r\n",
      "However, I have some concerns about the proposed method.\r\n",
      "0.56: (I; have; some concerns about the proposed method.)\r\n",
      "\r\n",
      "- It is not clear how to define the kernel, the feature function and the quality function for the proposed method.\r\n",
      "0.28: (It; is not; clear how to define the)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -15 mc_test_svo_predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mc_train_svo_predictions.txt\", \"r\") as f:\n",
    "    train_triple_sents = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It extends this approach by introducing an additional separation of foreground and background in the image.\\n',\n",
       " '0.93: (It; extends; this approach)\\n',\n",
       " '\\n',\n",
       " 'Experimentally, the results are rather weak compared to pure model-free agents.\\n',\n",
       " '0.08: (the results; are; rather weak to pure agents.)\\n',\n",
       " '\\n',\n",
       " \"The experiments are interesting but I'm still not completely convinced by the regression results in Figure 3, namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function.\\n\",\n",
       " '0.89: (The experiments; are; interesting)\\n',\n",
       " '\\n',\n",
       " \"Section 2.2 says they do the latter in the interest of solving control-related tasks, but I'm not clear why this follows.\\n\",\n",
       " '0.80: (Section 2.2; says; they do the latter in the interest of solving control-related tasks,)\\n',\n",
       " '\\n',\n",
       " '4)This paper proposed an improved version of the AEC algorithm.\\n',\n",
       " '0.34: (paper; proposed; an improved version of the AEC algorithm.)\\n',\n",
       " '\\n',\n",
       " 'Network sizes, learning rates, decay schedules, initialisations etc.\\n',\n",
       " '0.77: (Network sizes,; learning; rates, decay schedules, initialisations etc.)\\n',\n",
       " '\\n',\n",
       " '4)evaluates different f within MCTS for MiniRTS.\\n',\n",
       " '\\n',\n",
       " 'Because f is not good?\\n']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triple_sents[0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It extends this approach by introducing an additional separation of foreground and background in the image.',\n",
       " 'Experimentally, the results are rather weak compared to pure model-free agents.',\n",
       " \"The experiments are interesting but I'm still not completely convinced by the regression results in Figure 3, namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function.\",\n",
       " 'Section 2.2 says they do the latter in the interest of solving control-related tasks, but I’m not clear why this follows.',\n",
       " '4)This paper proposed an improved version of the AEC algorithm.',\n",
       " 'Network sizes, learning rates, decay schedules, initialisations etc.',\n",
       " '4)evaluates different f within MCTS for MiniRTS.',\n",
       " 'Because f is not good?',\n",
       " 'The methods proposed here are not all too original, RAD was proposed by Li et al, distillation was proposed in Goodfellow et al\\'s \"Explaining and harnessing adversarial examples\", stacked autoencoders were proposed by Szegedy et al\\'s \"Intriguing Properties of Neural Networks\".',\n",
       " 'Then, one has to carefully balance the approximation quality from one layer to the next and essentially union bound the results over all layers and all sampled points.',\n",
       " 'Major Comments: I find the paper to not be lacking in exposition and clarity.',\n",
       " 'Is there a reason SVAEs don’t meet all the desiderata mentioned at the end of the Introduction?',\n",
       " '5 sub-network are used to model pose, appearance, foreground, background, and decoders.',\n",
       " 'Only the state-reconstruction error is shown now.',\n",
       " 'The main contribution of the paper are the analytical derivative of the solution to the DARE.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This requires a much more thorough evaluation.',\n",
       " 'Strengths: + Nicely motivates the approach of separating foreground and background + Fewer landmarks are needed than in previous work + Approach seems beneficial for video prediction + Clear and well written + Detailed description of architecture and training',\n",
       " 'Weaknesses: - The changes and improvements feel somewhat incremental - Some uncertainty about the solidity of the evaluation/comparability with baselines Results on CelebA somewhat weak Overall the paper is well written, easy to follow, presents a straightforward extension of previous work and appears to show an improvement.',\n",
       " 'gLSTMs on the other hand only allows updates within a single window over the entire sequence; As a result, one would expect phased LSTM to outperform gLSTM on tasks with periodical temporal dependencies;  2) The empirical results are not convincing enough.',\n",
       " 'Detailed: - What are the right prediction tasks that ensure the latent space captures enough of the forward model?']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[80:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Strengths: + Nicely motivates the approach of separating foreground and background + Fewer landmarks are needed than in previous work + Approach seems beneficial for video prediction + Clear and well written + Detailed description of architecture and training\\n',\n",
       " '0.67: (Fewer landmarks; are needed; than in previous work)\\n',\n",
       " '\\n',\n",
       " 'Strengths: + Nicely motivates the approach of separating foreground and background + Fewer landmarks are needed than in previous work + Approach seems beneficial for video prediction + Clear and well written + Detailed description of architecture and training\\n',\n",
       " '0.67: (Fewer landmarks; are needed; than in previous work)\\n',\n",
       " '\\n',\n",
       " 'Weaknesses: - The changes and improvements feel somewhat incremental - Some uncertainty about the solidity of the evaluation/comparability with baselines Results on CelebA somewhat weak Overall the paper is well written, easy to follow, presents a straightforward extension of previous work and appears to show an improvement.\\n']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triple_sents[238:245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "3 1\n",
      "6 2\n",
      "9 3\n",
      "12 4\n",
      "15 5\n",
      "18 6\n",
      "20 6\n",
      "20 7\n",
      "23 8\n",
      "26 9\n",
      "29 10\n",
      "32 11\n",
      "35 12\n",
      "38 13\n",
      "41 14\n",
      "44 15\n",
      "47 16\n",
      "49 16\n",
      "49 17\n",
      "52 18\n",
      "55 19\n",
      "58 20\n",
      "61 21\n",
      "64 22\n",
      "67 23\n",
      "70 24\n",
      "73 25\n",
      "76 26\n",
      "79 27\n",
      "81 27\n",
      "81 28\n",
      "84 29\n",
      "87 30\n",
      "90 31\n",
      "93 32\n",
      "96 33\n",
      "99 34\n",
      "102 35\n",
      "105 36\n",
      "108 37\n",
      "111 38\n",
      "114 39\n",
      "117 40\n",
      "120 41\n",
      "123 42\n",
      "126 43\n",
      "129 44\n",
      "132 45\n",
      "135 46\n",
      "138 47\n",
      "141 48\n",
      "144 49\n",
      "147 50\n",
      "150 51\n",
      "153 52\n",
      "156 53\n",
      "159 54\n",
      "162 55\n",
      "165 56\n",
      "168 57\n",
      "171 58\n",
      "174 59\n",
      "177 60\n",
      "180 61\n",
      "182 61\n",
      "182 62\n",
      "185 63\n",
      "188 64\n",
      "190 64\n",
      "190 65\n",
      "193 66\n",
      "196 67\n",
      "199 68\n",
      "202 69\n",
      "205 70\n",
      "208 71\n",
      "211 72\n",
      "214 73\n",
      "217 74\n",
      "220 75\n",
      "223 76\n",
      "226 77\n",
      "229 78\n",
      "232 79\n",
      "235 80\n",
      "238 81\n",
      "241 82\n",
      "241 83\n",
      "241 84\n",
      "241 85\n",
      "241 86\n",
      "241 87\n",
      "241 88\n",
      "241 89\n",
      "241 90\n",
      "241 91\n",
      "241 92\n",
      "241 93\n",
      "241 94\n",
      "241 95\n",
      "241 96\n",
      "241 97\n",
      "241 98\n",
      "241 99\n",
      "241 100\n",
      "241 101\n",
      "241 102\n",
      "241 103\n",
      "241 104\n",
      "241 105\n",
      "241 106\n",
      "241 107\n",
      "241 108\n",
      "241 109\n",
      "241 110\n",
      "241 111\n",
      "241 112\n",
      "241 113\n",
      "241 114\n",
      "241 115\n",
      "241 116\n",
      "241 117\n",
      "241 118\n",
      "241 119\n",
      "241 120\n",
      "241 121\n",
      "241 122\n",
      "241 123\n",
      "241 124\n",
      "241 125\n",
      "241 126\n",
      "241 127\n",
      "241 128\n",
      "241 129\n",
      "241 130\n",
      "241 131\n",
      "241 132\n",
      "241 133\n",
      "241 134\n",
      "241 135\n",
      "241 136\n",
      "241 137\n",
      "241 138\n",
      "241 139\n",
      "241 140\n",
      "241 141\n",
      "241 142\n",
      "241 143\n",
      "241 144\n",
      "241 145\n",
      "241 146\n",
      "241 147\n",
      "241 148\n",
      "241 149\n",
      "241 150\n",
      "241 151\n",
      "241 152\n",
      "241 153\n",
      "241 154\n",
      "241 155\n",
      "241 156\n",
      "241 157\n",
      "241 158\n",
      "241 159\n",
      "241 160\n",
      "241 161\n",
      "241 162\n",
      "241 163\n",
      "241 164\n",
      "241 165\n",
      "241 166\n",
      "241 167\n",
      "241 168\n",
      "241 169\n",
      "241 170\n",
      "241 171\n",
      "241 172\n",
      "241 173\n",
      "241 174\n",
      "241 175\n",
      "241 176\n",
      "241 177\n",
      "241 178\n",
      "241 179\n",
      "241 180\n",
      "241 181\n",
      "241 182\n",
      "241 183\n",
      "241 184\n",
      "241 185\n",
      "241 186\n",
      "241 187\n",
      "241 188\n",
      "241 189\n",
      "241 190\n",
      "241 191\n",
      "241 192\n",
      "241 193\n",
      "241 194\n",
      "241 195\n",
      "241 196\n",
      "241 197\n",
      "241 198\n",
      "241 199\n",
      "241 200\n",
      "241 201\n",
      "241 202\n",
      "241 203\n",
      "241 204\n",
      "241 205\n",
      "241 206\n",
      "241 207\n",
      "241 208\n",
      "241 209\n",
      "241 210\n",
      "241 211\n",
      "241 212\n",
      "241 213\n",
      "241 214\n",
      "241 215\n",
      "241 216\n",
      "241 217\n",
      "241 218\n",
      "241 219\n",
      "241 220\n",
      "241 221\n",
      "241 222\n",
      "241 223\n",
      "241 224\n",
      "241 225\n",
      "241 226\n",
      "241 227\n",
      "241 228\n",
      "241 229\n",
      "241 230\n",
      "241 231\n",
      "241 232\n",
      "241 233\n",
      "241 234\n",
      "241 235\n",
      "241 236\n",
      "241 237\n",
      "241 238\n",
      "241 239\n",
      "241 240\n",
      "241 241\n",
      "241 242\n",
      "241 243\n",
      "241 244\n",
      "241 245\n",
      "241 246\n",
      "241 247\n",
      "241 248\n",
      "241 249\n",
      "241 250\n",
      "241 251\n",
      "241 252\n",
      "241 253\n",
      "241 254\n",
      "241 255\n",
      "241 256\n",
      "241 257\n",
      "241 258\n",
      "241 259\n",
      "241 260\n",
      "241 261\n",
      "241 262\n",
      "241 263\n",
      "241 264\n",
      "241 265\n",
      "241 266\n",
      "241 267\n",
      "241 268\n",
      "241 269\n",
      "241 270\n",
      "241 271\n",
      "241 272\n",
      "241 273\n",
      "241 274\n",
      "241 275\n",
      "241 276\n",
      "241 277\n",
      "241 278\n",
      "241 279\n",
      "241 280\n",
      "241 281\n",
      "241 282\n",
      "241 283\n",
      "241 284\n",
      "241 285\n",
      "241 286\n",
      "241 287\n",
      "241 288\n",
      "241 289\n",
      "241 290\n",
      "241 291\n",
      "241 292\n",
      "241 293\n",
      "241 294\n",
      "241 295\n"
     ]
    }
   ],
   "source": [
    "triple_file_counter = 0\n",
    "train_sent_counter = 0\n",
    "\n",
    "train_sentid_triple_dict = {}\n",
    "\n",
    "while True:\n",
    "    print(triple_file_counter, train_sent_counter)\n",
    "    triple_sent = ''.join(ch for ch in train_triple_sents[triple_file_counter].strip() if ch.isalnum())\n",
    "    org_sent = ''.join(ch for ch in train_sentences[train_sent_counter].strip() if ch.isalnum())\n",
    "    if  triple_sent == org_sent:\n",
    "        if train_triple_sents[triple_file_counter+1] != \"\\n\":\n",
    "            train_sentid_triple_dict[train_sent_counter] = train_triple_sents[triple_file_counter+1][7:-2].split(\";\")\n",
    "            train_sent_counter += 1\n",
    "            triple_file_counter += 3\n",
    "        else:\n",
    "            triple_file_counter += 2\n",
    "        if triple_file_counter >= len(train_triple_sents):\n",
    "                break\n",
    "    else:\n",
    "        train_sent_counter += 1\n",
    "        if train_sent_counter >= len(train_sentences):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['It', ' extends', ' this approach'],\n",
       " 1: ['the results', ' are', ' rather weak to pure agents.'],\n",
       " 2: ['The experiments', ' are', ' interesting'],\n",
       " 3: ['Section 2.2',\n",
       "  ' says',\n",
       "  ' they do the latter in the interest of solving control-related tasks,'],\n",
       " 4: ['paper', ' proposed', ' an improved version of the AEC algorithm.'],\n",
       " 5: ['Network sizes,',\n",
       "  ' learning',\n",
       "  ' rates, decay schedules, initialisations etc.'],\n",
       " 7: ['Because f', ' is', ' not good?'],\n",
       " 8: ['The methods', ' proposed', ' here'],\n",
       " 9: ['one',\n",
       "  ' to carefully balance',\n",
       "  ' the approximation quality from one layer to the next and essentially union'],\n",
       " 10: ['I', ' find', ' the paper to not be lacking in exposition and clarity.'],\n",
       " 11: ['SVAEs',\n",
       "  \" don't meet\",\n",
       "  ' all the desiderata mentioned at the end of the Introduction?'],\n",
       " 12: ['5 sub-network',\n",
       "  ' are used',\n",
       "  ' to model pose, appearance, foreground, background, and decoders.'],\n",
       " 13: ['Only the state-reconstruction error', ' is shown', ' now.'],\n",
       " 14: ['The main contribution of the paper',\n",
       "  ' are',\n",
       "  ' the analytical derivative of the solution to the DARE.'],\n",
       " 15: ['Their methods', ' let', ' the network focus more on the foreground'],\n",
       " 17: ['the coordinates', ' should be combined', ' in a 3x3 checkerboard'],\n",
       " 18: ['strong agents',\n",
       "  ' might have learned',\n",
       "  ' an informative latent representation of the observed state-space.'],\n",
       " 19: ['The paper',\n",
       "  ' proposes to use',\n",
       "  ' a pretrained model-free RL agent to extract the developed state representation and further re-use it for learning forward model of the environment and planning.'],\n",
       " 20: ['the proposed techniques',\n",
       "  ' is will perform',\n",
       "  ' provide improvements over a well-tuned baseline for some realistic tasks,'],\n",
       " 21: ['2)Section 3.3', ' is', ' a interesting investigation.'],\n",
       " 22: ['lots details',\n",
       "  ' missing',\n",
       "  ' for the training of the whole network even with the supplementary.'],\n",
       " 23: ['The experimental results',\n",
       "  ' look',\n",
       "  ' promising, at least in the limited setup.'],\n",
       " 24: ['Approximate inference',\n",
       "  ' is performed',\n",
       "  ' over these innovation variables,'],\n",
       " 25: ['Which forward model', ' is trained', ' from which model-free agent?'],\n",
       " 26: ['The paper',\n",
       "  ' documents',\n",
       "  ' a series of experiments on making models robust against adversarial examples.'],\n",
       " 28: ['this',\n",
       "  \" Doesn't support\",\n",
       "  ' the argument about need in stochastic prediction?'],\n",
       " 29: ['this paper',\n",
       "  ' proposes to add',\n",
       "  ' additional data independent gates to LSTM units'],\n",
       " 30: ['The paper', ' devotes', ' a lot of space'],\n",
       " 31: ['its results', ' are', ' still inspiring.'],\n",
       " 32: ['a model', ' based', ' on the features from a model-free agent'],\n",
       " 33: ['This', ' seems', ' rather trivial to achieve.'],\n",
       " 34: ['The idea of pre-stabilization', ' seems', ' related to this paper:'],\n",
       " 35: ['g-LSTM', ' converges faster.', ' In all experiments,'],\n",
       " 36: ['the optimized loss the cells', ' encouraged', ' to update less often.'],\n",
       " 37: ['I',\n",
       "  ' assume',\n",
       "  \" it's similar to what AlphaGo does, but right now it's not clear at\"],\n",
       " 38: ['I', ' suggest', ' using a capital G for Gauss, e.g.,'],\n",
       " 39: ['adversarial images', ' derived', ' on another?'],\n",
       " 40: ['Too much components in the design',\n",
       "  ' make',\n",
       "  ' this work hard to follow.'],\n",
       " 41: ['you', ' could provide', ' some more details about the steps'],\n",
       " 42: ['none of the methods',\n",
       "  ' can really resist',\n",
       "  \" the 'additional' attack from cg or adam.\"],\n",
       " 43: ['The paper',\n",
       "  ' establishes',\n",
       "  ' experimental evidence that the RAD framework provides the best defense mechanism against adversarial attacks'],\n",
       " 44: ['The testbed', ' used', ' '],\n",
       " 45: ['H36M', ' is also', ' a video-based dataset.'],\n",
       " 46: ['the main contribution of this paper', ' seems', ' '],\n",
       " 47: ['They',\n",
       "  ' use the latent state representation to learn',\n",
       "  ' a model for planning, which performs slightly better than a random baseline (win rate ~25%).'],\n",
       " 48: ['The parametrization', ' introduced', ' in Phased LSTMs'],\n",
       " 49: ['Page 3: Equation', ' is also', ' non-convex.'],\n",
       " 50: ['this paper',\n",
       "  ' provides',\n",
       "  ' a nice investigation in the convex LTI case.'],\n",
       " 51: ['1)what', ' are', ' the details of the color jitter process?'],\n",
       " 52: ['input features',\n",
       "  ' are',\n",
       "  ' important for the model-free algorithm, such as base HP ratio and the amount of resources available.'],\n",
       " 53: ['the paper', ' uses', ' multi-step errors to stabilize learning.'],\n",
       " 54: ['work',\n",
       "  ' was framed',\n",
       "  ' as an easier-to-optimize alternative to the time-based gating mechanism in phased LSTMs,'],\n",
       " 55: ['The experiments',\n",
       "  ' show',\n",
       "  ' interesting results on illustrative toy examples.'],\n",
       " 56: ['The pre-stabilising controller reformulation', ' is', ' a neat trick.'],\n",
       " 57: ['The paper', ' to use', ' the Discrete-time Algebraic Riccati Equation'],\n",
       " 58: ['I', ' could find', ' the details on how figure 1 was produced.'],\n",
       " 59: ['all', ' appear', ' '],\n",
       " 60: ['the non-convexity of Equation (2)',\n",
       "  ' should not be',\n",
       "  ' the motivation of Equation'],\n",
       " 62: ['the contribution of the paper', ' seems', ' limited.'],\n",
       " 63: ['prior work on differentiable MPC learning',\n",
       "  ' may lead',\n",
       "  ' to unstable controllers'],\n",
       " 65: ['The performance of the modified g-LSTM',\n",
       "  ' is compared',\n",
       "  ' to LSTM on the Addition,'],\n",
       " 66: ['the forward value function', ' used', ' in MCTS?'],\n",
       " 67: ['I',\n",
       "  ' was',\n",
       "  ' disappointed to learn that in reality it drastically underperforms.'],\n",
       " 68: ['The second concern', ' is', ' about the results on CelebA'],\n",
       " 69: ['I', ' consider', ' this to be a well-executed paper'],\n",
       " 70: ['the foreground', ' is so focused', ' on the central part of the face.'],\n",
       " 71: ['Their main result', ' is stated', ' as Theorem 4.'],\n",
       " 72: ['The authors',\n",
       "  ' argue',\n",
       "  ' that g-LSTM results in better performance and has faster convergence on these tasks.'],\n",
       " 73: ['the difference between the red and blue curves', ' is.', ' '],\n",
       " 74: ['the datasets', ' used.', ' '],\n",
       " 75: ['I', ' commend', ' the authors for a polished writeup.'],\n",
       " 76: ['The experiments', ' show', ' promise.'],\n",
       " 77: ['your baseline', ' seems', ' on CelebA'],\n",
       " 78: ['mini-RTS', ' Is', ' a deterministic environment?'],\n",
       " 79: ['the network',\n",
       "  ' can skip',\n",
       "  ' updating the states by closing the time-gate, as a result'],\n",
       " 80: ['This', ' requires', ' a much more thorough evaluation.'],\n",
       " 81: ['Fewer landmarks', ' are needed', ' than in previous work']}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentid_triple_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"0.58: (The rest of the paper; are also clearly written.; )\\n\"\n",
    "s1 = \"0.58: (The rest of the paper; ;best way )\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The rest of the paper', ' are also clearly written.', ' '],\n",
       " ['The rest of the paper', ' ', 'best way '])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[7:-2].split(\";\"), s1[7:-2].split(\";\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
