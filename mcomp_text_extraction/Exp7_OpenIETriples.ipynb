{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.txt.oie\", \"r\") as f:\n",
    "    l = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6633\n"
     ]
    }
   ],
   "source": [
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The authors propose to use k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting.\\n',\n",
       " '0.89: (The authors; propose; to use k-DPP and use them to search for a good a hyperparameter setting.)\\n',\n",
       " '0.00: (The authors; propose to use; k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting.)\\n',\n",
       " '0.72: (The authors; propose to use k-DPP to select; a set of diverse parameters)\\n',\n",
       " '0.00: (The authors; use; them to search for a good a hyperparameter setting.)\\n',\n",
       " '\\n',\n",
       " 'This paper covers the related work nicely, with details on both closed loop and open loop methods.\\n',\n",
       " '1.00: (This paper; covers nicely,; the related work)\\n',\n",
       " '\\n',\n",
       " 'The rest of the paper are also clearly written.\\n',\n",
       " '0.99: (The rest of the paper; are also clearly written.; )\\n',\n",
       " '\\n',\n",
       " 'However, I have some concerns about the proposed method.\\n',\n",
       " '1.00: (I; have; some concerns about the proposed method.)\\n',\n",
       " '\\n',\n",
       " '- It is not clear how to define the kernel, the feature function and the quality function for the proposed method.\\n',\n",
       " '0.99: (It; is not; clear how)\\n',\n",
       " '\\n',\n",
       " 'The choices of those seem to have a huge impact on the performance.\\n',\n",
       " '1.00: (The choices of those; seem; )\\n',\n",
       " '1.00: (The choices of those; to have; a huge impact on the performance.)\\n',\n",
       " '\\n',\n",
       " 'How was those functions decided and how sensitive is the result to hyperparameters of those functions?\\n',\n",
       " '0.99: (those functions how sensitive; is; the result to hyperparameters of those functions?)\\n',\n",
       " '\\n',\n",
       " '- If the search space is continuous, what is the mixing rate of Algorithm 2?\\n',\n",
       " '1.00: (the search space; is; continuous,)\\n',\n",
       " '\\n',\n",
       " 'In practice, how is \"mixed\" decided?\\n',\n",
       " '0.96: (how \"mixed\"; is decided?; )\\n',\n",
       " '\\n',\n",
       " 'What exactly is the space and time complexity?\\n',\n",
       " '0.99: (What exactly; is; the space and time complexity?)\\n',\n",
       " '\\n',\n",
       " \"I'm not sure where k log(N) comes from in page 7)\\n\",\n",
       " \"1.00: (I'm; not; sure where k log(N) comes from in page 7))\\n\",\n",
       " '0.97: (k log(N); comes; from in page 7))\\n',\n",
       " '\\n',\n",
       " '- Algorithm 2 is a straight forward extension of Algorithm 1, just with L not explicitly computed.\\n',\n",
       " '1.00: (Algorithm 2; is; a straight forward extension of Algorithm 1,)\\n',\n",
       " '0.00: (just with L; not explicitly computed.; )\\n',\n",
       " '\\n',\n",
       " 'I think it would have more novelty if some theoretical analyses can be shown on the mixing rate and how good this optimization algorithm is.\\n',\n",
       " '0.92: (some theoretical analyses; can be shown; on the mixing rate and)\\n',\n",
       " '0.87: (this optimization algorithm; is.; how good)\\n',\n",
       " '1.00: (I; think; it would have more novelty if some theoretical analyses can be shown on the mixing rate and how good this optimization algorithm is.)\\n',\n",
       " '1.00: (it; would have; more novelty)\\n',\n",
       " '\\n',\n",
       " 'Other small things:\\n',\n",
       " '\\n',\n",
       " '- citation format problems in, for example, Section 4.1) It should be \\\\citep instead of \\\\cite.\\n',\n",
       " '0.95: (Section 4.1) It; should be; \\\\citep instead of \\\\cite.)\\n',\n",
       " '\\n',\n",
       " '- it would be good to mention Figure 2 in the text first before showing it.\\n',\n",
       " '\\n',\n",
       " '[Post rebuttal]\\n',\n",
       " '\\n',\n",
       " 'I would like to thank the authors for their clarifications.\\n',\n",
       " '1.00: (I; would like; to thank the authors for their clarifications.)\\n',\n",
       " '1.00: (I; would like to thank; the authors for their clarifications.)\\n',\n",
       " '\\n',\n",
       " 'However, I am still concerned with the novelty.\\n',\n",
       " '1.00: (I; am; still concerned with the novelty.)\\n',\n",
       " '\\n',\n",
       " 'The absence of provable mixing rate is also a potential weakness.\\n',\n",
       " '1.00: (The absence of provable mixing rate; is also; a potential weakness.)\\n',\n",
       " '\\n',\n",
       " 'I think a clearer emphasis on the novelty, eg: current algorithm with mixing rate analyses or more thorough empirical comparisons will make the paper stronger for resubmission.\\n',\n",
       " '0.48: (I current algorithm with mixing rate analyses or more thorough empirical comparisons; think will make; a clearer emphasis on the novelty, the paper stronger for resubmission.)\\n',\n",
       " '0.36: (I current algorithm with mixing rate analyses or more thorough empirical comparisons; think; a clearer emphasis on the novelty, eg: the paper stronger for resubmission.)\\n',\n",
       " '\\n',\n",
       " 'I reviewed the same paper last year.\\n',\n",
       " '1.00: (I; reviewed; the same paper last year.)\\n',\n",
       " '\\n',\n",
       " 'I am appending a few lines based on the changes made by authors.\\n',\n",
       " '1.00: (I; am appending; a few lines based on the changes)\\n',\n",
       " '1.00: (a few lines; based; on the changes)\\n',\n",
       " '1.00: (the changes; made; by authors.)\\n',\n",
       " '\\n',\n",
       " 'The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\\n',\n",
       " '0.93: (The authors; propose; k-DPP as an open loop)\\n',\n",
       " '0.03: (The authors; k-DPP provide; its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra)\\n',\n",
       " '0.11: (uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization; using; tree-structured Parzen estimator))\\n',\n",
       " '\\n',\n",
       " 'The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new, so the main contribution here is the empirical study.\\n',\n",
       " '1.00: (The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters; are not; new,)\\n',\n",
       " '1.00: (the main contribution here; is; the empirical study.)\\n',\n",
       " '\\n',\n",
       " 'The first experiment by the authors shows that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner (Figure 1).\\n',\n",
       " '0.20: (The first experiment by the authors; shows; that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner)\\n',\n",
       " '0.39: (k-DPP-RBF; gives; better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner)\\n',\n",
       " '\\n',\n",
       " 'The second experiment shows surprisingly that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Figure 2, column 1).\\n',\n",
       " '0.62: (The second experiment; shows surprisingly; that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Figure)\\n',\n",
       " '0.86: (k-DPP-RBF; performs better; for than uniform random search, and moreover, both of these outperform BO-TPE (Figure 2, column 1).)\\n',\n",
       " '\\n',\n",
       " 'The third experiment shows that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.\\n',\n",
       " '0.99: (The third experiment; shows; that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.)\\n',\n",
       " '0.98: (k-DPP-RBF and its discrete analog; slightly outperform respectively.; uniform random search and its discrete analog, on good or stable ranges,)\\n',\n",
       " '\\n',\n",
       " 'I have a few reservations.\\n',\n",
       " '1.00: (I; have; a few reservations.)\\n',\n",
       " '\\n',\n",
       " 'First, I do not find these outcomes very surprising or informative, except for the second experiment (Figure 2, column 1).\\n',\n",
       " '0.95: (I; do not find; these outcomes very surprising or informative, except for the second experiment First,)\\n',\n",
       " '\\n',\n",
       " 'Second, their study only applies to a small number like 3-6 hyperparameters with a small k=20) The real challenge lies in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al (http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf) and Snoek et al (https://arxiv.org/pdf/1502.05700.pdf) that is essential for this kind of empirical study.\\n',\n",
       " '0.16: (the authors; do not compare is; against some relevant, recent work, e.g., essential for this kind of empirical study.)\\n',\n",
       " '0.63: (their study The real challenge; only applies; to a small number like 3-6 hyperparameters with a small k=20) in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third,)\\n',\n",
       " '0.04: (their study The real challenge; only applies lies; to a small number like 3-6 hyperparameters with a small k=20) in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third,)\\n',\n",
       " '\\n',\n",
       " 'COMMENTS ON THE CHANGES SINCE THE LAST YEAR\\n',\n",
       " '\\n',\n",
       " 'I am not convinced by the comparison with Spearmint added by the authors since the previous version.\\n',\n",
       " '1.00: (I; am not convinced; by the comparison with Spearmint)\\n',\n",
       " '0.69: (the comparison with Spearmint; added; by the authors since the previous version.)\\n',\n",
       " '\\n',\n",
       " 'It is unclear to me if the comparison of wall clock time and accuracy holds for larger number of hyperparameters or against Spearmint with more parallelization.\\n',\n",
       " '0.92: (It and; is; unclear to me)\\n',\n",
       " '0.98: (the comparison of wall clock time and accuracy; holds; for larger number of hyperparameters or against Spearmint with more parallelization.)\\n',\n",
       " '\\n',\n",
       " 'In addition the authors do not compare against more recent work, e.g.,\\n',\n",
       " '0.94: (the authors; do not compare e.g.,; against more recent work,)\\n',\n",
       " '\\n',\n",
       " '@INPROCEEDINGS{falkner-bayesopt17,\\n',\n",
       " '\\n',\n",
       " 'author = {S. Falkner and A. Klein and F. Hutter},\\n',\n",
       " '\\n',\n",
       " 'title = {Combining Hyperband and Bayesian Optimization},\\n',\n",
       " '\\n',\n",
       " 'booktitle = {NIPS 2017 Bayesian Optimization Workshop},\\n',\n",
       " '\\n',\n",
       " 'year = {2017},\\n',\n",
       " '\\n',\n",
       " 'month = dec,\\n',\n",
       " '\\n',\n",
       " '}\\n',\n",
       " '\\n',\n",
       " '@InProceedings{falkner-icml-18,\\n',\n",
       " '\\n',\n",
       " 'title = {{BOHB}: Robust and Efficient Hyperparameter Optimization at Scale},\\n',\n",
       " '\\n',\n",
       " 'author = {Falkner, Stefan and Klein, Aaron and Hutter, Frank},\\n',\n",
       " '\\n',\n",
       " 'booktitle = {Proceedings of the 35th International Conference on Machine Learning (ICML 2018)},\\n',\n",
       " '\\n',\n",
       " 'pages = {1436--1445},\\n',\n",
       " '0.98: (pages; =; )\\n',\n",
       " '\\n',\n",
       " 'year = {2018},\\n',\n",
       " '\\n',\n",
       " 'month = jul,\\n',\n",
       " '0.93: (month; =; jul,)\\n',\n",
       " '\\n',\n",
       " '- This paper proposes an approach to get samples with high dispersion for hyperparameter optimisation.\\n',\n",
       " '1.00: (This paper; proposes; an approach to get samples with high dispersion for hyperparameter optimisation.)\\n',\n",
       " '\\n',\n",
       " '- It theoretically motivates the use of Determinantal Point Processes in yielding such samples.\\n',\n",
       " '1.00: (It; theoretically motivates; the use of Determinantal Point Processes in yielding such samples.)\\n',\n",
       " '\\n',\n",
       " '- Further, an iterative mixing algorithm is proposed to handle continuous and discrete sample space.\\n',\n",
       " '1.00: (an iterative mixing algorithm; is proposed; )\\n',\n",
       " '1.00: (an iterative mixing algorithm; to handle; continuous and discrete sample space.)\\n',\n",
       " '\\n',\n",
       " '- Experiments on finding hyperparameter for sentence classification are presented.\\n',\n",
       " '0.99: (Experiments on finding hyperparameter for sentence classification; are presented.; )\\n',\n",
       " '\\n',\n",
       " 'In terms of accuracy, it performs better than other open-loop methods.\\n',\n",
       " '0.96: (it; performs better; than other open-loop methods. of accuracy,)\\n',\n",
       " '\\n',\n",
       " 'In comparison to closed-loop methods, it yields parameter settings with comparable performance but with gains in wall clock time.\\n',\n",
       " '1.00: (it; yields; parameter settings In comparison to closed-loop methods,)\\n',\n",
       " '\\n',\n",
       " '- The distinction from close-loop approaches makes it easy to parallelise.\\n',\n",
       " '1.00: (The distinction from close-loop approaches; makes; it easy to parallelise.)\\n',\n",
       " '\\n',\n",
       " 'This paper is novel in its modelling of hyperparameter optimisation with DPP and the theoretical justification and experiments have been clearly presented.\\n',\n",
       " '0.63: (This paper; is; novel in its modelling of hyperparameter optimisation with DPP and the theoretical justification and experiments)\\n',\n",
       " '0.52: (This paper; have been clearly presented.; )\\n',\n",
       " '\\n',\n",
       " 'It would be interesting to explore the practicability of the method on more large-scale experiments on image related tasks.\\n',\n",
       " '0.00: (It interesting; to; explore the practicability of the method on more large-scale experiments on image related tasks.)\\n',\n",
       " '\\n',\n",
       " 'The proposed regularizer seems to be a particular combination of existing methods.\\n',\n",
       " '1.00: (The proposed regularizer; seems; )\\n',\n",
       " '1.00: (The proposed regularizer; to be; a particular combination of existing methods.)\\n',\n",
       " '\\n',\n",
       " 'Though the implied connection between nonlinearities and stochastic regularizers is intriguing, in my opinion the empirical performance does not exceed the performance achieved by similar methods by a large enough margin to arrive at a meaningful conclusion.\\n',\n",
       " '1.00: (the implied connection between nonlinearities and stochastic regularizers; is; intriguing,)\\n',\n",
       " '0.47: (the empirical performance; does not exceed; the performance achieved by similar methods by a large enough margin to arrive at a meaningful conclusion. in my opinion)\\n',\n",
       " '0.98: (the performance; achieved; by similar methods by a large enough margin)\\n',\n",
       " '0.53: (the performance achieved by similar methods by a large enough margin; to arrive; at a meaningful conclusion.)\\n',\n",
       " '\\n',\n",
       " 'The method proposed essential trains neural networks without a traditional nonlinearity, using multiplicative gating by the CDF of a Gaussian evaluated at the preactivation; this is motivated as a relaxation of a probit-Bernoulli stochastic gate.\\n',\n",
       " '0.80: (a Gaussian this; evaluated motivated; at the preactivation; as a relaxation of a probit-Bernoulli stochastic gate.)\\n',\n",
       " '0.01: (The method this; proposed is; essential trains neural networks multiplicative gating by the CDF of as a relaxation of a probit-Bernoulli stochastic gate.)\\n',\n",
       " '0.03: (The method; proposed essential trains neural using; networks multiplicative gating by the CDF of a Gaussian)\\n',\n",
       " '\\n',\n",
       " 'Experiments are performed with both.\\n',\n",
       " '1.00: (Experiments; are performed; with both.)\\n',\n",
       " '\\n',\n",
       " 'The work is somewhat novel and interesting.\\n',\n",
       " '1.00: (The work; is; somewhat novel and interesting.)\\n',\n",
       " '\\n',\n",
       " 'Little is said about why this is preferable to other similar parameterizations of the same (sigmoidal?\\n',\n",
       " '0.99: (Little; is said; about why this is preferable to other similar parameterizations of the same (sigmoidal?)\\n',\n",
       " '0.95: (this; is; preferable to other similar parameterizations of the same (sigmoidal?)\\n',\n",
       " '\\n',\n",
       " 'softsign?\\n',\n",
       " '\\n',\n",
       " 'etc.)\\n',\n",
       " '\\n',\n",
       " 'It would be stronger with more empirical interrogation of why this works and exploration of the nearby conceptual space.\\n',\n",
       " '1.00: (It; would be; stronger with more empirical interrogation of why this works and exploration of the nearby conceptual space.)\\n',\n",
       " '1.00: (this; works; )\\n',\n",
       " '\\n',\n",
       " \"The CIFAR results look okay by today's standards but the MNIST results are quite bad, neural nets were doing better than 1.5% a decade ago and the SOI map results (and the ReLU baseline) are above 2%.\\n\",\n",
       " '0.96: (CIFAR the MNIST results; are; quite bad,)\\n',\n",
       " '0.83: (the SOI map results (and the ReLU baseline); are; above 2%.)\\n',\n",
       " '0.28: (neural nets; were doing; better than 1.5% baseline) above 2%. a decade ago)\\n',\n",
       " '0.97: (The CIFAR results; look okay; )\\n',\n",
       " '\\n',\n",
       " \"(TIMIT results on frame classification also aren't that interesting without evaluating word error rate within a speech pipeline, but this is a minor point.)\\n\",\n",
       " \"0.98: (results on frame classification; also aren't; that interesting)\\n\",\n",
       " '1.00: (this; is; a minor point.))\\n',\n",
       " '\\n',\n",
       " 'The idea put forth that SOI map networks without additional nonlinearities are comparable to linear functions is rather misleading as they are, in expectation, nonlinear functions of their input.\\n',\n",
       " '0.95: (The idea; put; forth)\\n',\n",
       " '0.66: (SOI map networks without additional nonlinearities; are; comparable to linear functions)\\n',\n",
       " '0.12: (The idea put forth that SOI map networks without additional nonlinearities are comparable to linear functions; is; rather misleading as they are, in expectation, nonlinear functions of their input.)\\n',\n",
       " '0.94: (they; are,; )\\n',\n",
       " '\\n',\n",
       " 'Varying an input example by multiplying or adding a constant will not be linearly reflected in the expected output of the network.\\n',\n",
       " '0.28: (Varying an input example by multiplying or adding a constant; will not be linearly reflected; in the expected output of the network.)\\n',\n",
       " '\\n',\n",
       " 'In this sense they are more nonlinear than ReLU networks which are at least locally linear.\\n',\n",
       " '1.00: (they; are; more nonlinear than ReLU networks In this sense)\\n',\n",
       " '1.00: (ReLU networks; are; at least locally linear.)\\n',\n",
       " '\\n',\n",
       " 'The plots are very difficult to read in grayscale,\\n',\n",
       " '1.00: (The plots; are; very difficult to read in grayscale,)\\n',\n",
       " '0.76: (plots; to read; grayscale,)\\n',\n",
       " '\\n',\n",
       " 'Approaches like adaptive dropout also have the binary mask as a function of input to a neuron very similar to the proposed approach.\\n',\n",
       " '1.00: (Approaches like adaptive dropout; have; the binary mask as a function of input to a neuron very similar to the proposed approach.)\\n',\n",
       " '\\n',\n",
       " 'It is not clear, even from the new draft, how the proposed approach differs to Adaptive dropout in terms of functionality.\\n',\n",
       " '0.92: (It; is not; clear, even from the new draft,)\\n',\n",
       " '0.62: (the proposed approach; differs; to Adaptive dropout)\\n',\n",
       " '\\n',\n",
       " 'The experimental validation is also not extensive since comparison to SOTA is not included.\\n',\n",
       " '0.00: (The experimental validation; is also not; extensive since comparison to SOTA is not included.)\\n',\n",
       " '1.00: (comparison to SOTA; is not included.; )\\n',\n",
       " '\\n',\n",
       " 'This paper proposed an effective defense against model stealing attacks.\\n',\n",
       " '0.98: (This paper; proposed; an effective defense against model stealing)\\n',\n",
       " '1.00: (model; stealing; attacks.)\\n',\n",
       " '\\n',\n",
       " 'Merits:\\n',\n",
       " '\\n',\n",
       " '1) In general, this paper is well written and easy to follow.\\n',\n",
       " '0.91: (this paper; is; well written and easy to follow. In general,)\\n',\n",
       " '0.76: (this paper; written to follow.; )\\n',\n",
       " '\\n',\n",
       " '2) The approach is a significant supplement to existing defense against model stealing attacks.\\n',\n",
       " '0.98: (The approach; is; a significant supplement to existing defense against model stealing attacks.)\\n',\n",
       " '1.00: (model; stealing; attacks.)\\n',\n",
       " '\\n',\n",
       " '3) Extensive experiments.\\n',\n",
       " '\\n',\n",
       " 'However, I still have concerns about the current version.\\n',\n",
       " '1.00: (I; have; concerns about the current version. still)\\n',\n",
       " '\\n',\n",
       " \"I will possibly adjust my score based on the authors' response.\\n\",\n",
       " \"1.00: (I; will possibly adjust; my score based on the authors' response.)\\n\",\n",
       " \"1.00: (my score; based; on the authors' response.)\\n\",\n",
       " '\\n',\n",
       " '1) In the model stealing setting, attacker and defender are seemingly knowledge limited.\\n',\n",
       " '1.00: (the model; stealing; setting,)\\n',\n",
       " '0.00: (1) attacker and defender; are seemingly; knowledge limited. In the model stealing setting,)\\n',\n",
       " '\\n',\n",
       " 'This should be clarified better in Section 3) It is important to highlight that the defender has no access to F_A, thus problem (4) is a black-box optimization problem for defense.\\n',\n",
       " '0.44: (This thus problem; be better; a black-box for defense.)\\n',\n",
       " '0.45: (thus problem (4); should is; in Section 3) a black-box optimization problem for defense.)\\n',\n",
       " '\\n',\n",
       " 'Also, it is better to have a table to summarize the notations.\\n',\n",
       " '0.89: (a table; to summarize; have the notations.)\\n',\n",
       " '\\n',\n",
       " 'Additional questions on problem formulation:\\n',\n",
       " '\\n',\n",
       " 'a) Problem (4) only relies on the transfer set, where $x \\\\sim P_A(x)$, right?\\n',\n",
       " '0.99: (Problem (4); only relies; on the transfer set,)\\n',\n",
       " '\\n',\n",
       " 'b) For evaluation metrics, utility and non-replicability, do they have the same D^{test}?\\n',\n",
       " '1.00: (they; have; the same D^{test}?)\\n',\n",
       " '\\n',\n",
       " 'How to determine them, in particularly for F_A?\\n',\n",
       " '0.86: (How; to determine; them, in particularly for F_A?)\\n',\n",
       " '\\n',\n",
       " 'c) One utility constraint is missing in problem (4).\\n',\n",
       " '0.98: (One utility constraint; is missing; in problem (4).)\\n',\n",
       " '\\n',\n",
       " 'I noticed that it was mentioned in MAD-argmax, however, I suggest to add it to the formulation (4).\\n',\n",
       " '0.92: (it I; suggest; MAD-argmax, to add it to the formulation)\\n',\n",
       " '0.96: (I; noticed; that it was mentioned in MAD-argmax, however,)\\n',\n",
       " '1.00: (it; was mentioned; in MAD-argmax,)\\n',\n",
       " '0.00: (I; suggest to add; it to the formulation (4).)\\n',\n",
       " '\\n',\n",
       " '2) The details of heuristic solver are unclear.\\n',\n",
       " '0.97: (2) The details of heuristic solver; are; unclear.)\\n',\n",
       " '\\n',\n",
       " 'Although the authors pointed out the pseudocode in the appendix, it lacks detailed analysis.\\n',\n",
       " '0.97: (the authors; pointed out; the pseudocode in the appendix,)\\n',\n",
       " '1.00: (it; lacks; detailed analysis.)\\n',\n",
       " '\\n',\n",
       " '3) In Estimating G, how to select the surrogate model?\\n',\n",
       " '0.93: (3) G,; to select; the surrogate model? In Estimating)\\n',\n",
       " '\\n',\n",
       " 'Moreover, in the experiment, the authors mentioned that defense performances are unaffected by choice of architectures, and hence use the victim architecture for the stolen model.\\n',\n",
       " '0.96: (defense performances; hence use; the victim architecture for the stolen model.)\\n',\n",
       " '1.00: (the authors; mentioned; that defense performances are unaffected by choice of architectures, and hence use the victim architecture for the stolen model. in the experiment,)\\n',\n",
       " '1.00: (defense performances; are; unaffected by choice of architectures,)\\n',\n",
       " '\\n',\n",
       " 'If possible, could the author provide results on different architecture choices for the stolen model as well as the surrogate model?\\n',\n",
       " '0.99: (the author; provide; results on different architecture choices for the stolen model as well as the surrogate model?)\\n',\n",
       " '\\n',\n",
       " '############## Post-feedback ################\\n',\n",
       " '\\n',\n",
       " \"I am satisfied with the authors' response.\\n\",\n",
       " \"1.00: (I; am; satisfied with the authors' response.)\\n\",\n",
       " '\\n',\n",
       " 'Thus, I would like to keep my positive comments on this paper.\\n',\n",
       " '1.00: (I; would like; to keep my positive comments on this paper.)\\n',\n",
       " '1.00: (I; would like to keep; my positive comments on this paper.)\\n',\n",
       " '\\n',\n",
       " 'Although the paper is between 6 and 8, I finally decide to increase my score to 8 due to its novelty in formulation and extensive experiments.\\n',\n",
       " '1.00: (the paper; is; between 6 and 8,)\\n',\n",
       " '1.00: (I; decide; to increase my score to 8 due to its novelty in formulation and extensive experiments. finally)\\n',\n",
       " '0.08: (I; decide to increase; my score to 8 due to its novelty in formulation and extensive experiments.)\\n',\n",
       " '\\n',\n",
       " 'The paper proposes a new method for defending against stealing attacks.\\n',\n",
       " '1.00: (The paper; proposes; a new method for defending against stealing attacks.)\\n',\n",
       " '\\n',\n",
       " 'Positives:\\n',\n",
       " '\\n',\n",
       " '1) The paper was very readable and clear.\\n',\n",
       " '1.00: (The paper; was; very readable and clear.)\\n',\n",
       " '\\n',\n",
       " '2) The proposed method is straightforward and well motivated.\\n',\n",
       " '1.00: (The proposed method; is; straightforward and well motivated.)\\n',\n",
       " '0.95: (The proposed method; well motivated.; )\\n',\n",
       " '\\n',\n",
       " '3) The authors included a good amount of experimental results.\\n',\n",
       " '1.00: (The authors; included; a good amount of experimental results.)\\n',\n",
       " '\\n',\n",
       " 'Concerns:\\n',\n",
       " '\\n',\n",
       " '1) You note that the random perturbation to the outputs performs poorly compared to your method, but this performance gap seems to decrease as the dataset becomes more difficult (ie CIFAR100).\\n',\n",
       " '0.42: (this performance gap; seems; the becomes more difficult (ie CIFAR100).)\\n',\n",
       " '0.91: (the dataset; to decrease becomes; as more difficult (ie CIFAR100).)\\n',\n",
       " '0.83: (You; note; that the random perturbation to the outputs performs poorly compared to your method, but this performance gap seems to decrease)\\n',\n",
       " '0.91: (the random perturbation to the outputs; performs poorly compared; to your method,)\\n',\n",
       " '0.41: (this performance gap; seems; )\\n',\n",
       " '\\n',\n",
       " \"I'm concerned that this may indicate that the attackers are generally weak and this threat model may not be very serious.\\n\",\n",
       " '0.99: (this threat model; may not be; very serious.)\\n',\n",
       " '1.00: (this; may indicate; that the attackers are generally weak and this threat model may not be very serious.)\\n',\n",
       " '0.34: (the attackers; are generally; weak this threat model may not be very serious.)\\n',\n",
       " '\\n',\n",
       " \"Overall, I'm skeptical of this threat model - the attackers require a very large number of queries, and don't achieve great results on difficult datasets.\\n\",\n",
       " '0.99: (the attackers; require; a very large number of queries,)\\n',\n",
       " \"0.99: (the attackers; don't achieve; great results on difficult datasets.)\\n\",\n",
       " '\\n',\n",
       " 'Including results on a dataset like ImageNet would be nice.\\n',\n",
       " '0.00: (Including results on a dataset like ImageNet; would be; nice.)\\n',\n",
       " '\\n',\n",
       " '2) How long does this optimization procedure take?\\n',\n",
       " '0.94: (this optimization procedure; take?; How long does)\\n',\n",
       " '\\n',\n",
       " 'It seems possibly unreasonable for the victim to implement this defense if it significantly lengthens the time to return outputs of queries.\\n',\n",
       " '1.00: (the victim; to implement; this defense)\\n',\n",
       " '1.00: (it; significantly lengthens; the time to return outputs of queries.)\\n',\n",
       " '\\n',\n",
       " '3) Although this is a defense paper, it would be nice if the attacks were explained a bit more.\\n',\n",
       " '1.00: (this; is; a defense paper,)\\n',\n",
       " '1.00: (it; would be; nice)\\n',\n",
       " '0.02: (the attacks; were explained; a bit more.)\\n',\n",
       " '\\n',\n",
       " 'Specifically, how are these attacks tested?\\n',\n",
       " '\\n',\n",
       " 'You use the validation set, but does the attacker have knowledge about the class-label space of the victim?\\n',\n",
       " '1.00: (You; use; the validation set,)\\n',\n",
       " '0.89: (the attacker; does have; knowledge about the class-label space of the victim?)\\n',\n",
       " '\\n',\n",
       " \"If the attacker trained with some synthetic data/other dataset, do you then freeze the feature extractor and train a linear layer to validate on the victim's test set?\\n\",\n",
       " '1.00: (the attacker; trained; with some synthetic data/other dataset,)\\n',\n",
       " \"1.00: (you; train; a linear layer to validate on the victim's test set?)\\n\",\n",
       " \"0.99: (a linear layer; to validate; on the victim's test set?)\\n\",\n",
       " '\\n',\n",
       " \"It seems like this is discussed in the context of the victim in the ''Attack Models'' subsection, but it's unclear what's happening with the attacker.\\n\",\n",
       " \"0.97: (It this; seems is discussed; in the context of the victim in the ''Attack Models'' subsection,)\\n\",\n",
       " '\\n',\n",
       " \"4) It would be nice to see an angular histogram plot for a model where the perturbed labels were not crafted with knowledge of this model's parameters - ie transfer the proposed defense to a blackbox attacker and produce this same plot.\\n\",\n",
       " '0.87: (the perturbed labels; were not crafted; plot for a model)\\n',\n",
       " \"0.24: (It this model's ie; transfer produce; the proposed defense to a blackbox attacker and this same plot.)\\n\",\n",
       " '\\n',\n",
       " 'This would motivate the defense more.\\n',\n",
       " '0.98: (This; would motivate more.; the defense)\\n',\n",
       " '\\n',\n",
       " 'This paper aims at defending against model stealing attacks by perturbing the posterior prediction of a protected DNN with a balanced goal of maintaining accuracy and maximizing misleading gradient deviation.\\n',\n",
       " '0.00: (This paper; aims stealing; at defending against model by perturbing the posterior prediction of a protected DNN with a balanced goal of maintaining accuracy and maximizing misleading gradient deviation.)\\n',\n",
       " '0.70: (This paper; aims at defending; against model attacks)\\n',\n",
       " '\\n',\n",
       " 'The maximizing angular deviation formulation makes sense and seemingly correct.\\n',\n",
       " '0.89: (The maximizing angular deviation formulation; makes; sense and seemingly correct.)\\n',\n",
       " '\\n',\n",
       " 'The heuristic solver toward this objective is shown to be relatively effective in the experiments.\\n',\n",
       " '1.00: (The heuristic solver toward this objective; is shown; )\\n',\n",
       " '1.00: (The heuristic solver toward this objective; to be; relatively effective in the experiments.)\\n',\n",
       " '\\n',\n",
       " 'While the theoretical novelty of the method is limited, the application in adversarial settings may be useful to advance of this research field, especially when it is relatively easy to apply by practitioners.I recommend toward acceptance of this paper even though can be convinced otherwise by better field experts.\\n',\n",
       " '1.00: (the theoretical novelty of the method; is; limited,)\\n',\n",
       " '1.00: (the application in adversarial settings; may be; useful to advance of this research field,)\\n',\n",
       " '\\n',\n",
       " 'This work presents the Simple Recurrent Unit architecture which allows more parallelism than the LSTM architecture while maintaining high performance.\\n',\n",
       " '1.00: (This work; presents; the Simple Recurrent Unit architecture)\\n',\n",
       " '1.00: (the Simple Recurrent Unit architecture; allows; more parallelism than the LSTM architecture while maintaining high performance.)\\n',\n",
       " '\\n',\n",
       " 'Significance, Quality and clarity:\\n',\n",
       " '\\n',\n",
       " 'The idea is well motivated: Faster training is important for rapid experimentation, and altering the RNN cell so it can be paralleled makes sense.\\n',\n",
       " '0.84: (RNN cell it; can be paralleled; )\\n',\n",
       " '0.69: (Faster training and altering the RNN cell so it; is makes; important for rapid experimentation, sense.)\\n',\n",
       " '0.35: (The idea Faster training; is motivated:; well important for rapid experimentation, and altering the RNN cell can be paralleled sense.)\\n',\n",
       " '0.48: (The idea; is well motivated:; )\\n',\n",
       " '\\n',\n",
       " 'The idea is well explained and the experiments convince that the new architecture is indeed much faster yet performs very well.\\n',\n",
       " '0.99: (The idea; is well explained; )\\n',\n",
       " '0.97: (the experiments; convince; that the new architecture is indeed much faster yet performs very well.)\\n',\n",
       " '0.48: (the experiments the new architecture; is faster; that indeed much yet performs very well.)\\n',\n",
       " '0.52: (the new architecture is; indeed much performs very well.; yet)\\n',\n",
       " '\\n',\n",
       " 'A few constructive comments:\\n',\n",
       " '\\n',\n",
       " \"- The experiment's tables alternate between ''time'' and ''speed'', It will be good to just have one of them.\\n\",\n",
       " \"1.00: (The experiment's tables; alternate; between ''time'' and ''speed'',)\\n\",\n",
       " '\\n',\n",
       " '- Table 4 has time/epoch yet only time is stated\\n',\n",
       " '0.96: (Table 4; has; time/epoch only time)\\n',\n",
       " '0.74: (Table 4 only time; is stated; yet)\\n',\n",
       " '\\n',\n",
       " 'The authors introduce SRU, the Simple Recurrent Unit that can be used as a substitute for LSTM or GRU cells in RNNs.\\n',\n",
       " '1.00: (The authors; introduce; SRU,)\\n',\n",
       " '1.00: (the Simple Recurrent Unit; can be used; as a substitute for LSTM or GRU cells in RNNs.)\\n',\n",
       " '0.00: (SRU,; is  of; the Simple Recurrent Unit)\\n',\n",
       " '\\n',\n",
       " 'SRU is much more parallel than the standard LSTM or GRU, so it trains much faster: almost as fast as a convolutional layer with properly optimized CUDA code.\\n',\n",
       " '0.91: (SRU; is fast; much more parallel than the standard LSTM or GRU,)\\n',\n",
       " '0.89: (it; trains much faster: almost as; much)\\n',\n",
       " '\\n',\n",
       " 'Authors perform experiments on numerous tasks showing that SRU performs on par with LSTMs, but the baselines for these tasks are a little problematic (see below).\\n',\n",
       " '0.99: (Authors; perform; experiments on numerous tasks)\\n',\n",
       " '0.99: (the baselines for these tasks; are; a little problematic (see below).)\\n',\n",
       " '0.99: (numerous tasks; showing; that SRU performs on par with LSTMs, but the baselines for these tasks are a little problematic (see below).)\\n',\n",
       " '0.98: (SRU; performs; on par with LSTMs,)\\n',\n",
       " '\\n',\n",
       " 'On the positive side, the paper is very clear and well-written, the SRU is a superbly elegant architecture with a fair bit of originality in its structure, and the results show that it could be a significant contribution to the field as it can probably replace LSTMs in most cases but yield fast training.\\n',\n",
       " '0.45: (it; can probably replace; LSTMs in most cases)\\n',\n",
       " '0.78: (it; yield; fast training. most cases)\\n',\n",
       " '0.99: (the SRU; is; a superbly elegant architecture with a fair bit of originality in its structure,)\\n',\n",
       " '0.97: (the paper; is; very clear and well-written, On the positive side,)\\n',\n",
       " '0.97: (the results; show; that it could be a significant contribution to the field as it can probably replace LSTMs in most cases but yield fast training.)\\n',\n",
       " '\\n',\n",
       " 'On the negative side, the authors present the results without fully referencing and acknowledging state-of-the-art.\\n',\n",
       " '1.00: (the authors; present; the results On the negative side,)\\n',\n",
       " '0.93: (the authors referencing; the results acknowledging; state-of-the-art.)\\n',\n",
       " '\\n',\n",
       " 'Some of this has been pointed out in the comments below already.\\n',\n",
       " '0.95: (Some of this; has been pointed out; in the comments below already.)\\n',\n",
       " '\\n',\n",
       " 'As another example: Table 5 that presents results for English-German WMT translation only compares to OpenNMT setups with maximum BLEU about 21) But already a long time ago Wu et al presented LSTMs reaching 25 BLEU and current SOTA is above 28 with training time much faster than those early models (https://arxiv.org/abs/1706.03762).\\n',\n",
       " '0.99: (Table 5; presents; results for English-German WMT translation)\\n',\n",
       " '0.84: (Table 5 that results for English-German WMT translation; only compares; to OpenNMT setups with maximum BLEU about 21))\\n',\n",
       " '0.34: (Wu et; al presented; LSTMs reaching 25 BLEU and current SOTA is above 28 with training time much faster than those early models already a long time ago)\\n',\n",
       " '0.46: (LSTMs; reaching; 25 BLEU and current SOTA)\\n',\n",
       " '0.09: (LSTMs 25 BLEU and current SOTA; is; above 28 with training time much faster than those early models already a long time ago)\\n',\n",
       " '\\n',\n",
       " 'While the latest are non-RNN architectures, a table like Table 5 should include them too, for a fair presentation.\\n',\n",
       " '1.00: (the latest; are; non-RNN architectures,)\\n',\n",
       " '1.00: (a table like Table 5; should include too,; them)\\n',\n",
       " '\\n',\n",
       " 'In conclusion: the authors seem to avoid discussing the problem that current non-RNN architectures could be both faster and yield better results on some of the studied problems.\\n',\n",
       " '1.00: (the authors; seem; In conclusion:)\\n',\n",
       " '0.87: (the authors; to avoid; discussing the problem that current non-RNN architectures could be both faster and yield better results on some of the studied problems.)\\n',\n",
       " '0.85: (the authors; discussing; the problem that current non-RNN architectures could be both faster and yield better results on some of the studied problems.)\\n',\n",
       " '0.91: (current non-RNN architectures; could be; both faster)\\n',\n",
       " '0.82: (current non-RNN architectures; yield; better results on some of the studied problems.)\\n',\n",
       " '\\n',\n",
       " \"That's bad presentation of related work and should be improved in the next versions (at which point this reviewer is willing to revise the score).\\n\",\n",
       " \"0.04: (That's; should be improved; in the next versions)\\n\",\n",
       " '0.99: (this reviewer; is; willing to revise the score). which point)\\n',\n",
       " '1.00: (this reviewer; to revise; the score).)\\n',\n",
       " '\\n',\n",
       " 'But in all cases, this is a significant contribution to deep learning and deserves acceptance.\\n',\n",
       " '0.94: (this; is; a significant contribution to deep learning deserves in all cases,)\\n',\n",
       " '0.93: (this a significant contribution to deep learning; deserves; acceptance. in all cases,)\\n',\n",
       " '\\n',\n",
       " \"Update: the revised version of the paper addresses all my concerns and the comments show new evidence of potential applications, so I'm increasing my score.\\n\",\n",
       " '0.75: (the revised version of the paper the comments; addresses show; all my concerns and new evidence of potential applications,)\\n',\n",
       " \"0.03: (Update: I'm; increasing; my score.)\\n\",\n",
       " '0.45: (the revised version of the paper; addresses; all my concerns and the comments show new evidence of potential applications,)\\n',\n",
       " '\\n',\n",
       " 'The authors propose to drop the recurrent state-to-gates connections from RNNs to speed up the model.\\n',\n",
       " '1.00: (The authors; propose; to drop the recurrent state-to-gates connections from RNNs)\\n',\n",
       " '0.98: (The authors; propose to drop; the recurrent state-to-gates connections from RNNs to speed up the model.)\\n',\n",
       " '\\n',\n",
       " 'The recurrent connections however are core to an RNN.\\n',\n",
       " '1.00: (The recurrent connections; are; core to an RNN.)\\n',\n",
       " '\\n',\n",
       " 'Without them, the RNN defaults simply to a CNN with gated incremental pooling.\\n',\n",
       " '0.92: (the RNN; defaults simply; to a CNN with gated incremental pooling.)\\n',\n",
       " '\\n',\n",
       " 'This results in a somewhat unfortunate naming (simple *recurrent* unit), but most importantly makes a comparison with autoregressive sequence CNNs [ Bytenet (Kalchbrenner et al 2016), Conv Seq2Seq (Dauphin et al, 2017) ] crucial in order to show that gated incremental pooling is beneficial over a simple CNN architecture baseline.\\n',\n",
       " '1.00: (This; results; in a somewhat unfortunate naming)\\n',\n",
       " '0.76: (This; most importantly makes; a comparison with autoregressive sequence CNNs)\\n',\n",
       " '0.50: (order that gated incremental pooling; is; beneficial over a simple CNN architecture baseline.)\\n',\n",
       " '\\n',\n",
       " 'In essence, the paper shows that autoregressive CNNs with gated incremental pooling perform comparably to RNNs on a number of tasks while being faster to compute.\\n',\n",
       " '0.71: (the paper; shows; that autoregressive CNNs with gated incremental pooling perform comparably to RNNs on a number of tasks while being faster to compute. In essence,)\\n',\n",
       " '0.90: (autoregressive CNNs with gated incremental pooling; perform comparably; to RNNs on a number of tasks)\\n',\n",
       " '\\n',\n",
       " 'Since it is already extensively known that autoregressive CNNs and attentional models can achieve this, the *CNN* part of the paper cannot be counted as a novel contribution.\\n',\n",
       " '0.49: (the *CNN* part of the paper; is extensively known cannot be counted; already)\\n',\n",
       " '0.97: (autoregressive CNNs and attentional models; can achieve; this,)\\n',\n",
       " '\\n',\n",
       " 'What is left is the gated incremental pooling operation; but to show that this operation is beneficial when added to autoregressive CNNs, a thorough comparison with an autoregressive CNN baseline is necessary.\\n',\n",
       " '1.00: (What is left; is; the gated incremental pooling operation;)\\n',\n",
       " '0.94: (a thorough comparison with an autoregressive CNN baseline; is; necessary. when added to autoregressive CNNs,)\\n',\n",
       " '\\n',\n",
       " 'Pros:\\n',\n",
       " '\\n',\n",
       " '- Fairly well presented\\n',\n",
       " '0.00: (Fairly; well presented; )\\n',\n",
       " '\\n',\n",
       " '- Wide range of experiments, despite underwhelming absolute results\\n',\n",
       " '0.94: (- Wide range of experiments,; despite underwhelming; absolute results)\\n',\n",
       " '\\n',\n",
       " 'Cons:\\n',\n",
       " '\\n',\n",
       " '- Quasi-RNNs are almost identical and already have results on small-scale tasks.\\n',\n",
       " '1.00: (Quasi-RNNs; are; almost identical)\\n',\n",
       " '1.00: (Quasi-RNNs; have; results on small-scale tasks. already)\\n',\n",
       " '\\n',\n",
       " '- Slightly unfortunate naming that does not account for autoregressive CNNs\\n',\n",
       " '1.00: (Slightly unfortunate naming; does not account; for autoregressive CNNs)\\n',\n",
       " '\\n',\n",
       " '- Lack of comparison with autoregressive CNN baselines, which signals a major conceptual error in the paper.\\n',\n",
       " '0.99: (Lack of comparison with autoregressive CNN baselines,; signals; a major conceptual error in the paper.)\\n',\n",
       " '\\n',\n",
       " '- I would suggest to focus on a small set of tasks and show that the model achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.\\n',\n",
       " '0.96: (I; would suggest; to focus on a small set of tasks and show that the model achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.)\\n',\n",
       " '0.12: (I; would to focus show; on a small set of tasks and achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.)\\n',\n",
       " '0.06: (I; suggest; that the model achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.)\\n',\n",
       " '0.66: (the model; achieves; very good SOTA performance on them,)\\n',\n",
       " '\\n',\n",
       " 'I recommend showing exhaustively and experimentally that gated incremental pooling can be helpful for autoregressive CNNs on sequence tasks (MT, LM and ASR).\\n',\n",
       " '0.69: (I; recommend; showing exhaustively and experimentally that gated incremental pooling can be helpful CNNs sequence)\\n',\n",
       " '0.04: (I; showing exhaustively experimentally; and that gated incremental pooling can be helpful for autoregressive CNNs on sequence tasks)\\n',\n",
       " '0.93: (gated incremental pooling; can be; helpful for autoregressive CNNs on sequence tasks)\\n',\n",
       " '\\n',\n",
       " 'I will adjust my score accordingly if the experiments are presented.\\n',\n",
       " '0.97: (I; will adjust accordingly; my score if)\\n',\n",
       " '1.00: (the experiments; are presented.; )\\n',\n",
       " '\\n',\n",
       " 'Contribution:\\n',\n",
       " '\\n',\n",
       " 'The paper proposes to use a set of handcrafted intrinsic rewards that depend on the novelty of an observation as perceived by the rest of the other agents.\\n',\n",
       " '0.95: (set of handcrafted intrinsic rewards; depend; on the novelty of an observation)\\n',\n",
       " '1.00: (The paper; proposes; to use a set of handcrafted intrinsic rewards)\\n',\n",
       " '0.33: (The paper; proposes to use; a set of handcrafted intrinsic rewards)\\n',\n",
       " '\\n',\n",
       " 'For each pair of reward and agent, they learn a policy and a value through actor critic method, and then a meta-policy choses at the beginning of each episode which intrinsic rewards to use, meaning that the policy used by the agents corresponds to the one that maximizes the reward chosen.\\n',\n",
       " '0.85: (they; learn; a policy and a value For each pair of reward and agent,)\\n',\n",
       " '0.38: (a meta-policy policy the one the reward; choses; at the beginning of each episode then)\\n',\n",
       " '0.33: (each episode intrinsic rewards policy used the one; maximizes chosen.; the reward)\\n',\n",
       " '0.00: (each episode the by the agents; to use,; to the one the reward)\\n',\n",
       " '\\n',\n",
       " 'Review:\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'The major limitation of the paper in my opinion is the fact that the \"coordination\" that occurs here is only happening at training time, not at execution time.\\n',\n",
       " '1.00: (The major limitation of the paper in my opinion; is; the fact that the \"coordination\" that occurs here is only happening at training time, not at execution time.)\\n',\n",
       " '0.99: (the \"coordination\"; occurs; here)\\n',\n",
       " '0.08: (the fact that the \"coordination\" that occurs here; is only happening; at training time, not at execution time.)\\n',\n",
       " '\\n',\n",
       " 'The agents eventually learn whatever trajectory they need to perform, and then proceed to do so without any interaction with the other agents.\\n',\n",
       " '0.98: (The agents; learn; whatever trajectory they need to perform, and then proceed to do so without any interaction with the other agents. eventually)\\n',\n",
       " '0.90: (they; need; to perform, so)\\n',\n",
       " '0.09: (whatever trajectory they; to perform,; )\\n',\n",
       " '0.18: (whatever trajectory they; need proceed; to do so without any interaction with the other agents. then)\\n',\n",
       " '\\n',\n",
       " \"In a sense, they don't even learn to explore collaboratively.\\n\",\n",
       " \"1.00: (they; don't even learn; to explore collaboratively. In a sense,)\\n\",\n",
       " '0.98: (they; to explore collaboratively.; )\\n',\n",
       " '\\n',\n",
       " 'In other words, agents trained on task 1 in a given maze would not be able to solve task 2 on the same maze without essentially relearning everything from scratch.\\n',\n",
       " '0.98: (agents; trained; on task 1 in a given maze)\\n',\n",
       " '0.02: (agents trained on task 1 in a given maze; would not be; able to solve task 2 on the same maze without essentially relearning everything from scratch.)\\n',\n",
       " '0.93: (agents trained on task 1 in a given maze; to solve; task 2 on the same maze)\\n',\n",
       " '0.23: (agents trained on task 1 in a given maze; without essentially relearning; everything from scratch.)\\n',\n",
       " '\\n',\n",
       " 'The other corollary of the fact that each agent learns its own policy is that the number of agents is fixed at training time, preventing testing with a different number of agents, as sometimes done in the literature ([1] [2]).\\n',\n",
       " '1.00: (each agent; learns; its own policy)\\n',\n",
       " '0.54: (The other corollary of the fact that each agent learns its own policy of agents; is; that the number is fixed at training time, preventing testing with a different number of agents,)\\n',\n",
       " '0.36: (The other corollary of the fact that; is fixed; that the number of agents at training time, preventing testing with a different number of agents,)\\n',\n",
       " '0.57: (the number of agents; is fixed preventing; at training time,)\\n',\n",
       " '\\n',\n",
       " 'Given this limitation the scope of the work basically reduces to the exploration of a fixed environment when the action space can be factored into different agents.\\n',\n",
       " '1.00: (the scope of the work; basically reduces; to the exploration of a fixed environment)\\n',\n",
       " '1.00: (the action space; can be factored; into different agents.)\\n',\n",
       " '\\n',\n",
       " 'This \"multi-agent\" formulation is presumably meant to break down the computational complexity of having a joint observation/action space.\\n',\n",
       " '1.00: (This \"multi-agent\" formulation; is presumably meant; )\\n',\n",
       " '1.00: (This \"multi-agent\" formulation; to break down; the computational complexity of having a joint observation/action space.)\\n',\n",
       " '\\n',\n",
       " 'However, the experiments are conducted only with a very limited number of agents (only 2 in the non toy environment of vizdoom).\\n',\n",
       " '0.99: (the experiments; are conducted; only with a very limited number of agents)\\n',\n",
       " '\\n',\n",
       " \"This small scale doesn't, in my opinion, demonstrate the advantage of the decomposition of the MDP over say SOTA single-agent exploration methods applied to the cartesian product of all the agents action spaces (in vizdoom the paper considers only 3 actions, so with two agents it would amount to 9 actions, which is still very tractable).\\n\",\n",
       " \"0.06: (This small scale; doesn't, demonstrate would amount; the advantage of the decomposition of the MDP over say SOTA single-agent exploration methods applied the agents action spaces (in vizdoom the paper 3 actions, to 9 actions, still very tractable).)\\n\",\n",
       " '0.09: (it; is; the advantage of the decomposition of the MDP to the cartesian product of all (in vizdoom the considers only 3 actions, still very tractable).)\\n',\n",
       " '0.04: (the it; applied considers; to the cartesian product of all the agents action spaces only 3 actions,)\\n',\n",
       " '\\n',\n",
       " 'Once the trajectories of both agents are found, they can be distilled to each of them individually so that they only depend on the local observation.\\n',\n",
       " '1.00: (the trajectories of both agents; are found,; )\\n',\n",
       " '0.69: (they; can be distilled individually; Once the trajectories of both agents are found, to each of them so that they only depend on the local observation.)\\n',\n",
       " '0.12: (they; only depend; on the local observation.)\\n',\n",
       " '\\n',\n",
       " \"Regarding the experiments on the Vizdoom environment, it appears that the traditional evaluation setup [3] doesn't involve providing the global position (x,y) to the agents as part of the observations (they must be inferred from the visual feed), contrary to the experimental setup presented in this paper.\\n\",\n",
       " '0.96: (the experimental setup; presented; in this paper.)\\n',\n",
       " '\\n',\n",
       " 'In my opinion, this weakens the claim that the method \"scales to more complex environments\" since providing the position essentially makes the environment similar to a grid-world (arguably the visual feed isn\\'t even needed to solve the task.\\n',\n",
       " '0.53: (this; weakens; the claim that the method \"scales to more complex environments\" since providing the position essentially makes the environment similar to a grid-world isn\\'t even In my opinion,)\\n',\n",
       " '0.28: (the method \"scales to more complex environments\"; essentially makes; the similar to a grid-world (arguably to solve the task.)\\n',\n",
       " \"0.46: (the visual feed; isn't even needed; to solve the task.)\\n\",\n",
       " '\\n',\n",
       " 'The use of a dynamic policy selection is somewhat interesting, but would benefit better investigation.\\n',\n",
       " '1.00: (The use of a dynamic policy selection; is; somewhat interesting,)\\n',\n",
       " '0.98: (The use of a dynamic policy selection; would benefit; better investigation.)\\n',\n",
       " '\\n',\n",
       " 'Firstly, it is not clear to me if all the selection of the policy to use during training affects all the trajectories of the batch, or if different episodes of the batch may have a different policy.\\n',\n",
       " '0.92: (all the selection of the policy; to use; during training)\\n',\n",
       " '0.93: (all the selection of the policy during training; affects; all the trajectories of the batch,)\\n',\n",
       " '0.73: (it different episodes of the batch; is not may have; clear to me a different policy.)\\n',\n",
       " '\\n',\n",
       " 'Secondly, it seems that the setting is typically the one of a (non-stationary) bandit, since there is no state and the \"reward\" is the return obtained by the policy.\\n',\n",
       " '0.95: (the \"reward\"; is; the return obtained by the policy.)\\n',\n",
       " '0.99: (the return; obtained; by the policy.)\\n',\n",
       " '\\n',\n",
       " 'Could you share the reason behind the choice of an actor-critic algorithm over classical bandit algorithms?\\n',\n",
       " '1.00: (you; share; the reason behind the choice of an actor-critic algorithm over classical bandit algorithms?)\\n',\n",
       " '\\n',\n",
       " 'One obvious advantage of the latter are provable regret bounds.\\n',\n",
       " '1.00: (One obvious advantage of the latter; are; provable regret bounds.)\\n',\n",
       " '\\n',\n",
       " 'In all, the selection policy seems to be useful during training, since it sometimes yields better solutions than any of the individual reward schemes.\\n',\n",
       " '0.97: (the selection policy; seems; In all,)\\n',\n",
       " '1.00: (the selection policy; to be; useful during training,)\\n',\n",
       " '1.00: (it; yields; better solutions than any of the individual reward schemes. sometimes)\\n',\n",
       " '\\n',\n",
       " \"It suggests that some form of curriculum over the rewards is occurring during training, but if this is really what is going on, then it's possible that the relevant literature about curriculum learning may offer more stable and principled solutions than an actor critic, for example population based training.\\n\",\n",
       " '0.69: (It; suggests is really; that what is going on,)\\n',\n",
       " '0.61: (It some; is; that form of curriculum over the rewards occurring during training,)\\n',\n",
       " '0.88: (some form of curriculum over the rewards; occurring; during training,)\\n',\n",
       " '0.38: (this the relevant literature about curriculum learning; is really; what is going on, more stable and principled solutions than an actor critic, for example population based training.)\\n',\n",
       " '\\n',\n",
       " 'This could potentially solve the issues observed in task 2.\\n',\n",
       " '1.00: (This; could potentially solve; the issues observed in task 2.)\\n',\n",
       " '1.00: (the issues; observed; in task 2.)\\n',\n",
       " '\\n',\n",
       " '[1] Relational Deep Reinforcement Learning, Zambaldi et al, https://arxiv.org/abs/1806.01830\\n',\n",
       " '0.88: (Relational Deep Reinforcement Zambaldi; Learning, et; al,)\\n',\n",
       " '\\n',\n",
       " '[2] A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learning, Carion et al, https://arxiv.org/abs/1910.08809\\n',\n",
       " '0.87: (Carion; et al, https://arxiv.org/abs/1910.08809; )\\n',\n",
       " '\\n',\n",
       " '[3] Curiosity-driven Exploration by Self-supervised Prediction, Pathak et al, ICML 2017\\n',\n",
       " '0.92: (Curiosity-driven Exploration by Self-supervised Prediction, Pathak; et al,; 2017)\\n',\n",
       " '\\n',\n",
       " 'Overall I like the approach in the paper.\\n',\n",
       " '0.97: (Overall I; like; the approach in the paper.)\\n',\n",
       " '\\n',\n",
       " 'It proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems.\\n',\n",
       " '1.00: (It; proposes; a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems.)\\n',\n",
       " '\\n',\n",
       " 'The parts that a bit lacking with the current version of the paper in this are the evaluation tasks are few and a bit simple and I think there needs to be more discussion on the \"coverage\" of the intrinsic reward types.\\n',\n",
       " '0.94: (The a bit; lacking; with the current version of the paper in this)\\n',\n",
       " '0.51: (The parts that a bit lacking with the current version of the paper in this; are; the evaluation tasks are few and a bit simple and I think there needs to be more discussion on the \"coverage\" of the intrinsic reward types.)\\n',\n",
       " '0.99: (the evaluation tasks; are; few and a bit simple)\\n',\n",
       " '0.33: (I; think; there needs to be more discussion on the \"coverage\" of the intrinsic reward types.)\\n',\n",
       " '\\n',\n",
       " 'Are the ones proposed motivated by the tasks in the paper or are they sufficient for tasks in general?\\n',\n",
       " '0.92: (the ones; proposed motivated; by the tasks in the paper)\\n',\n",
       " '\\n',\n",
       " 'Last using a more recent novelty metric could allow the method to work on more interesting/complex tasks.\\n',\n",
       " '1.00: (Last using a more recent novelty metric; could allow; the method to work on more interesting/complex tasks.)\\n',\n",
       " '1.00: (the method; to work; on more interesting/complex tasks.)\\n',\n",
       " '\\n',\n",
       " 'More detailed feedback:\\n',\n",
       " '\\n',\n",
       " '- It would be good to include more learning curves in the main text for the paper.\\n',\n",
       " '0.94: (It; be to; good include more learning curves in the main text for the paper.)\\n',\n",
       " '\\n',\n",
       " '- The fact that applying intrinsic motivation to multi-agent simulations seems like a natural idea would be to convert the problem to a \"single\" agent problem to compare against the \"normal\" application of intrinsic rewards.\\n',\n",
       " '0.97: (The fact that applying intrinsic motivation to multi-agent simulations; seems; )\\n',\n",
       " '0.99: (a natural idea; would be; to convert the problem to a \"single\" agent problem to compare against the \"normal\" application of intrinsic rewards.)\\n',\n",
       " '\\n',\n",
       " 'This might be another baseline to consider for comparison.\\n',\n",
       " '1.00: (This; might be; another baseline to consider for comparison.)\\n',\n",
       " '\\n',\n",
       " '- It says that all agents share the same replay buffer.\\n',\n",
       " '1.00: (It; says; that all agents share the same replay buffer.)\\n',\n",
       " '1.00: (all agents; share; the same replay buffer.)\\n',\n",
       " '\\n',\n",
       " 'Does this also imply that every agent is performing the same task there are just many agents?\\n',\n",
       " '0.96: (this every agent; is performing; the same task there are just many agents?)\\n',\n",
       " '\\n',\n",
       " 'This does not make the problem very multi-agent with different goals.\\n',\n",
       " '1.00: (This; does not make; the problem very multi-agent with different goals.)\\n',\n",
       " '\\n',\n",
       " 'Would it affect the algorithm significantly to work on an environment where the agents have various types of goals?\\n',\n",
       " '1.00: (the agents; have; various types of goals? an environment)\\n',\n",
       " '\\n',\n",
       " '- As is noted in the text, this method appears to work well in the centralized training scheme that many have adopted recently.\\n',\n",
       " '0.99: (this method; appears; )\\n',\n",
       " '0.99: (this method; to work well; in the centralized training scheme)\\n',\n",
       " '0.81: (the centralized training scheme; have adopted; many recently.)\\n',\n",
       " '\\n',\n",
       " 'However, It makes me wonder if there is a way to employ these exploration schemes in a non-centralized training form.\\n',\n",
       " '1.00: (It; makes; me wonder if there is a way)\\n',\n",
       " '1.00: (me; wonder; if there is a way)\\n',\n",
       " '\\n',\n",
       " 'The ability to ask other agents in the world about there preferences and novelty of states appears to be a strong assumption, especially in a multi-agent robotics problem.\\n',\n",
       " '1.00: (The ability to ask other agents in the world about there preferences and novelty of states; appears; )\\n',\n",
       " '1.00: (The ability to ask other agents in the world about there preferences and novelty of states; to be; a strong assumption, especially in a multi-agent robotics problem.)\\n',\n",
       " '\\n',\n",
       " '- While the authors note that the intrinsic rewards used in this work are not comprehensive it would be good to note how comprehensive they are.\\n',\n",
       " '1.00: (the authors; note; that the intrinsic rewards used in this work are not comprehensive)\\n',\n",
       " '0.84: (the intrinsic rewards used this work; are not; in comprehensive)\\n',\n",
       " '0.28: (the intrinsic rewards used in this work it; would be; good to note how comprehensive they are.)\\n',\n",
       " '0.62: (they; are.; )\\n',\n",
       " '\\n',\n",
       " 'Are there a few that were left out on purpose.\\n',\n",
       " '1.00: (a few; were left out; on purpose.)\\n',\n",
       " '\\n',\n",
       " 'Do the authours believe this set is sufficient.\\n',\n",
       " '0.94: (the authours this set; believe; is sufficient.)\\n',\n",
       " '0.97: (this set; is; sufficient.)\\n',\n",
       " '\\n',\n",
       " 'This statement makes it seem like the authors just tried a few options and found one that worked.\\n',\n",
       " '0.85: (one; found worked.; and that)\\n',\n",
       " '0.70: (This statement; makes; it seem like the authors just tried a few options and one)\\n',\n",
       " '0.76: (it the authors; seem just tried; a few options)\\n',\n",
       " '0.53: (the authors; found; one that worked.)\\n',\n",
       " '\\n',\n",
       " 'It would be good to expand on this discussion more.\\n',\n",
       " '0.97: (It; be; good to expand on this discussion more.)\\n',\n",
       " '\\n',\n",
       " '- More detail for Figure 1 would be helpful to understand the overall network design.\\n',\n",
       " '1.00: (More detail for Figure 1; would be; helpful to understand the overall network design.)\\n',\n",
       " '0.88: (More detail for Figure 1; to understand; the overall network design.)\\n',\n",
       " '\\n',\n",
       " 'While that figure it helpful maybe it would be good to include a version that goes into detail for the 2 agent environment.\\n',\n",
       " '0.90: (a version; goes; into detail for the 2 agent environment.)\\n',\n",
       " '0.96: (that; figure; it helpful)\\n',\n",
       " '\\n',\n",
       " 'Then a more compressed n agent version can also be shown.\\n',\n",
       " '0.96: (a more compressed n agent version; can also be shown.; Then)\\n',\n",
       " '\\n',\n",
       " '- The paper describes a policy selector that is a type of high-level policy for HRL.\\n',\n",
       " '1.00: (The paper; describes; a policy selector that is a type of high-level policy for HRL.)\\n',\n",
       " '1.00: (a policy selector; is; a type of high-level policy for HRL.)\\n',\n",
       " '0.88: (that; is a type of; high-level policy for HRL.)\\n',\n",
       " '\\n',\n",
       " 'This design seems rather unique in that this part of the policy can optimizing for which intrinsic reward to toggle based on the extrinsic rewards observed.\\n',\n",
       " '0.97: (This design; seems; )\\n',\n",
       " '0.45: (this part of the policy toggle based on the extrinsic rewards; can optimizing observed.; )\\n',\n",
       " '\\n',\n",
       " 'I like it.\\n',\n",
       " '1.00: (I; like; it.)\\n',\n",
       " '\\n',\n",
       " 'It is noted that entropy is important for this design.\\n',\n",
       " '\\n',\n",
       " 'Can this be analyzed in an empirical way?\\n',\n",
       " '0.96: (this; be analyzed; an empirical way?)\\n',\n",
       " '\\n',\n",
       " 'Is this true for most environments/tasks?\\n',\n",
       " '0.97: (this; Is; true for most environments/tasks?)\\n',\n",
       " '\\n',\n",
       " '- Task 2 seems a bit contrived.\\n',\n",
       " '1.00: (Task 2; seems; a bit contrived.)\\n',\n",
       " '0.75: (Task 2; bit contrived.; )\\n',\n",
       " '\\n',\n",
       " 'Is there another instance of this type of task elsewhere in another paper?\\n',\n",
       " '\\n',\n",
       " 'It would be better to use more standard tasks if they are available.\\n',\n",
       " '0.98: (It; would be; better to use more standard tasks if)\\n',\n",
       " '0.84: (It; better to use; more standard tasks available.)\\n',\n",
       " '1.00: (they; are; available.)\\n',\n",
       " '\\n',\n",
       " '- Before section 6.1 the paper is discussing rewards the are received.\\n',\n",
       " '0.90: (section 6.1 the paper; is discussing; rewards the are received.)\\n',\n",
       " '0.00: (6.1 the paper rewards; are received.; Before section the)\\n',\n",
       " '\\n',\n",
       " 'It would be good to more explicit about where these rewards are coming from.\\n',\n",
       " '0.99: (It; would be; good to more explicit about where these rewards are coming from.)\\n',\n",
       " '0.93: (these rewards; are coming; from.)\\n',\n",
       " '\\n',\n",
       " 'I think it is meant that these rewards are the extrinsic rewards but it does not say.\\n',\n",
       " '1.00: (it; does not say.; )\\n',\n",
       " '0.87: (I; think; it is meant that these rewards are the extrinsic rewards but it does not say.)\\n',\n",
       " '0.70: (it; is meant; that these rewards are the extrinsic rewards but it does not say.)\\n',\n",
       " '0.35: (these rewards; are; the extrinsic rewards it does not say.)\\n',\n",
       " '\\n',\n",
       " '- As noted just before section 6.1 it seems for the collection of tasks 1-3 it is already obvious what types of intrinsic rewards should be used.\\n',\n",
       " '0.93: (it; seems; for the collection of tasks)\\n',\n",
       " '0.75: (it; is; already obvious what types of intrinsic rewards should be used.)\\n',\n",
       " '\\n',\n",
       " 'It would be good to include more tasks where this decision is less obvious.\\n',\n",
       " '0.80: (It this decision; include is; less obvious. more tasks)\\n',\n",
       " '0.94: (this decision; is; less obvious.)\\n',\n",
       " '\\n',\n",
       " '- Why are there \"black holes\" in the environment?\\n',\n",
       " '\\n',\n",
       " 'Also if an agent steps into a black hole they are crushed never to be seen again.\\n',\n",
       " '0.90: (an agent they; are crushed; hole never to be seen again.)\\n',\n",
       " '0.03: (an steps into a black hole they; never to be seen; again.)\\n',\n",
       " '\\n',\n",
       " 'What you describe sounds more like a wormhole where one end is non-stationary... Also, can the agents detect the presence of a black hole in some way?\\n',\n",
       " '0.96: (you; describe; wormhole)\\n',\n",
       " '0.95: (one end; is; non-stationary... a wormhole)\\n',\n",
       " '0.02: (What you describe the agents; sounds more can detect; like the presence of a black hole in some way?)\\n',\n",
       " '\\n',\n",
       " '- It appears the novel metric is count based.\\n',\n",
       " '0.89: (It the novel metric; appears is based.; count)\\n',\n",
       " '\\n',\n",
       " 'While this can work in practice it seems a rather simple metric.\\n',\n",
       " '1.00: (this; can work; in practice)\\n',\n",
       " '0.91: (it; seems; )\\n',\n",
       " '\\n',\n",
       " 'Is it possible to use something more like ICM or RND that was referenced in the paper?\\n',\n",
       " '1.00: (something more like ICM or RND; was referenced; in the paper?)\\n',\n",
       " '\\n',\n",
       " 'Especially for the VizDoom environment?\\n',\n",
       " '\\n',\n",
       " '- In table 2 where are some of the numbers bold?\\n',\n",
       " '\\n',\n",
       " 'It would be good to include this information in the caption for the table.\\n',\n",
       " '0.95: (It; be; good to include this information in the caption for the table.)\\n',\n",
       " '\\n',\n",
       " '- I am not sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.\\n',\n",
       " '0.97: (I; am not; sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.)\\n',\n",
       " '0.92: (the discussion on the behaviours; result; the intrinsic reward functions in)\\n',\n",
       " '1.00: (the discussion on the behaviours; are; very surprising.)\\n',\n",
       " '\\n',\n",
       " 'Maybe there is a more interesting behaviour that results from the combination of two intrinsic rewards?\\n',\n",
       " '1.00: (a more interesting behaviour; results; from the combination of two intrinsic rewards?)\\n',\n",
       " '\\n',\n",
       " 'Summary:\\n',\n",
       " '\\n',\n",
       " 'The paper proposes a method for coordinating the exploration efforts of agents in a multi-agent reinforcement learning setting.\\n',\n",
       " '1.00: (The paper; proposes; a method for coordinating the exploration efforts of agents in a multi-agent reinforcement learning setting.)\\n',\n",
       " '0.90: (a multi-agent reinforcement; learning; setting.)\\n',\n",
       " '\\n',\n",
       " 'The approach has two main components: (i) learning different exploration policies using different \"joint\" intrinsic rewards; and (ii) learning a higher-level policy that selects one of the exploration policies to be executed at the beginning of each episode.\\n',\n",
       " '0.99: (The approach; has; two main components: (i) learning different exploration policies using different \"joint\" intrinsic rewards;)\\n',\n",
       " '0.82: (a higher-level policy one of the exploration policies; to be executed; at the beginning of each episode.)\\n',\n",
       " '0.95: (different exploration policies; using; different \"joint\" intrinsic rewards;)\\n',\n",
       " '0.71: (a higher-level policy; selects; that one of the exploration policies to be executed at the beginning of each episode.)\\n',\n",
       " '\\n',\n",
       " 'Each agent has its own novelty function which quantifies the novelty of observation seen by that agent.\\n',\n",
       " '1.00: (Each agent; has; its own novelty function which quantifies the novelty of observation)\\n',\n",
       " '1.00: (its own novelty function; quantifies; the novelty of observation seen by that agent.)\\n',\n",
       " '1.00: (the novelty of observation; seen; by that agent.)\\n',\n",
       " '\\n',\n",
       " 'To coordinate exploration, these novelty functions are combined using aggregation functions to produce intrinsic reward for the agent.\\n',\n",
       " '0.93: (these novelty functions; are combined; using aggregation functions produce)\\n',\n",
       " '0.75: (these functions; using to produce; intrinsic reward for the agent.)\\n',\n",
       " '\\n',\n",
       " 'Each such aggregating function yields a different intrinsic reward.\\n',\n",
       " '1.00: (Each such aggregating function; yields; a different intrinsic reward.)\\n',\n",
       " '\\n',\n",
       " 'The authors propose several such aggregating functions as examples, however the method is applicable to other aggregating functions as well, as long as they can be computed off-policy.\\n',\n",
       " '0.72: (they; as can be computed; off-policy.)\\n',\n",
       " '0.98: (the method; is as well,; applicable to other aggregating functions)\\n',\n",
       " '0.99: (The authors; propose; several such aggregating functions as examples,)\\n',\n",
       " '\\n',\n",
       " 'During training, the higher level policy selects one of the exploration policies which is then executed for the entire episode.\\n',\n",
       " '1.00: (the higher level policy; selects; one of the exploration policies During training,)\\n',\n",
       " '1.00: (the exploration policies; is executed; for the entire episode. then)\\n',\n",
       " '\\n',\n",
       " 'The episode data is used in two ways: (i) to train the higher-level policy using policy gradients for maximizing extrinsic rewards along with an entropy term; and (ii) to train each exploration policy using soft actor-critic on its own intrinsic reward function (and extrinsic reward) in an off-policy manner.\\n',\n",
       " '1.00: (The episode data; is used; )\\n',\n",
       " '0.18: (the higher-level policy policy each exploration policy; to train using; gradients for maximizing extrinsic rewards along with an entropy term; soft actor-critic on its own intrinsic reward function (and extrinsic reward) in an off-policy manner.)\\n',\n",
       " '0.19: (each exploration policy; using; soft actor-critic its own intrinsic reward function)\\n',\n",
       " '\\n',\n",
       " 'Experiments done on grid-world and VizDoom environment for three different tasks demonstrate that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards.\\n',\n",
       " '1.00: (Experiments; done; on grid-world and VizDoom environment for three different tasks)\\n',\n",
       " '0.02: (Experiments done on grid-world and VizDoom environment for three different tasks; demonstrate; that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards.)\\n',\n",
       " '0.38: (the proposed approach; performs at least as well; on as separately trained individual intrinsic rewards. most tasks,)\\n',\n",
       " '\\n',\n",
       " 'Further ablation studies confirm that both the hierarchical setup and the \"joint\" intrinsic rewards are useful.\\n',\n",
       " '1.00: (Further ablation studies; confirm; that both the hierarchical setup and the \"joint\" intrinsic rewards are useful.)\\n',\n",
       " '1.00: (both the hierarchical setup and the \"joint\" intrinsic rewards; are; useful.)\\n',\n",
       " '\\n',\n",
       " 'Questions to the Authors:\\n',\n",
       " '\\n',\n",
       " '1) The second sentence in section 5 is not clear - \"Furthermore, the type of reward ... sufficiently complex\".\\n',\n",
       " '0.99: (1) The second sentence in section 5; is not; clear)\\n',\n",
       " '\\n',\n",
       " 'The high-level policy selects an exploration strategy at the beginning of each episode and then sticks to it for the entire duration of the episode.\\n',\n",
       " '0.99: (The high-level policy; selects; an exploration strategy at the beginning of each episode)\\n',\n",
       " '0.98: (The high-level policy; sticks; to it for the entire duration of the episode. then)\\n',\n",
       " '\\n',\n",
       " 'Changing the exploration strategy over the course of training might be useful in cases when agent needs to switch to a different exploration strategy after reaching a particular bottleneck state.\\n',\n",
       " '1.00: (Changing the exploration strategy over the course of training; might be; useful in cases)\\n',\n",
       " '1.00: (agent; needs; to switch to a different exploration strategy after reaching a particular bottleneck state. cases)\\n',\n",
       " '0.11: (agent; needs to switch; to a different exploration strategy after reaching a particular bottleneck state.)\\n',\n",
       " '0.70: (agent; needs to switch to a different exploration strategy after reaching; a particular bottleneck state.)\\n',\n",
       " '\\n',\n",
       " 'However, this would require the exploration strategy to be changed in the middle of an episode which is not supported.\\n',\n",
       " '0.00: (this; would require; the exploration strategy to be changed in the middle of an episode)\\n',\n",
       " '1.00: (the exploration strategy; to be changed; in the middle of an episode)\\n',\n",
       " '1.00: (an episode; is not supported.; )\\n',\n",
       " '\\n',\n",
       " 'Could you give an example where the exploration strategy must be changed over time even if one only selects the strategy at the beginning of each episode?\\n',\n",
       " '0.95: (the exploration strategy; must be changed; where over time an example)\\n',\n",
       " '0.87: (one; only selects; the strategy)\\n',\n",
       " '\\n',\n",
       " 'Also, why not select the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?\\n',\n",
       " '0.01: (why; not select; the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?)\\n',\n",
       " '\\n',\n",
       " '2) Analyzing the role of high-level policy and its evolution over time on different tasks would be a very nice addition to the paper.\\n',\n",
       " '1.00: (2) Analyzing the role of high-level policy and its evolution over time on different tasks; would be; a very nice addition to the paper.)\\n',\n",
       " '\\n',\n",
       " 'Qualitative experiments demonstrating that it provides a curriculum which helps the agents in surpassing the performance of individual intrinsic rewards would be helpful.\\n',\n",
       " '0.88: (it provides a curriculum; helps; the agents in surpassing the performance of individual intrinsic rewards)\\n',\n",
       " '0.66: (Qualitative experiments demonstrating that a curriculum which the agents in surpassing the performance of individual intrinsic rewards; would be; helpful.)\\n',\n",
       " '0.99: (Qualitative experiments; demonstrating; that it provides a curriculum)\\n',\n",
       " '0.73: (it; provides; a curriculum which helps the agents in surpassing the performance of individual intrinsic rewards would be)\\n',\n",
       " '\\n',\n",
       " '3) Should \\\\Pi in (10) also depend on i?\\n',\n",
       " '0.96: (Should \\\\Pi in; depend; on i?)\\n',\n",
       " '\\n',\n",
       " 'Though paper is reasonably well written I find the contributions are very marginal.\\n',\n",
       " '0.99: (paper; is reasonably well written; )\\n',\n",
       " '0.00: (I; find; the contributions are very marginal.)\\n',\n",
       " '1.00: (the contributions; are; very marginal.)\\n',\n",
       " '\\n',\n",
       " 'If authors can position the paper well with the existing literature and bring out the impact of the contributions it will be helpful.\\n',\n",
       " '0.95: (authors; can position well; the paper)\\n',\n",
       " '1.00: (authors; bring out; the impact of the contributions)\\n',\n",
       " '1.00: (it; will be; helpful.)\\n',\n",
       " '\\n',\n",
       " 'Summary: The paper proposes a method to compute adversarial examples with minimum distance to the original inputs, and to use the method to do two things: Show how well heuristic methods do in finding \"optimal/minimal\" adversarial examples (how close the come to the minimal change that flips the label) and to assess how a method that is designed to make the model more robust to adversarial examples actually works.\\n',\n",
       " '0.85: (The paper; proposes; a method to compute adversarial examples with minimum distance to the original inputs, and the)\\n',\n",
       " '0.67: (The paper method; a to compute; adversarial examples)\\n',\n",
       " '0.00: (the minimal change a method that is designed the model examples; flips to make actually works.; the label) more robust to adversarial)\\n',\n",
       " '\\n',\n",
       " 'Pros:\\n',\n",
       " '\\n',\n",
       " 'I like the idea and the proposed applications.\\n',\n",
       " '1.00: (I; like; the idea and the proposed applications.)\\n',\n",
       " '\\n',\n",
       " 'It is certainly highly relevant, both in terms of assessing models for critical use cases as well as a tool to better understand the phenomenon.\\n',\n",
       " '1.00: (It; is certainly; highly relevant,)\\n',\n",
       " '0.94: (models a tool; to better understand; the phenomenon.)\\n',\n",
       " '\\n',\n",
       " 'Some of the suggested insights in the analysis of defense techniques are interesting.\\n',\n",
       " '1.00: (Some of the suggested insights in the analysis of defense techniques; are; interesting.)\\n',\n",
       " '\\n',\n",
       " 'Cons:\\n',\n",
       " '\\n',\n",
       " 'The is not much technical novelty.\\n',\n",
       " '1.00: (The; is not; much technical novelty.)\\n',\n",
       " '\\n',\n",
       " 'The method boils down to applying Reluplex (Katz et al 2017b) in a binary search (although I acknowledge the extension to L1 as distance metric).\\n',\n",
       " '0.95: (The method; boils down; to applying Reluplex (Katz et al 2017b) in a binary search)\\n',\n",
       " '1.00: (I; acknowledge; the extension to L1 as distance metric).)\\n',\n",
       " '\\n',\n",
       " 'The practical application of the method is very limited since the search is very slow and is only feasible at all for relatively small models.\\n',\n",
       " '0.94: (The practical application of the method; is; very limited since the search is very slow and is only feasible at all for relatively small models.)\\n',\n",
       " '1.00: (the search; is; very slow)\\n',\n",
       " '0.79: (the search; is at; only feasible all for relatively small models.)\\n',\n",
       " '\\n',\n",
       " 'State-of-the-art practical models that achieve accuracy rates that make them interesting for deployment in potentially safety critical applications are out of reach for this analysis.\\n',\n",
       " '1.00: (State-of-the-art practical models; achieve; accuracy rates that make them interesting for deployment in potentially safety critical applications)\\n',\n",
       " '1.00: (accuracy rates; make; them interesting for deployment in potentially safety critical applications)\\n',\n",
       " '0.92: (State-of-the-art practical models that achieve accuracy rates that; are; out of reach for this analysis.)\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id = 0\n",
    "templist = []\n",
    "\n",
    "sent_triples = {}\n",
    "\n",
    "for i in l:\n",
    "    if i == \"\\n\":\n",
    "        try:\n",
    "            sent_triples[sent_id] = [templist[0], templist[1]]\n",
    "        except Exception as ex:\n",
    "            continue\n",
    "        sent_id += 1\n",
    "        templist = []\n",
    "    else:\n",
    "        templist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['The authors propose to use k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting.\\n',\n",
       "  '0.89: (The authors; propose; to use k-DPP and use them to search for a good a hyperparameter setting.)\\n'],\n",
       " 1: ['This paper covers the related work nicely, with details on both closed loop and open loop methods.\\n',\n",
       "  '1.00: (This paper; covers nicely,; the related work)\\n'],\n",
       " 2: ['The rest of the paper are also clearly written.\\n',\n",
       "  '0.99: (The rest of the paper; are also clearly written.; )\\n'],\n",
       " 3: ['However, I have some concerns about the proposed method.\\n',\n",
       "  '1.00: (I; have; some concerns about the proposed method.)\\n'],\n",
       " 4: ['- It is not clear how to define the kernel, the feature function and the quality function for the proposed method.\\n',\n",
       "  '0.99: (It; is not; clear how)\\n'],\n",
       " 5: ['The choices of those seem to have a huge impact on the performance.\\n',\n",
       "  '1.00: (The choices of those; seem; )\\n'],\n",
       " 6: ['How was those functions decided and how sensitive is the result to hyperparameters of those functions?\\n',\n",
       "  '0.99: (those functions how sensitive; is; the result to hyperparameters of those functions?)\\n'],\n",
       " 7: ['- If the search space is continuous, what is the mixing rate of Algorithm 2?\\n',\n",
       "  '1.00: (the search space; is; continuous,)\\n'],\n",
       " 8: ['In practice, how is \"mixed\" decided?\\n',\n",
       "  '0.96: (how \"mixed\"; is decided?; )\\n'],\n",
       " 9: ['What exactly is the space and time complexity?\\n',\n",
       "  '0.99: (What exactly; is; the space and time complexity?)\\n'],\n",
       " 10: [\"I'm not sure where k log(N) comes from in page 7)\\n\",\n",
       "  \"1.00: (I'm; not; sure where k log(N) comes from in page 7))\\n\"],\n",
       " 11: ['- Algorithm 2 is a straight forward extension of Algorithm 1, just with L not explicitly computed.\\n',\n",
       "  '1.00: (Algorithm 2; is; a straight forward extension of Algorithm 1,)\\n'],\n",
       " 12: ['I think it would have more novelty if some theoretical analyses can be shown on the mixing rate and how good this optimization algorithm is.\\n',\n",
       "  '0.92: (some theoretical analyses; can be shown; on the mixing rate and)\\n'],\n",
       " 13: ['Other small things:\\n',\n",
       "  '- citation format problems in, for example, Section 4.1) It should be \\\\citep instead of \\\\cite.\\n'],\n",
       " 14: ['- it would be good to mention Figure 2 in the text first before showing it.\\n',\n",
       "  '[Post rebuttal]\\n'],\n",
       " 15: ['I would like to thank the authors for their clarifications.\\n',\n",
       "  '1.00: (I; would like; to thank the authors for their clarifications.)\\n'],\n",
       " 16: ['However, I am still concerned with the novelty.\\n',\n",
       "  '1.00: (I; am; still concerned with the novelty.)\\n'],\n",
       " 17: ['The absence of provable mixing rate is also a potential weakness.\\n',\n",
       "  '1.00: (The absence of provable mixing rate; is also; a potential weakness.)\\n'],\n",
       " 18: ['I think a clearer emphasis on the novelty, eg: current algorithm with mixing rate analyses or more thorough empirical comparisons will make the paper stronger for resubmission.\\n',\n",
       "  '0.48: (I current algorithm with mixing rate analyses or more thorough empirical comparisons; think will make; a clearer emphasis on the novelty, the paper stronger for resubmission.)\\n'],\n",
       " 19: ['I reviewed the same paper last year.\\n',\n",
       "  '1.00: (I; reviewed; the same paper last year.)\\n'],\n",
       " 20: ['I am appending a few lines based on the changes made by authors.\\n',\n",
       "  '1.00: (I; am appending; a few lines based on the changes)\\n'],\n",
       " 21: ['The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).\\n',\n",
       "  '0.93: (The authors; propose; k-DPP as an open loop)\\n'],\n",
       " 22: ['The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new, so the main contribution here is the empirical study.\\n',\n",
       "  '1.00: (The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters; are not; new,)\\n'],\n",
       " 23: ['The first experiment by the authors shows that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner (Figure 1).\\n',\n",
       "  '0.20: (The first experiment by the authors; shows; that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner)\\n'],\n",
       " 24: ['The second experiment shows surprisingly that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Figure 2, column 1).\\n',\n",
       "  '0.62: (The second experiment; shows surprisingly; that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Figure)\\n'],\n",
       " 25: ['The third experiment shows that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.\\n',\n",
       "  '0.99: (The third experiment; shows; that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.)\\n'],\n",
       " 26: ['I have a few reservations.\\n',\n",
       "  '1.00: (I; have; a few reservations.)\\n'],\n",
       " 27: ['First, I do not find these outcomes very surprising or informative, except for the second experiment (Figure 2, column 1).\\n',\n",
       "  '0.95: (I; do not find; these outcomes very surprising or informative, except for the second experiment First,)\\n'],\n",
       " 28: ['Second, their study only applies to a small number like 3-6 hyperparameters with a small k=20) The real challenge lies in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al (http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf) and Snoek et al (https://arxiv.org/pdf/1502.05700.pdf) that is essential for this kind of empirical study.\\n',\n",
       "  '0.16: (the authors; do not compare is; against some relevant, recent work, e.g., essential for this kind of empirical study.)\\n'],\n",
       " 29: ['COMMENTS ON THE CHANGES SINCE THE LAST YEAR\\n',\n",
       "  'I am not convinced by the comparison with Spearmint added by the authors since the previous version.\\n'],\n",
       " 30: ['It is unclear to me if the comparison of wall clock time and accuracy holds for larger number of hyperparameters or against Spearmint with more parallelization.\\n',\n",
       "  '0.92: (It and; is; unclear to me)\\n'],\n",
       " 31: ['In addition the authors do not compare against more recent work, e.g.,\\n',\n",
       "  '0.94: (the authors; do not compare e.g.,; against more recent work,)\\n'],\n",
       " 32: ['@INPROCEEDINGS{falkner-bayesopt17,\\n',\n",
       "  'author = {S. Falkner and A. Klein and F. Hutter},\\n'],\n",
       " 33: ['title = {Combining Hyperband and Bayesian Optimization},\\n',\n",
       "  'booktitle = {NIPS 2017 Bayesian Optimization Workshop},\\n'],\n",
       " 34: ['year = {2017},\\n', 'month = dec,\\n'],\n",
       " 35: ['}\\n', '@InProceedings{falkner-icml-18,\\n'],\n",
       " 36: ['title = {{BOHB}: Robust and Efficient Hyperparameter Optimization at Scale},\\n',\n",
       "  'author = {Falkner, Stefan and Klein, Aaron and Hutter, Frank},\\n'],\n",
       " 37: ['booktitle = {Proceedings of the 35th International Conference on Machine Learning (ICML 2018)},\\n',\n",
       "  'pages = {1436--1445},\\n'],\n",
       " 38: ['year = {2018},\\n', 'month = jul,\\n'],\n",
       " 39: ['- This paper proposes an approach to get samples with high dispersion for hyperparameter optimisation.\\n',\n",
       "  '1.00: (This paper; proposes; an approach to get samples with high dispersion for hyperparameter optimisation.)\\n'],\n",
       " 40: ['- It theoretically motivates the use of Determinantal Point Processes in yielding such samples.\\n',\n",
       "  '1.00: (It; theoretically motivates; the use of Determinantal Point Processes in yielding such samples.)\\n'],\n",
       " 41: ['- Further, an iterative mixing algorithm is proposed to handle continuous and discrete sample space.\\n',\n",
       "  '1.00: (an iterative mixing algorithm; is proposed; )\\n'],\n",
       " 42: ['- Experiments on finding hyperparameter for sentence classification are presented.\\n',\n",
       "  '0.99: (Experiments on finding hyperparameter for sentence classification; are presented.; )\\n'],\n",
       " 43: ['In terms of accuracy, it performs better than other open-loop methods.\\n',\n",
       "  '0.96: (it; performs better; than other open-loop methods. of accuracy,)\\n'],\n",
       " 44: ['In comparison to closed-loop methods, it yields parameter settings with comparable performance but with gains in wall clock time.\\n',\n",
       "  '1.00: (it; yields; parameter settings In comparison to closed-loop methods,)\\n'],\n",
       " 45: ['- The distinction from close-loop approaches makes it easy to parallelise.\\n',\n",
       "  '1.00: (The distinction from close-loop approaches; makes; it easy to parallelise.)\\n'],\n",
       " 46: ['This paper is novel in its modelling of hyperparameter optimisation with DPP and the theoretical justification and experiments have been clearly presented.\\n',\n",
       "  '0.63: (This paper; is; novel in its modelling of hyperparameter optimisation with DPP and the theoretical justification and experiments)\\n'],\n",
       " 47: ['It would be interesting to explore the practicability of the method on more large-scale experiments on image related tasks.\\n',\n",
       "  '0.00: (It interesting; to; explore the practicability of the method on more large-scale experiments on image related tasks.)\\n'],\n",
       " 48: ['The proposed regularizer seems to be a particular combination of existing methods.\\n',\n",
       "  '1.00: (The proposed regularizer; seems; )\\n'],\n",
       " 49: ['Though the implied connection between nonlinearities and stochastic regularizers is intriguing, in my opinion the empirical performance does not exceed the performance achieved by similar methods by a large enough margin to arrive at a meaningful conclusion.\\n',\n",
       "  '1.00: (the implied connection between nonlinearities and stochastic regularizers; is; intriguing,)\\n'],\n",
       " 50: ['The method proposed essential trains neural networks without a traditional nonlinearity, using multiplicative gating by the CDF of a Gaussian evaluated at the preactivation; this is motivated as a relaxation of a probit-Bernoulli stochastic gate.\\n',\n",
       "  '0.80: (a Gaussian this; evaluated motivated; at the preactivation; as a relaxation of a probit-Bernoulli stochastic gate.)\\n'],\n",
       " 51: ['Experiments are performed with both.\\n',\n",
       "  '1.00: (Experiments; are performed; with both.)\\n'],\n",
       " 52: ['The work is somewhat novel and interesting.\\n',\n",
       "  '1.00: (The work; is; somewhat novel and interesting.)\\n'],\n",
       " 53: ['Little is said about why this is preferable to other similar parameterizations of the same (sigmoidal?\\n',\n",
       "  '0.99: (Little; is said; about why this is preferable to other similar parameterizations of the same (sigmoidal?)\\n'],\n",
       " 54: ['softsign?\\n', 'etc.)\\n'],\n",
       " 55: ['It would be stronger with more empirical interrogation of why this works and exploration of the nearby conceptual space.\\n',\n",
       "  '1.00: (It; would be; stronger with more empirical interrogation of why this works and exploration of the nearby conceptual space.)\\n'],\n",
       " 56: [\"The CIFAR results look okay by today's standards but the MNIST results are quite bad, neural nets were doing better than 1.5% a decade ago and the SOI map results (and the ReLU baseline) are above 2%.\\n\",\n",
       "  '0.96: (CIFAR the MNIST results; are; quite bad,)\\n'],\n",
       " 57: [\"(TIMIT results on frame classification also aren't that interesting without evaluating word error rate within a speech pipeline, but this is a minor point.)\\n\",\n",
       "  \"0.98: (results on frame classification; also aren't; that interesting)\\n\"],\n",
       " 58: ['The idea put forth that SOI map networks without additional nonlinearities are comparable to linear functions is rather misleading as they are, in expectation, nonlinear functions of their input.\\n',\n",
       "  '0.95: (The idea; put; forth)\\n'],\n",
       " 59: ['Varying an input example by multiplying or adding a constant will not be linearly reflected in the expected output of the network.\\n',\n",
       "  '0.28: (Varying an input example by multiplying or adding a constant; will not be linearly reflected; in the expected output of the network.)\\n'],\n",
       " 60: ['In this sense they are more nonlinear than ReLU networks which are at least locally linear.\\n',\n",
       "  '1.00: (they; are; more nonlinear than ReLU networks In this sense)\\n'],\n",
       " 61: ['The plots are very difficult to read in grayscale,\\n',\n",
       "  '1.00: (The plots; are; very difficult to read in grayscale,)\\n'],\n",
       " 62: ['Approaches like adaptive dropout also have the binary mask as a function of input to a neuron very similar to the proposed approach.\\n',\n",
       "  '1.00: (Approaches like adaptive dropout; have; the binary mask as a function of input to a neuron very similar to the proposed approach.)\\n'],\n",
       " 63: ['It is not clear, even from the new draft, how the proposed approach differs to Adaptive dropout in terms of functionality.\\n',\n",
       "  '0.92: (It; is not; clear, even from the new draft,)\\n'],\n",
       " 64: ['The experimental validation is also not extensive since comparison to SOTA is not included.\\n',\n",
       "  '0.00: (The experimental validation; is also not; extensive since comparison to SOTA is not included.)\\n'],\n",
       " 65: ['This paper proposed an effective defense against model stealing attacks.\\n',\n",
       "  '0.98: (This paper; proposed; an effective defense against model stealing)\\n'],\n",
       " 66: ['Merits:\\n',\n",
       "  '1) In general, this paper is well written and easy to follow.\\n'],\n",
       " 67: ['2) The approach is a significant supplement to existing defense against model stealing attacks.\\n',\n",
       "  '0.98: (The approach; is; a significant supplement to existing defense against model stealing attacks.)\\n'],\n",
       " 68: ['3) Extensive experiments.\\n',\n",
       "  'However, I still have concerns about the current version.\\n'],\n",
       " 69: [\"I will possibly adjust my score based on the authors' response.\\n\",\n",
       "  \"1.00: (I; will possibly adjust; my score based on the authors' response.)\\n\"],\n",
       " 70: ['1) In the model stealing setting, attacker and defender are seemingly knowledge limited.\\n',\n",
       "  '1.00: (the model; stealing; setting,)\\n'],\n",
       " 71: ['This should be clarified better in Section 3) It is important to highlight that the defender has no access to F_A, thus problem (4) is a black-box optimization problem for defense.\\n',\n",
       "  '0.44: (This thus problem; be better; a black-box for defense.)\\n'],\n",
       " 72: ['Also, it is better to have a table to summarize the notations.\\n',\n",
       "  '0.89: (a table; to summarize; have the notations.)\\n'],\n",
       " 73: ['Additional questions on problem formulation:\\n',\n",
       "  'a) Problem (4) only relies on the transfer set, where $x \\\\sim P_A(x)$, right?\\n'],\n",
       " 74: ['b) For evaluation metrics, utility and non-replicability, do they have the same D^{test}?\\n',\n",
       "  '1.00: (they; have; the same D^{test}?)\\n'],\n",
       " 75: ['How to determine them, in particularly for F_A?\\n',\n",
       "  '0.86: (How; to determine; them, in particularly for F_A?)\\n'],\n",
       " 76: ['c) One utility constraint is missing in problem (4).\\n',\n",
       "  '0.98: (One utility constraint; is missing; in problem (4).)\\n'],\n",
       " 77: ['I noticed that it was mentioned in MAD-argmax, however, I suggest to add it to the formulation (4).\\n',\n",
       "  '0.92: (it I; suggest; MAD-argmax, to add it to the formulation)\\n'],\n",
       " 78: ['2) The details of heuristic solver are unclear.\\n',\n",
       "  '0.97: (2) The details of heuristic solver; are; unclear.)\\n'],\n",
       " 79: ['Although the authors pointed out the pseudocode in the appendix, it lacks detailed analysis.\\n',\n",
       "  '0.97: (the authors; pointed out; the pseudocode in the appendix,)\\n'],\n",
       " 80: ['3) In Estimating G, how to select the surrogate model?\\n',\n",
       "  '0.93: (3) G,; to select; the surrogate model? In Estimating)\\n'],\n",
       " 81: ['Moreover, in the experiment, the authors mentioned that defense performances are unaffected by choice of architectures, and hence use the victim architecture for the stolen model.\\n',\n",
       "  '0.96: (defense performances; hence use; the victim architecture for the stolen model.)\\n'],\n",
       " 82: ['If possible, could the author provide results on different architecture choices for the stolen model as well as the surrogate model?\\n',\n",
       "  '0.99: (the author; provide; results on different architecture choices for the stolen model as well as the surrogate model?)\\n'],\n",
       " 83: ['############## Post-feedback ################\\n',\n",
       "  \"I am satisfied with the authors' response.\\n\"],\n",
       " 84: ['Thus, I would like to keep my positive comments on this paper.\\n',\n",
       "  '1.00: (I; would like; to keep my positive comments on this paper.)\\n'],\n",
       " 85: ['Although the paper is between 6 and 8, I finally decide to increase my score to 8 due to its novelty in formulation and extensive experiments.\\n',\n",
       "  '1.00: (the paper; is; between 6 and 8,)\\n'],\n",
       " 86: ['The paper proposes a new method for defending against stealing attacks.\\n',\n",
       "  '1.00: (The paper; proposes; a new method for defending against stealing attacks.)\\n'],\n",
       " 87: ['Positives:\\n', '1) The paper was very readable and clear.\\n'],\n",
       " 88: ['2) The proposed method is straightforward and well motivated.\\n',\n",
       "  '1.00: (The proposed method; is; straightforward and well motivated.)\\n'],\n",
       " 89: ['3) The authors included a good amount of experimental results.\\n',\n",
       "  '1.00: (The authors; included; a good amount of experimental results.)\\n'],\n",
       " 90: ['Concerns:\\n',\n",
       "  '1) You note that the random perturbation to the outputs performs poorly compared to your method, but this performance gap seems to decrease as the dataset becomes more difficult (ie CIFAR100).\\n'],\n",
       " 91: [\"I'm concerned that this may indicate that the attackers are generally weak and this threat model may not be very serious.\\n\",\n",
       "  '0.99: (this threat model; may not be; very serious.)\\n'],\n",
       " 92: [\"Overall, I'm skeptical of this threat model - the attackers require a very large number of queries, and don't achieve great results on difficult datasets.\\n\",\n",
       "  '0.99: (the attackers; require; a very large number of queries,)\\n'],\n",
       " 93: ['Including results on a dataset like ImageNet would be nice.\\n',\n",
       "  '0.00: (Including results on a dataset like ImageNet; would be; nice.)\\n'],\n",
       " 94: ['2) How long does this optimization procedure take?\\n',\n",
       "  '0.94: (this optimization procedure; take?; How long does)\\n'],\n",
       " 95: ['It seems possibly unreasonable for the victim to implement this defense if it significantly lengthens the time to return outputs of queries.\\n',\n",
       "  '1.00: (the victim; to implement; this defense)\\n'],\n",
       " 96: ['3) Although this is a defense paper, it would be nice if the attacks were explained a bit more.\\n',\n",
       "  '1.00: (this; is; a defense paper,)\\n'],\n",
       " 97: ['Specifically, how are these attacks tested?\\n',\n",
       "  'You use the validation set, but does the attacker have knowledge about the class-label space of the victim?\\n'],\n",
       " 98: [\"If the attacker trained with some synthetic data/other dataset, do you then freeze the feature extractor and train a linear layer to validate on the victim's test set?\\n\",\n",
       "  '1.00: (the attacker; trained; with some synthetic data/other dataset,)\\n'],\n",
       " 99: [\"It seems like this is discussed in the context of the victim in the ''Attack Models'' subsection, but it's unclear what's happening with the attacker.\\n\",\n",
       "  \"0.97: (It this; seems is discussed; in the context of the victim in the ''Attack Models'' subsection,)\\n\"],\n",
       " 100: [\"4) It would be nice to see an angular histogram plot for a model where the perturbed labels were not crafted with knowledge of this model's parameters - ie transfer the proposed defense to a blackbox attacker and produce this same plot.\\n\",\n",
       "  '0.87: (the perturbed labels; were not crafted; plot for a model)\\n'],\n",
       " 101: ['This would motivate the defense more.\\n',\n",
       "  '0.98: (This; would motivate more.; the defense)\\n'],\n",
       " 102: ['This paper aims at defending against model stealing attacks by perturbing the posterior prediction of a protected DNN with a balanced goal of maintaining accuracy and maximizing misleading gradient deviation.\\n',\n",
       "  '0.00: (This paper; aims stealing; at defending against model by perturbing the posterior prediction of a protected DNN with a balanced goal of maintaining accuracy and maximizing misleading gradient deviation.)\\n'],\n",
       " 103: ['The maximizing angular deviation formulation makes sense and seemingly correct.\\n',\n",
       "  '0.89: (The maximizing angular deviation formulation; makes; sense and seemingly correct.)\\n'],\n",
       " 104: ['The heuristic solver toward this objective is shown to be relatively effective in the experiments.\\n',\n",
       "  '1.00: (The heuristic solver toward this objective; is shown; )\\n'],\n",
       " 105: ['While the theoretical novelty of the method is limited, the application in adversarial settings may be useful to advance of this research field, especially when it is relatively easy to apply by practitioners.I recommend toward acceptance of this paper even though can be convinced otherwise by better field experts.\\n',\n",
       "  '1.00: (the theoretical novelty of the method; is; limited,)\\n'],\n",
       " 106: ['This work presents the Simple Recurrent Unit architecture which allows more parallelism than the LSTM architecture while maintaining high performance.\\n',\n",
       "  '1.00: (This work; presents; the Simple Recurrent Unit architecture)\\n'],\n",
       " 107: ['Significance, Quality and clarity:\\n',\n",
       "  'The idea is well motivated: Faster training is important for rapid experimentation, and altering the RNN cell so it can be paralleled makes sense.\\n'],\n",
       " 108: ['The idea is well explained and the experiments convince that the new architecture is indeed much faster yet performs very well.\\n',\n",
       "  '0.99: (The idea; is well explained; )\\n'],\n",
       " 109: ['A few constructive comments:\\n',\n",
       "  \"- The experiment's tables alternate between ''time'' and ''speed'', It will be good to just have one of them.\\n\"],\n",
       " 110: ['- Table 4 has time/epoch yet only time is stated\\n',\n",
       "  '0.96: (Table 4; has; time/epoch only time)\\n'],\n",
       " 111: ['The authors introduce SRU, the Simple Recurrent Unit that can be used as a substitute for LSTM or GRU cells in RNNs.\\n',\n",
       "  '1.00: (The authors; introduce; SRU,)\\n'],\n",
       " 112: ['SRU is much more parallel than the standard LSTM or GRU, so it trains much faster: almost as fast as a convolutional layer with properly optimized CUDA code.\\n',\n",
       "  '0.91: (SRU; is fast; much more parallel than the standard LSTM or GRU,)\\n'],\n",
       " 113: ['Authors perform experiments on numerous tasks showing that SRU performs on par with LSTMs, but the baselines for these tasks are a little problematic (see below).\\n',\n",
       "  '0.99: (Authors; perform; experiments on numerous tasks)\\n'],\n",
       " 114: ['On the positive side, the paper is very clear and well-written, the SRU is a superbly elegant architecture with a fair bit of originality in its structure, and the results show that it could be a significant contribution to the field as it can probably replace LSTMs in most cases but yield fast training.\\n',\n",
       "  '0.45: (it; can probably replace; LSTMs in most cases)\\n'],\n",
       " 115: ['On the negative side, the authors present the results without fully referencing and acknowledging state-of-the-art.\\n',\n",
       "  '1.00: (the authors; present; the results On the negative side,)\\n'],\n",
       " 116: ['Some of this has been pointed out in the comments below already.\\n',\n",
       "  '0.95: (Some of this; has been pointed out; in the comments below already.)\\n'],\n",
       " 117: ['As another example: Table 5 that presents results for English-German WMT translation only compares to OpenNMT setups with maximum BLEU about 21) But already a long time ago Wu et al presented LSTMs reaching 25 BLEU and current SOTA is above 28 with training time much faster than those early models (https://arxiv.org/abs/1706.03762).\\n',\n",
       "  '0.99: (Table 5; presents; results for English-German WMT translation)\\n'],\n",
       " 118: ['While the latest are non-RNN architectures, a table like Table 5 should include them too, for a fair presentation.\\n',\n",
       "  '1.00: (the latest; are; non-RNN architectures,)\\n'],\n",
       " 119: ['In conclusion: the authors seem to avoid discussing the problem that current non-RNN architectures could be both faster and yield better results on some of the studied problems.\\n',\n",
       "  '1.00: (the authors; seem; In conclusion:)\\n'],\n",
       " 120: [\"That's bad presentation of related work and should be improved in the next versions (at which point this reviewer is willing to revise the score).\\n\",\n",
       "  \"0.04: (That's; should be improved; in the next versions)\\n\"],\n",
       " 121: ['But in all cases, this is a significant contribution to deep learning and deserves acceptance.\\n',\n",
       "  '0.94: (this; is; a significant contribution to deep learning deserves in all cases,)\\n'],\n",
       " 122: [\"Update: the revised version of the paper addresses all my concerns and the comments show new evidence of potential applications, so I'm increasing my score.\\n\",\n",
       "  '0.75: (the revised version of the paper the comments; addresses show; all my concerns and new evidence of potential applications,)\\n'],\n",
       " 123: ['The authors propose to drop the recurrent state-to-gates connections from RNNs to speed up the model.\\n',\n",
       "  '1.00: (The authors; propose; to drop the recurrent state-to-gates connections from RNNs)\\n'],\n",
       " 124: ['The recurrent connections however are core to an RNN.\\n',\n",
       "  '1.00: (The recurrent connections; are; core to an RNN.)\\n'],\n",
       " 125: ['Without them, the RNN defaults simply to a CNN with gated incremental pooling.\\n',\n",
       "  '0.92: (the RNN; defaults simply; to a CNN with gated incremental pooling.)\\n'],\n",
       " 126: ['This results in a somewhat unfortunate naming (simple *recurrent* unit), but most importantly makes a comparison with autoregressive sequence CNNs [ Bytenet (Kalchbrenner et al 2016), Conv Seq2Seq (Dauphin et al, 2017) ] crucial in order to show that gated incremental pooling is beneficial over a simple CNN architecture baseline.\\n',\n",
       "  '1.00: (This; results; in a somewhat unfortunate naming)\\n'],\n",
       " 127: ['In essence, the paper shows that autoregressive CNNs with gated incremental pooling perform comparably to RNNs on a number of tasks while being faster to compute.\\n',\n",
       "  '0.71: (the paper; shows; that autoregressive CNNs with gated incremental pooling perform comparably to RNNs on a number of tasks while being faster to compute. In essence,)\\n'],\n",
       " 128: ['Since it is already extensively known that autoregressive CNNs and attentional models can achieve this, the *CNN* part of the paper cannot be counted as a novel contribution.\\n',\n",
       "  '0.49: (the *CNN* part of the paper; is extensively known cannot be counted; already)\\n'],\n",
       " 129: ['What is left is the gated incremental pooling operation; but to show that this operation is beneficial when added to autoregressive CNNs, a thorough comparison with an autoregressive CNN baseline is necessary.\\n',\n",
       "  '1.00: (What is left; is; the gated incremental pooling operation;)\\n'],\n",
       " 130: ['Pros:\\n', '- Fairly well presented\\n'],\n",
       " 131: ['- Wide range of experiments, despite underwhelming absolute results\\n',\n",
       "  '0.94: (- Wide range of experiments,; despite underwhelming; absolute results)\\n'],\n",
       " 132: ['Cons:\\n',\n",
       "  '- Quasi-RNNs are almost identical and already have results on small-scale tasks.\\n'],\n",
       " 133: ['- Slightly unfortunate naming that does not account for autoregressive CNNs\\n',\n",
       "  '1.00: (Slightly unfortunate naming; does not account; for autoregressive CNNs)\\n'],\n",
       " 134: ['- Lack of comparison with autoregressive CNN baselines, which signals a major conceptual error in the paper.\\n',\n",
       "  '0.99: (Lack of comparison with autoregressive CNN baselines,; signals; a major conceptual error in the paper.)\\n'],\n",
       " 135: ['- I would suggest to focus on a small set of tasks and show that the model achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.\\n',\n",
       "  '0.96: (I; would suggest; to focus on a small set of tasks and show that the model achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.)\\n'],\n",
       " 136: ['I recommend showing exhaustively and experimentally that gated incremental pooling can be helpful for autoregressive CNNs on sequence tasks (MT, LM and ASR).\\n',\n",
       "  '0.69: (I; recommend; showing exhaustively and experimentally that gated incremental pooling can be helpful CNNs sequence)\\n'],\n",
       " 137: ['I will adjust my score accordingly if the experiments are presented.\\n',\n",
       "  '0.97: (I; will adjust accordingly; my score if)\\n'],\n",
       " 138: ['Contribution:\\n',\n",
       "  'The paper proposes to use a set of handcrafted intrinsic rewards that depend on the novelty of an observation as perceived by the rest of the other agents.\\n'],\n",
       " 139: ['For each pair of reward and agent, they learn a policy and a value through actor critic method, and then a meta-policy choses at the beginning of each episode which intrinsic rewards to use, meaning that the policy used by the agents corresponds to the one that maximizes the reward chosen.\\n',\n",
       "  '0.85: (they; learn; a policy and a value For each pair of reward and agent,)\\n'],\n",
       " 140: ['Review:\\n',\n",
       "  'The major limitation of the paper in my opinion is the fact that the \"coordination\" that occurs here is only happening at training time, not at execution time.\\n'],\n",
       " 141: ['The agents eventually learn whatever trajectory they need to perform, and then proceed to do so without any interaction with the other agents.\\n',\n",
       "  '0.98: (The agents; learn; whatever trajectory they need to perform, and then proceed to do so without any interaction with the other agents. eventually)\\n'],\n",
       " 142: [\"In a sense, they don't even learn to explore collaboratively.\\n\",\n",
       "  \"1.00: (they; don't even learn; to explore collaboratively. In a sense,)\\n\"],\n",
       " 143: ['In other words, agents trained on task 1 in a given maze would not be able to solve task 2 on the same maze without essentially relearning everything from scratch.\\n',\n",
       "  '0.98: (agents; trained; on task 1 in a given maze)\\n'],\n",
       " 144: ['The other corollary of the fact that each agent learns its own policy is that the number of agents is fixed at training time, preventing testing with a different number of agents, as sometimes done in the literature ([1] [2]).\\n',\n",
       "  '1.00: (each agent; learns; its own policy)\\n'],\n",
       " 145: ['Given this limitation the scope of the work basically reduces to the exploration of a fixed environment when the action space can be factored into different agents.\\n',\n",
       "  '1.00: (the scope of the work; basically reduces; to the exploration of a fixed environment)\\n'],\n",
       " 146: ['This \"multi-agent\" formulation is presumably meant to break down the computational complexity of having a joint observation/action space.\\n',\n",
       "  '1.00: (This \"multi-agent\" formulation; is presumably meant; )\\n'],\n",
       " 147: ['However, the experiments are conducted only with a very limited number of agents (only 2 in the non toy environment of vizdoom).\\n',\n",
       "  '0.99: (the experiments; are conducted; only with a very limited number of agents)\\n'],\n",
       " 148: [\"This small scale doesn't, in my opinion, demonstrate the advantage of the decomposition of the MDP over say SOTA single-agent exploration methods applied to the cartesian product of all the agents action spaces (in vizdoom the paper considers only 3 actions, so with two agents it would amount to 9 actions, which is still very tractable).\\n\",\n",
       "  \"0.06: (This small scale; doesn't, demonstrate would amount; the advantage of the decomposition of the MDP over say SOTA single-agent exploration methods applied the agents action spaces (in vizdoom the paper 3 actions, to 9 actions, still very tractable).)\\n\"],\n",
       " 149: ['Once the trajectories of both agents are found, they can be distilled to each of them individually so that they only depend on the local observation.\\n',\n",
       "  '1.00: (the trajectories of both agents; are found,; )\\n'],\n",
       " 150: [\"Regarding the experiments on the Vizdoom environment, it appears that the traditional evaluation setup [3] doesn't involve providing the global position (x,y) to the agents as part of the observations (they must be inferred from the visual feed), contrary to the experimental setup presented in this paper.\\n\",\n",
       "  '0.96: (the experimental setup; presented; in this paper.)\\n'],\n",
       " 151: ['In my opinion, this weakens the claim that the method \"scales to more complex environments\" since providing the position essentially makes the environment similar to a grid-world (arguably the visual feed isn\\'t even needed to solve the task.\\n',\n",
       "  '0.53: (this; weakens; the claim that the method \"scales to more complex environments\" since providing the position essentially makes the environment similar to a grid-world isn\\'t even In my opinion,)\\n'],\n",
       " 152: ['The use of a dynamic policy selection is somewhat interesting, but would benefit better investigation.\\n',\n",
       "  '1.00: (The use of a dynamic policy selection; is; somewhat interesting,)\\n'],\n",
       " 153: ['Firstly, it is not clear to me if all the selection of the policy to use during training affects all the trajectories of the batch, or if different episodes of the batch may have a different policy.\\n',\n",
       "  '0.92: (all the selection of the policy; to use; during training)\\n'],\n",
       " 154: ['Secondly, it seems that the setting is typically the one of a (non-stationary) bandit, since there is no state and the \"reward\" is the return obtained by the policy.\\n',\n",
       "  '0.95: (the \"reward\"; is; the return obtained by the policy.)\\n'],\n",
       " 155: ['Could you share the reason behind the choice of an actor-critic algorithm over classical bandit algorithms?\\n',\n",
       "  '1.00: (you; share; the reason behind the choice of an actor-critic algorithm over classical bandit algorithms?)\\n'],\n",
       " 156: ['One obvious advantage of the latter are provable regret bounds.\\n',\n",
       "  '1.00: (One obvious advantage of the latter; are; provable regret bounds.)\\n'],\n",
       " 157: ['In all, the selection policy seems to be useful during training, since it sometimes yields better solutions than any of the individual reward schemes.\\n',\n",
       "  '0.97: (the selection policy; seems; In all,)\\n'],\n",
       " 158: [\"It suggests that some form of curriculum over the rewards is occurring during training, but if this is really what is going on, then it's possible that the relevant literature about curriculum learning may offer more stable and principled solutions than an actor critic, for example population based training.\\n\",\n",
       "  '0.69: (It; suggests is really; that what is going on,)\\n'],\n",
       " 159: ['This could potentially solve the issues observed in task 2.\\n',\n",
       "  '1.00: (This; could potentially solve; the issues observed in task 2.)\\n'],\n",
       " 160: ['[1] Relational Deep Reinforcement Learning, Zambaldi et al, https://arxiv.org/abs/1806.01830\\n',\n",
       "  '0.88: (Relational Deep Reinforcement Zambaldi; Learning, et; al,)\\n'],\n",
       " 161: ['[2] A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learning, Carion et al, https://arxiv.org/abs/1910.08809\\n',\n",
       "  '0.87: (Carion; et al, https://arxiv.org/abs/1910.08809; )\\n'],\n",
       " 162: ['[3] Curiosity-driven Exploration by Self-supervised Prediction, Pathak et al, ICML 2017\\n',\n",
       "  '0.92: (Curiosity-driven Exploration by Self-supervised Prediction, Pathak; et al,; 2017)\\n'],\n",
       " 163: ['Overall I like the approach in the paper.\\n',\n",
       "  '0.97: (Overall I; like; the approach in the paper.)\\n'],\n",
       " 164: ['It proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems.\\n',\n",
       "  '1.00: (It; proposes; a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems.)\\n'],\n",
       " 165: ['The parts that a bit lacking with the current version of the paper in this are the evaluation tasks are few and a bit simple and I think there needs to be more discussion on the \"coverage\" of the intrinsic reward types.\\n',\n",
       "  '0.94: (The a bit; lacking; with the current version of the paper in this)\\n'],\n",
       " 166: ['Are the ones proposed motivated by the tasks in the paper or are they sufficient for tasks in general?\\n',\n",
       "  '0.92: (the ones; proposed motivated; by the tasks in the paper)\\n'],\n",
       " 167: ['Last using a more recent novelty metric could allow the method to work on more interesting/complex tasks.\\n',\n",
       "  '1.00: (Last using a more recent novelty metric; could allow; the method to work on more interesting/complex tasks.)\\n'],\n",
       " 168: ['More detailed feedback:\\n',\n",
       "  '- It would be good to include more learning curves in the main text for the paper.\\n'],\n",
       " 169: ['- The fact that applying intrinsic motivation to multi-agent simulations seems like a natural idea would be to convert the problem to a \"single\" agent problem to compare against the \"normal\" application of intrinsic rewards.\\n',\n",
       "  '0.97: (The fact that applying intrinsic motivation to multi-agent simulations; seems; )\\n'],\n",
       " 170: ['This might be another baseline to consider for comparison.\\n',\n",
       "  '1.00: (This; might be; another baseline to consider for comparison.)\\n'],\n",
       " 171: ['- It says that all agents share the same replay buffer.\\n',\n",
       "  '1.00: (It; says; that all agents share the same replay buffer.)\\n'],\n",
       " 172: ['Does this also imply that every agent is performing the same task there are just many agents?\\n',\n",
       "  '0.96: (this every agent; is performing; the same task there are just many agents?)\\n'],\n",
       " 173: ['This does not make the problem very multi-agent with different goals.\\n',\n",
       "  '1.00: (This; does not make; the problem very multi-agent with different goals.)\\n'],\n",
       " 174: ['Would it affect the algorithm significantly to work on an environment where the agents have various types of goals?\\n',\n",
       "  '1.00: (the agents; have; various types of goals? an environment)\\n'],\n",
       " 175: ['- As is noted in the text, this method appears to work well in the centralized training scheme that many have adopted recently.\\n',\n",
       "  '0.99: (this method; appears; )\\n'],\n",
       " 176: ['However, It makes me wonder if there is a way to employ these exploration schemes in a non-centralized training form.\\n',\n",
       "  '1.00: (It; makes; me wonder if there is a way)\\n'],\n",
       " 177: ['The ability to ask other agents in the world about there preferences and novelty of states appears to be a strong assumption, especially in a multi-agent robotics problem.\\n',\n",
       "  '1.00: (The ability to ask other agents in the world about there preferences and novelty of states; appears; )\\n'],\n",
       " 178: ['- While the authors note that the intrinsic rewards used in this work are not comprehensive it would be good to note how comprehensive they are.\\n',\n",
       "  '1.00: (the authors; note; that the intrinsic rewards used in this work are not comprehensive)\\n'],\n",
       " 179: ['Are there a few that were left out on purpose.\\n',\n",
       "  '1.00: (a few; were left out; on purpose.)\\n'],\n",
       " 180: ['Do the authours believe this set is sufficient.\\n',\n",
       "  '0.94: (the authours this set; believe; is sufficient.)\\n'],\n",
       " 181: ['This statement makes it seem like the authors just tried a few options and found one that worked.\\n',\n",
       "  '0.85: (one; found worked.; and that)\\n'],\n",
       " 182: ['It would be good to expand on this discussion more.\\n',\n",
       "  '0.97: (It; be; good to expand on this discussion more.)\\n'],\n",
       " 183: ['- More detail for Figure 1 would be helpful to understand the overall network design.\\n',\n",
       "  '1.00: (More detail for Figure 1; would be; helpful to understand the overall network design.)\\n'],\n",
       " 184: ['While that figure it helpful maybe it would be good to include a version that goes into detail for the 2 agent environment.\\n',\n",
       "  '0.90: (a version; goes; into detail for the 2 agent environment.)\\n'],\n",
       " 185: ['Then a more compressed n agent version can also be shown.\\n',\n",
       "  '0.96: (a more compressed n agent version; can also be shown.; Then)\\n'],\n",
       " 186: ['- The paper describes a policy selector that is a type of high-level policy for HRL.\\n',\n",
       "  '1.00: (The paper; describes; a policy selector that is a type of high-level policy for HRL.)\\n'],\n",
       " 187: ['This design seems rather unique in that this part of the policy can optimizing for which intrinsic reward to toggle based on the extrinsic rewards observed.\\n',\n",
       "  '0.97: (This design; seems; )\\n'],\n",
       " 188: ['I like it.\\n', '1.00: (I; like; it.)\\n'],\n",
       " 189: ['It is noted that entropy is important for this design.\\n',\n",
       "  'Can this be analyzed in an empirical way?\\n'],\n",
       " 190: ['Is this true for most environments/tasks?\\n',\n",
       "  '0.97: (this; Is; true for most environments/tasks?)\\n'],\n",
       " 191: ['- Task 2 seems a bit contrived.\\n',\n",
       "  '1.00: (Task 2; seems; a bit contrived.)\\n'],\n",
       " 192: ['Is there another instance of this type of task elsewhere in another paper?\\n',\n",
       "  'It would be better to use more standard tasks if they are available.\\n'],\n",
       " 193: ['- Before section 6.1 the paper is discussing rewards the are received.\\n',\n",
       "  '0.90: (section 6.1 the paper; is discussing; rewards the are received.)\\n'],\n",
       " 194: ['It would be good to more explicit about where these rewards are coming from.\\n',\n",
       "  '0.99: (It; would be; good to more explicit about where these rewards are coming from.)\\n'],\n",
       " 195: ['I think it is meant that these rewards are the extrinsic rewards but it does not say.\\n',\n",
       "  '1.00: (it; does not say.; )\\n'],\n",
       " 196: ['- As noted just before section 6.1 it seems for the collection of tasks 1-3 it is already obvious what types of intrinsic rewards should be used.\\n',\n",
       "  '0.93: (it; seems; for the collection of tasks)\\n'],\n",
       " 197: ['It would be good to include more tasks where this decision is less obvious.\\n',\n",
       "  '0.80: (It this decision; include is; less obvious. more tasks)\\n'],\n",
       " 198: ['- Why are there \"black holes\" in the environment?\\n',\n",
       "  'Also if an agent steps into a black hole they are crushed never to be seen again.\\n'],\n",
       " 199: ['What you describe sounds more like a wormhole where one end is non-stationary... Also, can the agents detect the presence of a black hole in some way?\\n',\n",
       "  '0.96: (you; describe; wormhole)\\n'],\n",
       " 200: ['- It appears the novel metric is count based.\\n',\n",
       "  '0.89: (It the novel metric; appears is based.; count)\\n'],\n",
       " 201: ['While this can work in practice it seems a rather simple metric.\\n',\n",
       "  '1.00: (this; can work; in practice)\\n'],\n",
       " 202: ['Is it possible to use something more like ICM or RND that was referenced in the paper?\\n',\n",
       "  '1.00: (something more like ICM or RND; was referenced; in the paper?)\\n'],\n",
       " 203: ['Especially for the VizDoom environment?\\n',\n",
       "  '- In table 2 where are some of the numbers bold?\\n'],\n",
       " 204: ['It would be good to include this information in the caption for the table.\\n',\n",
       "  '0.95: (It; be; good to include this information in the caption for the table.)\\n'],\n",
       " 205: ['- I am not sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.\\n',\n",
       "  '0.97: (I; am not; sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.)\\n'],\n",
       " 206: ['Maybe there is a more interesting behaviour that results from the combination of two intrinsic rewards?\\n',\n",
       "  '1.00: (a more interesting behaviour; results; from the combination of two intrinsic rewards?)\\n'],\n",
       " 207: ['Summary:\\n',\n",
       "  'The paper proposes a method for coordinating the exploration efforts of agents in a multi-agent reinforcement learning setting.\\n'],\n",
       " 208: ['The approach has two main components: (i) learning different exploration policies using different \"joint\" intrinsic rewards; and (ii) learning a higher-level policy that selects one of the exploration policies to be executed at the beginning of each episode.\\n',\n",
       "  '0.99: (The approach; has; two main components: (i) learning different exploration policies using different \"joint\" intrinsic rewards;)\\n'],\n",
       " 209: ['Each agent has its own novelty function which quantifies the novelty of observation seen by that agent.\\n',\n",
       "  '1.00: (Each agent; has; its own novelty function which quantifies the novelty of observation)\\n'],\n",
       " 210: ['To coordinate exploration, these novelty functions are combined using aggregation functions to produce intrinsic reward for the agent.\\n',\n",
       "  '0.93: (these novelty functions; are combined; using aggregation functions produce)\\n'],\n",
       " 211: ['Each such aggregating function yields a different intrinsic reward.\\n',\n",
       "  '1.00: (Each such aggregating function; yields; a different intrinsic reward.)\\n'],\n",
       " 212: ['The authors propose several such aggregating functions as examples, however the method is applicable to other aggregating functions as well, as long as they can be computed off-policy.\\n',\n",
       "  '0.72: (they; as can be computed; off-policy.)\\n'],\n",
       " 213: ['During training, the higher level policy selects one of the exploration policies which is then executed for the entire episode.\\n',\n",
       "  '1.00: (the higher level policy; selects; one of the exploration policies During training,)\\n'],\n",
       " 214: ['The episode data is used in two ways: (i) to train the higher-level policy using policy gradients for maximizing extrinsic rewards along with an entropy term; and (ii) to train each exploration policy using soft actor-critic on its own intrinsic reward function (and extrinsic reward) in an off-policy manner.\\n',\n",
       "  '1.00: (The episode data; is used; )\\n'],\n",
       " 215: ['Experiments done on grid-world and VizDoom environment for three different tasks demonstrate that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards.\\n',\n",
       "  '1.00: (Experiments; done; on grid-world and VizDoom environment for three different tasks)\\n'],\n",
       " 216: ['Further ablation studies confirm that both the hierarchical setup and the \"joint\" intrinsic rewards are useful.\\n',\n",
       "  '1.00: (Further ablation studies; confirm; that both the hierarchical setup and the \"joint\" intrinsic rewards are useful.)\\n'],\n",
       " 217: ['Questions to the Authors:\\n',\n",
       "  '1) The second sentence in section 5 is not clear - \"Furthermore, the type of reward ... sufficiently complex\".\\n'],\n",
       " 218: ['The high-level policy selects an exploration strategy at the beginning of each episode and then sticks to it for the entire duration of the episode.\\n',\n",
       "  '0.99: (The high-level policy; selects; an exploration strategy at the beginning of each episode)\\n'],\n",
       " 219: ['Changing the exploration strategy over the course of training might be useful in cases when agent needs to switch to a different exploration strategy after reaching a particular bottleneck state.\\n',\n",
       "  '1.00: (Changing the exploration strategy over the course of training; might be; useful in cases)\\n'],\n",
       " 220: ['However, this would require the exploration strategy to be changed in the middle of an episode which is not supported.\\n',\n",
       "  '0.00: (this; would require; the exploration strategy to be changed in the middle of an episode)\\n'],\n",
       " 221: ['Could you give an example where the exploration strategy must be changed over time even if one only selects the strategy at the beginning of each episode?\\n',\n",
       "  '0.95: (the exploration strategy; must be changed; where over time an example)\\n'],\n",
       " 222: ['Also, why not select the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?\\n',\n",
       "  '0.01: (why; not select; the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?)\\n'],\n",
       " 223: ['2) Analyzing the role of high-level policy and its evolution over time on different tasks would be a very nice addition to the paper.\\n',\n",
       "  '1.00: (2) Analyzing the role of high-level policy and its evolution over time on different tasks; would be; a very nice addition to the paper.)\\n'],\n",
       " 224: ['Qualitative experiments demonstrating that it provides a curriculum which helps the agents in surpassing the performance of individual intrinsic rewards would be helpful.\\n',\n",
       "  '0.88: (it provides a curriculum; helps; the agents in surpassing the performance of individual intrinsic rewards)\\n'],\n",
       " 225: ['3) Should \\\\Pi in (10) also depend on i?\\n',\n",
       "  '0.96: (Should \\\\Pi in; depend; on i?)\\n'],\n",
       " 226: ['Though paper is reasonably well written I find the contributions are very marginal.\\n',\n",
       "  '0.99: (paper; is reasonably well written; )\\n'],\n",
       " 227: ['If authors can position the paper well with the existing literature and bring out the impact of the contributions it will be helpful.\\n',\n",
       "  '0.95: (authors; can position well; the paper)\\n'],\n",
       " 228: ['Summary: The paper proposes a method to compute adversarial examples with minimum distance to the original inputs, and to use the method to do two things: Show how well heuristic methods do in finding \"optimal/minimal\" adversarial examples (how close the come to the minimal change that flips the label) and to assess how a method that is designed to make the model more robust to adversarial examples actually works.\\n',\n",
       "  '0.85: (The paper; proposes; a method to compute adversarial examples with minimum distance to the original inputs, and the)\\n'],\n",
       " 229: ['Pros:\\n', 'I like the idea and the proposed applications.\\n'],\n",
       " 230: ['It is certainly highly relevant, both in terms of assessing models for critical use cases as well as a tool to better understand the phenomenon.\\n',\n",
       "  '1.00: (It; is certainly; highly relevant,)\\n'],\n",
       " 231: ['Some of the suggested insights in the analysis of defense techniques are interesting.\\n',\n",
       "  '1.00: (Some of the suggested insights in the analysis of defense techniques; are; interesting.)\\n'],\n",
       " 232: ['Cons:\\n', 'The is not much technical novelty.\\n'],\n",
       " 233: ['The method boils down to applying Reluplex (Katz et al 2017b) in a binary search (although I acknowledge the extension to L1 as distance metric).\\n',\n",
       "  '0.95: (The method; boils down; to applying Reluplex (Katz et al 2017b) in a binary search)\\n'],\n",
       " 234: ['The practical application of the method is very limited since the search is very slow and is only feasible at all for relatively small models.\\n',\n",
       "  '0.94: (The practical application of the method; is; very limited since the search is very slow and is only feasible at all for relatively small models.)\\n'],\n",
       " 235: ['State-of-the-art practical models that achieve accuracy rates that make them interesting for deployment in potentially safety critical applications are out of reach for this analysis.\\n',\n",
       "  '1.00: (State-of-the-art practical models; achieve; accuracy rates that make them interesting for deployment in potentially safety critical applications)\\n'],\n",
       " 236: ['The network analysed here does not reach the state-of-the-art on MNIST from almost two decades ago.\\n',\n",
       "  '1.00: (The network; analysed; here)\\n'],\n",
       " 237: ['The analysis also has to be done for each sample.\\n',\n",
       "  '1.00: (The analysis; to be done; for each sample.)\\n'],\n",
       " 238: ['The long runtime does not permit to analyse large amounts of input samples, which makes the analysis in terms of the increase in robustness rather weak.\\n',\n",
       "  '0.97: (amounts input samples,; makes; the analysis)\\n'],\n",
       " 239: ['The statement can only be made for the very limited set of tested samples.\\n',\n",
       "  '1.00: (The statement; can only be made; for the very limited set of tested samples.)\\n'],\n",
       " 240: ['It is also unclear whether it is possible to include distance metrics that capture more sophisticated attacks that fool network even under various transformations of the input.\\n',\n",
       "  '0.96: (distance metrics; capture; more sophisticated attacks that fool network even under various transformations of the input.)\\n'],\n",
       " 241: [\"The paper does not consider the more recent and highly relevant Moosavi-Dezfooli et al ''Universal Adversarial Perturbations'' CVPR 2017.\\n\",\n",
       "  \"1.00: (The paper; does not consider; the more recent and highly relevant Moosavi-Dezfooli et al ''Universal Adversarial Perturbations'')\\n\"],\n",
       " 242: [\"The distance metrics that are considered are only L_inf and L1, whereas it would be interesting to see more relevant ''perceptual losses'' such as those used in style transfer and domain adaptation with GANs.\\n\",\n",
       "  '1.00: (The distance metrics; are considered; )\\n'],\n",
       " 243: ['Minor details:\\n',\n",
       "  \"* I would consider calling them ''minimal adversarial samples'' instead of ''ground-truth''.\\n\"],\n",
       " 244: [\"* I don't know if the notation in the Equation in the paragraph describing Carlini & Wagner comes from the original paper, but the inner max would be easier to read as \\\\max_{i \\\\neq t} \\\\{Z(x')_i \\\\}\\n\",\n",
       "  '0.95: (the paragraph; describing; Carlini & Wagner)\\n'],\n",
       " 245: [\"* Page 3 ''Neural network verification'': I dont agree with the statement that neural networks commonly are trained on ''a small set of inputs''.\\n\",\n",
       "  \"1.00: (I; dont agree; with the statement that neural networks commonly are trained on ''a small set of inputs''.)\\n\"],\n",
       " 246: ['* Algorithm 1 is essentially only a description of binary search, which should not be necessary.\\n',\n",
       "  '1.00: (Algorithm 1; is essentially; only a description of binary search,)\\n'],\n",
       " 247: ['* What is the timeout for the computation, mentioned in Section 4?\\n',\n",
       "  '0.98: (is the timeout for the computation,; mentioned; in Section 4?)\\n'],\n",
       " 248: [\"* Page 7, second paragraph: I wouldn't say the observation is in line with Carlini & Wagner, because they take a random step, not necessarily one in the direction of the optimum?\\n\",\n",
       "  '0.26: (they; take not necessarily; a random step, one in the direction of the optimum?)\\n'],\n",
       " 249: [\"That's also the conclusion two paragraphs below, no?\\n\",\n",
       "  \"0.99: (That's; also; the conclusion two paragraphs below, no?)\\n\"],\n",
       " 250: [\"* I don't fully agree with the conclusion that the defense of Madry does not overfit to the specific method of creating adversarial examples.\\n\",\n",
       "  \"1.00: (I; don't fully agree; with the conclusion that the defense of Madry does not overfit to the specific method of creating adversarial examples.)\\n\"],\n",
       " 251: ['Those were not created with the CW attack, but are related because CW was used to initialize the search.\\n',\n",
       "  '1.00: (Those; were not created; with the CW attack,)\\n'],\n",
       " 252: ['The authors propose to employ provably minimal-distance examples as a tool to evaluate the robustness of a trained network.\\n',\n",
       "  '1.00: (The authors; propose; to employ provably minimal-distance examples as a tool)\\n'],\n",
       " 253: ['This is demonstrated on a small-scale network using the MNIST data set.\\n',\n",
       "  '1.00: (This; is demonstrated; on a small-scale network)\\n'],\n",
       " 254: ['First of all, I find it striking that a trained network with 97% accuracy (as claimed by the authors) seems extremely brittle -- considering the fact that all the adversarial examples in Figure 1 are hardly borderline examples at all, at least to my eyes.\\n',\n",
       "  '0.14: (all the adversarial examples in Figure 1; find are; it striking that a trained network with 97% accuracy (as claimed by the authors) extremely brittle -- considering the fact that hardly borderline examples at all, at least to my eyes.)\\n'],\n",
       " 255: ['This does reinforce the (well-known?)\\n',\n",
       "  '1.00: (This; does reinforce; the (well-known?))\\n'],\n",
       " 256: ['weakness of neural networks in general.\\n',\n",
       "  'I therefore find the authors\\' statement on page 3 disturbing: \"... they are trained over a small set of inputs, and can then perform well, in general, on previously-unseen inputs\" -- which seems false (with high probability over all possible worlds).\\n'],\n",
       " 257: ['Secondly, the term \"ground truth\" example seems very misleading to me.\\n',\n",
       "  '0.98: (the term \"ground truth\" example; seems; very misleading to me.)\\n'],\n",
       " 258: ['Perhaps \"closest misclassified examples\"?\\n',\n",
       "  '0.91: (\"closest misclassified examples\"?; Perhaps; )\\n'],\n",
       " 259: ['Finally, while the idea of \"closest misclassified examples\" seems interesting, I am not convinced that they are the right way to go when it comes to both building and evaluating robustness.\\n',\n",
       "  '0.99: (the idea of \"closest misclassified examples\"; seems; interesting,)\\n'],\n",
       " 260: ['All such examples shown in the paper are indeed within-class examples that are misclassified.\\n',\n",
       "  '1.00: (All such examples; shown; in the paper)\\n'],\n",
       " 261: ['But we could equally consider another extreme, where the trained network is \"over-regularized\" in the sense that the closest misclassified examples are indeed from another class, and therefore \"correctly\" misclassified.\\n',\n",
       "  '0.92: (we; could equally consider; another extreme, where the trained network is \"over-regularized\" in the sense that the closest misclassified examples are indeed from another class,)\\n'],\n",
       " 262: ['Adding these as adversarial examples could seriously degrade the accuracy.\\n',\n",
       "  '1.00: (adversarial examples; could seriously degrade; the accuracy.)\\n'],\n",
       " 263: ['Also, for building robustness, one could argue that adding misclassified examples that are \"furthest\" (ie closest to the true decision boundary) is a much more efficient training approach, since a few of these can possibly subsume a large number of close examples.\\n',\n",
       "  '0.24: (one a few of these; possibly; adding misclassified examples that are \"furthest\" (ie closest to the true decision boundary) can a large number of close examples.)\\n'],\n",
       " 264: ['The paper describes a method for generating so called ground truth adversarial examples: adversaries that have minimal (L1 or L_inf) distance to the training example used to generate them.\\n',\n",
       "  '1.00: (The paper; describes; a method for generating so called ground truth adversarial examples:)\\n'],\n",
       " 265: ['The technique uses the recently developed reluplex, which can be used to verify certian properties of deep neural networks that use ReLU activations.\\n',\n",
       "  '1.00: (The technique; uses; the recently developed reluplex, which can be used to verify certian properties of deep neural networks)\\n'],\n",
       " 266: ['The authors show how the L1 distance can be formulated using a ReLU and therefore extend the reluplex also work with L1 distances.\\n',\n",
       "  '0.61: (The authors the L1 distance; using; a ReLU therefore extend the reluplex work)\\n'],\n",
       " 267: ['The experiments on MNIST suggest that the C&W attack produces close to optimal adversarial examples, although it is not clear if these findings would transfer to larger more complex networks.\\n',\n",
       "  '0.79: (MNIST it findings; is not; clear)\\n'],\n",
       " 268: ['The evaluation also suggests that training with iterative adversarial examples does not overfit and does indeed harden the network to attacks in many cases.\\n',\n",
       "  '0.94: (training with iterative adversarial examples; does indeed harden; the network to attacks in many cases.)\\n'],\n",
       " 269: ['In general, this is a nice idea, but it seems like the inherent computational cost will limit the applicability of this approach to small networks and datasets for the time being.\\n',\n",
       "  '1.00: (this; is; a nice idea,)\\n'],\n",
       " 270: ['Incidentally, it would have been useful if the authors provided indicative information on the computational cost (eg: in the form of time on a standard GPU) for generating these ground truths and carrying out experiments.\\n',\n",
       "  '1.00: (it; would have been; useful)\\n'],\n",
       " 271: ['The experiments are quite small scale, which I expect is due to the computational cost of generating the adversarial examples.\\n',\n",
       "  '0.98: (The experiments; are; quite small scale, which I expect is due to the computational cost of generating the adversarial examples.)\\n'],\n",
       " 272: ['It is difficult to say how far the findings can be generalized from MNIST to more realistic situations.\\n',\n",
       "  '0.87: (the findings; to say can be generalized; how far from MNIST to more realistic situations.)\\n'],\n",
       " 273: ['Tests on another dataset would have been welcomed.\\n',\n",
       "  '1.00: (Tests on another dataset; would have been welcomed.; )\\n'],\n",
       " 274: ['Also, while interesting, are adversarial examples that have minimal L_p distance from training examples really that useful in practice?\\n',\n",
       "  '0.77: (adversarial examples; have; minimal L_p distance from training examples really that useful in practice?)\\n'],\n",
       " 275: [\"Of course, it's nice that we can find these, but it could be argued that L_p norms are not a good way of judging the similarity of an adversarial example to a true example.\\n\",\n",
       "  '1.00: (we; can find; these,)\\n'],\n",
       " 276: ['I think it would be more useful to investigate attacks that are perceptually insignificant, or attacks that operate in the physical world, as these are more likely to be a concern for real world systems.\\n',\n",
       "  '0.50: (I; think; it would be more useful to investigate attacks that or attacks to be a concern for real world systems.)\\n'],\n",
       " 277: [\"In summary, while I think the paper is interesting, I suspect that the applicability of this technique is possibly limited at present, and I'm unsure how much we can really read into the findings of the paper when the experiments are based on MNIST alone.\\n\",\n",
       "  '0.72: (the experiments; think are based; on MNIST alone.)\\n'],\n",
       " 278: ['This paper is not standalone.\\n',\n",
       "  '1.00: (This paper; is not; standalone.)\\n'],\n",
       " 279: ['A section on the basics of document analysis would have been nice.\\n',\n",
       "  '1.00: (A section on the basics of document analysis; would have been; nice.)\\n'],\n",
       " 280: ['The work proposes Tensor Product Decomposition Networks (TRDN) as a way to uncover the representation learned in recurrent neural networks (RNNs).\\n',\n",
       "  '1.00: (The work; proposes; Tensor Product Decomposition Networks)\\n'],\n",
       " 281: ['TRDN trains a Tensor Product Representation, which additively combine tensor products of role (e.g., sequence position) embeddings and filler (e.g., word) embeddings to approximate the encoding produced by RNNs.\\n',\n",
       "  '0.97: (TRDN; trains; a Tensor Product Representation, which)\\n'],\n",
       " 282: ['TRDN as a result shed light into inspecting and interpreting representation learned through RNNs.\\n',\n",
       "  '0.93: (TRDN as a result; shed; light inspecting and interpreting representation)\\n'],\n",
       " 283: ['The authors suggest that the structures captured in RNNs are largely compositional and can be well captured by TPRs without recurrence and nonlinearity.\\n',\n",
       "  '1.00: (the structures; captured; in RNNs)\\n'],\n",
       " 284: ['pros:\\n',\n",
       "  '1) The paper is mostly clearly written and easy to follow.\\n'],\n",
       " 285: ['The diagrams shown in Figure 2 are illustrative;\\n',\n",
       "  '1.00: (The diagrams; shown; in Figure 2)\\n'],\n",
       " 286: ['2) TRDN offers a headway to look into and interpret the representations learned in RNNs, which remained largely incomprehensible;\\n',\n",
       "  '0.67: (2) TRDN RNNs,; remained; into and largely incomprehensible;)\\n'],\n",
       " 287: ['3) The analysis and insight provided in section 4 is interesting and insightful.\\n',\n",
       "  '1.00: (The analysis and insight; provided; in section 4)\\n'],\n",
       " 288: ['In particular, how does the training task influence the kinds of structural representation learned.\\n',\n",
       "  '0.92: (the training task influence the kinds of structural representation; learned.; )\\n'],\n",
       " 289: ['cons:\\n',\n",
       "  '1) The method relies heavily on these manually crafted role schemes as shown in section 2.1; It is unclear the gap in the approximation of TPRs to the encodings learned in RNNs are due to inaccurate role definition or in fact RNNs learn more complex structural dependencies which TPRs cannot capture;\\n'],\n",
       " 290: ['2) The MSE of approximation error shown in Table 1 are not informative.\\n',\n",
       "  '1.00: (approximation error; shown; in Table 1)\\n'],\n",
       " 291: ['How should these numbers be interpreted?\\n',\n",
       "  '0.95: (these numbers; be interpreted?; should)\\n'],\n",
       " 292: ['Why normalizing by dividing by the MSE from training TPDN on random vectors?\\n',\n",
       "  '3) The alignment between prediction using RNN representations and TPDN approximations shown in Table 2 are far from perfect, which would contradict with the claim that RNNs only learn tensor-product representation.\\n'],\n",
       " 293: ['This paper presents an analysis of popularly-use RNN model for structure modeling abilities by designing Tensor Product Decomposition Networks to approximate the encoder.\\n',\n",
       "  '1.00: (This paper; presents; an analysis of popularly-use RNN model for structure modeling abilities)\\n'],\n",
       " 294: ['The results show that the representations exhibit interpretable compositional structure.\\n',\n",
       "  '1.00: (The results; show; that the representations exhibit interpretable compositional structure.)\\n'],\n",
       " 295: ['To provide better understanding, the paper evaluates the performance on synthesized digit sequence data as well as several sentence-encoding tasks.\\n',\n",
       "  '0.95: (the paper; evaluates; the performance on synthesized digit sequence data as well as several sentence-encoding tasks.)\\n'],\n",
       " 296: ['Pros:\\n', '1) The paper is well-written and easy to follow.\\n'],\n",
       " 297: ['The design of the TPDN and corresponding settings (including what an filler is and what roles are included) for experiments are understandable.\\n',\n",
       "  '0.97: (an filler; is; )\\n'],\n",
       " 298: ['It makes good point at the end of the paper (section 4) on how these analysis contribute to further design of RNN models, which seems useful.\\n',\n",
       "  '1.00: (It; makes; good point at the end of the paper)\\n'],\n",
       " 299: ['2) The experiments are extensive to support their claims.\\n',\n",
       "  '0.96: (2) The experiments; are; extensive to support their claims.)\\n'],\n",
       " 300: ['Not only synthetic data but also several popularly-used data and models are being conducted and compared.\\n',\n",
       "  '0.86: (Not only synthetic data also several popularly-used data and models; are being conducted; )\\n'],\n",
       " 301: ['An addition of analogy dataset further demonstrate the effect of TPDN on modeling structural regularities.\\n',\n",
       "  '1.00: (An addition of analogy dataset; demonstrate; the effect of TPDN on modeling structural regularities.)\\n'],\n",
       " 302: ['Cons:\\n',\n",
       "  \"1) More detailed and extensive discussion on the contribution of the paper should be included in the introduction part to help readers understand what's the point of investigating TPDN on RNN models.\\n\"],\n",
       " 303: ['2) Some details are missing to better understand the construction.\\n',\n",
       "  '0.99: (Some details; are missing; to better understand the construction.)\\n'],\n",
       " 304: ['For example, on page 4, Evaluation, it is unclear of how TPDN encoder is trained, specifically, which parameters are updated?\\n',\n",
       "  '0.94: (TPDN encoder; is trained, specifically,; )\\n'],\n",
       " 305: [\"What's the objective for training?\\n\",\n",
       "  'It is also unclear of whether the models in Figure 3(c) use bidirectional or unidirectional or tree decoder?\\n'],\n",
       " 306: ['In Section 3, it could be better to roughly introduce each of the existing 4 models.\\n',\n",
       "  '0.93: (it; could be; better to roughly introduce each of the existing 4 models. In Section 3,)\\n'],\n",
       " 307: ['How do TPDN trained for these 4 sentence encoding models need to be further illustrated.\\n',\n",
       "  '0.89: (TPDN these 4 sentence encoding models; to be illustrated.; further)\\n'],\n",
       " 308: ['More reasons should be discussed for the results in Table 2 (why bag-of-words role seem to be ok, why skip-thought cannot be approximated well).\\n',\n",
       "  '1.00: (More reasons; should be discussed; for the results in Table 2)\\n'],\n",
       " 309: ['3) It could be better to provide the actual performance (accuracy) given by TPDN on the 4 existing tasks.\\n',\n",
       "  '0.89: (It; be; better to provide the actual performance (accuracy) given by TPDN on the 4 existing tasks.)\\n'],\n",
       " 310: ['4) Further thoughts: have you considered applying these analysis on other models besides RNN?\\n',\n",
       "  '0.99: (you; considered; applying these analysis on other models besides RNN?)\\n'],\n",
       " 311: ['The paper describes new norm-based generalization bounds that were specifically adapted to convolutional neural networks.\\n',\n",
       "  '1.00: (The paper; describes; new norm-based generalization bounds that were specifically adapted to convolutional neural networks.)\\n'],\n",
       " 312: ['Since convolutional neural networks do not explicitly depend on the input dimension, these bounds share the same property.\\n',\n",
       "  '1.00: (convolutional neural networks; do not explicitly depend; on the input dimension,)\\n'],\n",
       " 313: ['Further additional improvement over Bartlett et al 17 bound, is that this new bound depends on the sum of the operator norms of the parameter matrices, rather than the product.\\n',\n",
       "  '0.61: (Further additional improvement over Bartlett et al 17 bound,; is; that this new bound depends on the sum of the operator norms of the parameter matrices, rather than the product.)\\n'],\n",
       " 314: ['The paper is clearly written and self-contained.\\n',\n",
       "  '0.99: (The paper; is clearly written; and self-contained.)\\n'],\n",
       " 315: ['I appreciate that the authors added a detailed comparison to Bartlett et al 17 bound.\\n',\n",
       "  '0.94: (Bartlett al; bound.; )\\n'],\n",
       " 316: ['However, the main result seems to be very incremental.\\n',\n",
       "  '1.00: (the main result; seems; )\\n'],\n",
       " 317: ['The experiments are also very limited and not too convincing.\\n',\n",
       "  '1.00: (The experiments; are also; very limited and not too convincing.)\\n'],\n",
       " 318: ['Further empirical evaluation is needed to demonstrate progress.\\n',\n",
       "  '1.00: (Further empirical evaluation; is needed; to demonstrate progress.)\\n'],\n",
       " 319: ['I would be willing to increase my score if the authors added a comparison to Wei and Ma 19, and more evidence was provided that the bound is tighter for typical convolutional networks found in practice (please see detailed comments below).\\n',\n",
       "  '1.00: (I; would be; willing to increase my score)\\n'],\n",
       " 320: ['Detailed comments:\\n',\n",
       "  'I see Wei and Ma 19 cited in the beginning only, but there is no further comparison.\\n'],\n",
       " 321: ['They also proved bounds with similar dependencies.\\n',\n",
       "  '1.00: (They; proved; bounds with similar dependencies.)\\n'],\n",
       " 322: ['How do the bounds presented in the paper compare to Wei and Ma bounds?\\n',\n",
       "  '1.00: (the bounds; presented; in the paper)\\n'],\n",
       " 323: ['What is the dependence of the constant C on \\\\eta in the bounds presented in Theorem 2.1?\\n',\n",
       "  '1.00: (the bounds; presented; in Theorem 2.1?)\\n'],\n",
       " 324: ['It is unclear what trade-off comes with eta and how the empirical risk term is balanced with the complexity term, since \\\\eta only appears next to the empirical risk term.\\n',\n",
       "  '0.91: (the empirical risk term; is balanced; with the complexity term,)\\n'],\n",
       " 325: ['The authors demonstrate via a concrete example that there exists a setting (depending on epsilon), under which this new bound (up to constants) is tighter than Bartlett et al bound.\\n',\n",
       "  '0.01: (a concrete example a setting (depending under this new bound (up to constants) Bartlett et; demonstrate is bound.; there exists tighter than al)\\n'],\n",
       " 326: ['Three things remain unclear to me:\\n',\n",
       "  '1.00: (Three things; remain; unclear to me:)\\n'],\n",
       " 327: ['- How do the constants differ?\\n',\n",
       "  '1.00: (the constants; differ?; )\\n'],\n",
       " 328: ['Is the bound presented in the paper tighter in absolute terms?\\n',\n",
       "  '- Is the bound tighter when the norms in the bounded are measured on typical trained neural network weights?\\n'],\n",
       " 329: ['An analysis of a few networks used in practice would make the comparison more meaningful (included the comparison to Wei and Ma).\\n',\n",
       "  '1.00: (a few networks; used; in practice)\\n'],\n",
       " 330: ['- Is the bound not worse than a VC bound in any (reasonable) setting?\\n',\n",
       "  '1.00: (a VC; bound; in any (reasonable) setting?)\\n'],\n",
       " 331: ['If not, is the bound tighter under typical settings when training standard vision networks?\\n',\n",
       "  '0.91: (the bound under typical settings; training; when standard vision networks?)\\n'],\n",
       " 332: ['Other minor comments.\\n', 'In the introduction, the authors:\\n'],\n",
       " 333: ['- say that their bounds are size-free, which refers to the bounds not having an explicit dependence on the input size.\\n',\n",
       "  '0.97: (the bounds; not having; an explicit dependence on the input size.)\\n'],\n",
       " 334: [\"In my opinion, this comes almost ''for free'' when using convolutional neural network.\\n\",\n",
       "  \"0.95: (this; comes; almost free'' when using convolutional neural network.)\\n\"],\n",
       " 335: ['Also, I think that size-free in the title is misleading, and should be replaced with input size-free.\\n',\n",
       "  '0.98: (that size-free in the title; should be replaced; with input size-free.)\\n'],\n",
       " 336: ['- mention that most recent bounds depend on the distance from the initialization instead of the size of the weights.\\n',\n",
       "  '0.96: (that most recent bounds; depend; on the distance from the initialization instead of the size of the weights.)\\n'],\n",
       " 337: ['This idea was first presented in Dziugate and Roy 17, which does not seem to be cited there.\\n',\n",
       "  '0.98: (This idea; was presented; in Dziugate and Roy 17, first)\\n'],\n",
       " 338: ['*** UPDATE ***\\n', '0.99: (UPDATE; ***; )\\n'],\n",
       " 339: [\"I've reread the rebuttals and feel that most of my concerns have been addressed.\\n\",\n",
       "  \"1.00: (I've; reread; the rebuttals)\\n\"],\n",
       " 340: ['I increased my score to weak accept.\\n',\n",
       "  '1.00: (I; increased; my score to weak accept.)\\n'],\n",
       " 341: ['The paper considers the generalization bound for deep neural networks, specifically, convolutional neural networks, which is one of the popular and crucial topics in the machine learning community, which has gathered a lot of attention.\\n',\n",
       "  '0.94: (The paper; considers; the generalization bound for deep neural networks, specifically, convolutional neural networks, is)\\n'],\n",
       " 342: ['The paper presents a generalization bound based on the number of parameters, the Lipschitz constant of the loss function and the distance of the final weights from the initialization, without dependence on the dimension of the input.\\n',\n",
       "  '0.96: (The paper; presents; a generalization bound based on the number of parameters, the Lipschitz constant of the loss function and the distance of the final weights from the initialization, without dependence on the dimension of the input.)\\n'],\n",
       " 343: ['The bound improves upon previous bound in some regimes when the size convolutional kernel is much less than the width of the network, which is a reasonable assumption.\\n',\n",
       "  '0.56: (The bound the size convolutional kernel; is; in some regimes much less than the width of the network,)\\n'],\n",
       " 344: ['The paper also gives another bound which works for fully connected layers with an additional term that is linear with the depth of the network.\\n',\n",
       "  '1.00: (The paper; gives; another bound which works for fully connected layers with an additional term)\\n'],\n",
       " 345: ['The paper has some nice ideas, but the contribution of the paper is not clear for me.\\n',\n",
       "  '1.00: (The paper; has; some nice ideas,)\\n'],\n",
       " 346: ['The main theorems are based on previous results (Lemma 2.3).\\n',\n",
       "  '1.00: (The main theorems; are based; on previous results)\\n'],\n",
       " 347: ['And the remaining work of the paper is mainly deriving the Lipchitz bound to be used in the theorem for various kinds of networks.\\n',\n",
       "  '0.99: (the remaining work of the paper; is mainly deriving; the Lipchitz)\\n'],\n",
       " 348: ['I think this should be clearly stated in the paper.\\n',\n",
       "  '1.00: (I; think; this should be clearly stated in the paper.)\\n'],\n",
       " 349: ['The experiment part is not quite convincing.\\n',\n",
       "  '1.00: (The experiment part; is not; quite convincing.)\\n'],\n",
       " 350: ['It is not clear from the figures that the norm decreases with the number of parameters in the network, which is claimed in the paper.\\n',\n",
       "  '1.00: (It; is not; clear from the figures)\\n'],\n",
       " 351: ['The writing of the paper also can be improved.\\n',\n",
       "  '0.98: (The writing of the paper; also can be improved.; )\\n'],\n",
       " 352: ['The paper presents math, which is nice, but without much intuition explained.\\n',\n",
       "  '0.96: (The paper; presents; math, which is nice, but without much intuition explained.)\\n'],\n",
       " 353: ['Overall I would not recommend this paper for admission.\\n',\n",
       "  '0.97: (Overall I; would not recommend; this paper for admission.)\\n'],\n",
       " 354: ['Summary\\n',\n",
       "  'This paper studied the generalization power of CNNs and showed several upper bounds of generalization errors.\\n'],\n",
       " 355: ['Their results have two characteristics.\\n',\n",
       "  '1.00: (Their results; have; two characteristics.)\\n'],\n",
       " 356: ['First, the bounds are in terms of the quantity that is independent of the input dimension (size-free).\\n',\n",
       "  '1.00: (the bounds; are; in terms of the quantity First,)\\n'],\n",
       " 357: ['Second, the upper bounds involve the distance between initial and learned parameters.\\n',\n",
       "  '1.00: (the upper bounds; involve; the distance between initial and learned parameters.)\\n'],\n",
       " 358: ['These results improved the upper bounds that we can derive by naively applying the results of Bartlett et al (2017) or Neushubar et al (2017), because the dominant term of the existing upper bounds contained $l_{2, 1}$ or $l_2$ norms, which could depend on the input dimensions in the worst case.\\n',\n",
       "  '0.62: (These results; improved; the upper bounds that we can derive by naively applying the results of Bartlett et al (2017) or Neushubar et al (2017),)\\n'],\n",
       " 359: ['The authors empirically showed that there is a correlation between the generalization error of learned CNNs and the dominant term of the upper bound (i.e., the product of the parameter size and the distance from the set of initial parameters).\\n',\n",
       "  '0.87: (The authors; empirically showed; that there is a correlation between the generalization error of learned CNNs and the dominant term of the upper bound (i.e., the product of the parameter size and the distance from the set of initial parameters).)\\n'],\n",
       " 360: ['Decision\\n',\n",
       "  'To the best of my knowledge, this is the first work that proved the size-free generalization bound for multi-layer CNNs.\\n'],\n",
       " 361: ['However, I think the assumption on the hypothesis class is very restrictive and significantly eases the problem, as I discuss in detail later.\\n',\n",
       "  '0.93: (the assumption on the hypothesis class; significantly eases; the problem, I)\\n'],\n",
       " 362: ['Therefore, I judge the technical contribution of the paper is moderate and recommend to reject the paper weakly.\\n',\n",
       "  '0.92: (I; judge; the technical contribution of the paper is moderate and recommend to reject the paper weakly.)\\n'],\n",
       " 363: ['By the standard argument of the statistical learning theory (such as Theorem A.4), we can typically bound the generalization error by $O(B\\\\sqrt{D/N})$ where $B$ is the infimum of Lipschitz constant of hypotheses, $D$ is the intrinsic dimension of the hypothesis class, and $N$ is the sample size.\\n',\n",
       "  '0.78: (we $B$; is; the infimum of Lipschitz constant of hypotheses,)\\n'],\n",
       " 364: ['Therefore, we can derive the size-free generalization bound if $B$ does not depend on the input dimension.\\n',\n",
       "  '1.00: (we; can derive; the size-free generalization bound)\\n'],\n",
       " 365: ['Since the hypothesis class $F_\\\\beta$ is defined via the spectral norm of CNNs, it is not surprising that we can derive the size-freeness of $B$.\\n',\n",
       "  '1.00: (the hypothesis class; is defined; )\\n'],\n",
       " 366: ['The size-free generalization bound has been already proven by Du et al, (2017), although it was the two-layered case.\\n',\n",
       "  '1.00: (The size-free generalization; bound; )\\n'],\n",
       " 367: ['They imposed a restricted eigenvalue assumption.\\n',\n",
       "  '1.00: (They; imposed; a restricted eigenvalue assumption.)\\n'],\n",
       " 368: ['I think it implies that we need more sophisticated analysis if we do not assume the size-freeness of the hypothesis class.\\n',\n",
       "  '1.00: (we; do not assume; the size-freeness of the hypothesis class.)\\n'],\n",
       " 369: ['Comments\\n',\n",
       "  '- The authors claimed that Figure 3 is consistent with theorems because, according to the upper bound of theorems, the distance from the initialization point decreases when the generalization error is the same and the parameter size increases.\\n'],\n",
       " 370: ['However, I think it is too aggressive to conclude it from Figure 3 because the decreasing trend in the value of $\\\\|K-K_0\\\\|_\\\\sigma$ is found only around $2\\\\times 10^6\\\\leq W \\\\leq 3\\\\times 10^6$.\\n',\n",
       "  '0.66: (I; think; it is too aggressive to conclude it from Figure 3 because the decreasing trend in the value of $\\\\|K-K_0\\\\|_\\\\sigma$ is found only around $2\\\\times 10^6\\\\leq W \\\\leq 3\\\\times 10^6$.)\\n'],\n",
       " 371: ['Furthermore, the value of $\\\\|K-K_0\\\\|_\\\\sigma$ for $W\\\\approx 5\\\\times 10^5$ is approximately the same as the value for $W\\\\approx 3\\\\times 10^6$.\\n',\n",
       "  '0.67: (the value 10^5$; is; approximately the same as the value for $W\\\\approx 5\\\\times 3\\\\times 10^6$.)\\n'],\n",
       " 372: ['Suggestions\\n',\n",
       "  '- Please add the conclusion section which summarizes the paper and discusses the possible research directions.\\n'],\n",
       " 373: ['Minor Comments\\n', '- page 1, section 1, paragraph 1\\n'],\n",
       " 374: ['- ... with roots in (Bartett, 1998) , is that ...  Use \\\\citet\\n',\n",
       "  '0.06: (... with roots in (Bartett,; is; that ...  Use \\\\citet)\\n'],\n",
       " 375: ['- page 2, section 2.1, paragraph 2\\n',\n",
       "  '- Write the definition of \"expansive\" activations.\\n'],\n",
       " 376: ['- page 3, section 2., theorem 2.1\\n',\n",
       "  '1.00: (page 3, section 2.,; theorem; 2.1)\\n'],\n",
       " 377: ['- I think we should replace $\\\\log(\\\\lambda n)$ and $\\\\log(\\\\lambda)$ in equations with $\\\\log(\\\\beta \\\\lambda n)$ and $\\\\log(\\\\beta \\\\lambda)$, respectively.\\n',\n",
       "  '0.68: (I; think; we should replace $\\\\log(\\\\lambda n)$ and $\\\\log(\\\\lambda)$ in equations with $\\\\log(\\\\beta \\\\lambda n)$ and $\\\\log(\\\\beta \\\\lambda)$, respectively.)\\n'],\n",
       " 378: ['- page 3, section 2.2, definition 2.2\\n',\n",
       "  '0.99: (page 3, section 2.2,; definition; 2.2)\\n'],\n",
       " 379: ['- $N$  $\\\\mathbb{N}$\\n', '1.00: ($N$; ; $\\\\mathbb{N}$)\\n'],\n",
       " 380: ['In this paper, the authors study Neural Architecture Search, which aims to automate design of neural network models.\\n',\n",
       "  '1.00: (the authors; study; Neural Architecture Search, In this paper,)\\n'],\n",
       " 381: ['Their approach consists in using a two stage algorithm:\\n',\n",
       "  '1.00: (Their approach; consists; in using a two stage algorithm:)\\n'],\n",
       " 382: ['- A first Neural Network $f$ is trained for predicting the performances of sub-architectures.\\n',\n",
       "  '0.96: (A first Neural Network; is trained; for predicting the performances of sub-architectures.)\\n'],\n",
       " 383: ['Then binary sub-graphs coding the sub-architectures are uniformly sampled (Bernouilli(0.5)), and their performances y are evaluated thanks to the first Neural Network.\\n',\n",
       "  '1.00: (binary sub-graphs; coding; the sub-architectures)\\n'],\n",
       " 384: ['- The graph sampling matrix A, which is indexed by the m sampled architectures and the Fourier basis of size $O(n^d)$, is built.\\n',\n",
       "  '0.56: (The graph sampling matrix A,; is indexed; by the m sampled architectures and the Fourier basis of size)\\n'],\n",
       " 385: ['Then the optimization problem $x^*= \\\\arg\\\\min_x ||y  Ax||$ is solved using Lasso.\\n',\n",
       "  '0.92: (the optimization problem; is solved; Then using Lasso.)\\n'],\n",
       " 386: ['The largest Fourier coefficients are chosen to build an estimate g of f. Finally, computing minimum of g, the architecture is generated.\\n',\n",
       "  '1.00: (The largest Fourier coefficients; are chosen; to build an estimate g of f.)\\n'],\n",
       " 387: ['Since $m << n^d$, the optimization problem is ill-posed.\\n',\n",
       "  '0.99: (the optimization problem; is; ill-posed. Since $m << n^d$,)\\n'],\n",
       " 388: ['Theorem 3.2 shows that if A satisfies the restricted isometry of order s, then the sparse coefficients x can be recovered.\\n',\n",
       "  '0.99: (A; satisfies; the restricted isometry of order s,)\\n'],\n",
       " 389: ['The algorithm is evaluated and compared to the state-of-the-art on various image classification tasks and on RNN.\\n',\n",
       "  '1.00: (The algorithm; is evaluated; )\\n'],\n",
       " 390: ['Major concern:\\n',\n",
       "  '1/ I did not find the proof of Theorem 3.2 in the main paper and in the appendix, so I do not buy it.\\n'],\n",
       " 391: ['2/ The authors claim that their algorithm performs better than the state-of-the-art, but according to tables 1,2,3, I did not find significant differences of performances in term of test errors.\\n',\n",
       "  '1.00: (I; did not find; significant differences of performances in term of test errors.)\\n'],\n",
       " 392: ['3/ The key idea of the algorithm is not well explained.\\n',\n",
       "  '0.97: (3/ The key idea of the algorithm; is not well explained.; )\\n'],\n",
       " 393: ['A one-shot NAS f is pre-trained.\\n',\n",
       "  '1.00: (A one-shot NAS f; is; pre-trained.)\\n'],\n",
       " 394: ['f is assumed to be well-trained.\\n',\n",
       "  '0.93: (f is; assumed to be; well-trained.)\\n'],\n",
       " 395: ['Then it is approximated with a Fourier-sparse Boolean function.\\n',\n",
       "  '1.00: (it; is approximated; with a Fourier-sparse Boolean function. Then)\\n'],\n",
       " 396: ['Why using an approximation if f is perfect?\\n',\n",
       "  '0.92: (using an approximation f; is; perfect?)\\n'],\n",
       " 397: ['Do you expect to reduce the needed number of sampled architectures?\\n',\n",
       "  '0.92: (Do you expect; to reduce; the needed number of sampled architectures?)\\n'],\n",
       " 398: ['Minor concerns:\\n', 'Equation 3.1 is not clear.\\n'],\n",
       " 399: ['$X_S (\\\\alpha_l)$ does not depend on k. So all rows seem to be the same.\\n',\n",
       "  '0.77: (all rows; depend to be; on k. the same.)\\n'],\n",
       " 400: ['Contributions:\\n',\n",
       "  'This paper tackles the problem of One-shot Neural architecture search by proposing a new method.\\n'],\n",
       " 401: ['The method consists mainly of new search strategy of the optimal architecture that is inspired by the recovery of boolean functions from their sparse Fourier expansions.\\n',\n",
       "  '1.00: (The method; consists mainly; of new search strategy of the optimal architecture)\\n'],\n",
       " 402: ['As such, this work is an application of recent progress in the field of compressive sensing to One-shot neural architecture search.\\n',\n",
       "  '1.00: (this work; is; an application of recent progress in the field of compressive sensing to One-shot neural architecture search.)\\n'],\n",
       " 403: ['Given the problem formalism, the authors have also provides guarantee for the optimality of their method, i.e the method can recover the optimal sub-network of any given a sufficient number of performance measurements.\\n',\n",
       "  '0.95: (any; given; a sufficient number of performance measurements.)\\n'],\n",
       " 404: ['Clarity\\n',\n",
       "  'Overall, the paper is well motivated and the technical content is good.\\n'],\n",
       " 405: ['That said the structure could be enormously improved to ease the reading and the overall understanding.\\n',\n",
       "  '1.00: (the structure; to ease; the reading and the overall understanding.)\\n'],\n",
       " 406: ['For example: better caption for Figure 2 explaining what is shown; presenting the pseudo-code directly in the method overview and spending the rest of the section explaining the method; showing the related work before the experiments; etc.\\n',\n",
       "  '0.99: (better caption for Figure 2; explaining; what is shown;)\\n'],\n",
       " 407: ['Novelty\\n',\n",
       "  'The main novelty in my opinion is the application of compressive sensing methods to One-shot NAS.\\n'],\n",
       " 408: ['This approach is significantly different from other One-shot NAS method that I am aware of mainly regarding the search strategy employed to find the best architecture.\\n',\n",
       "  '1.00: (This approach; is; significantly different from other One-shot NAS method)\\n'],\n",
       " 409: ['However, this work seems like an incremental improvement over Hazan et al 2018) To this regard, the only novelty that was the framing of One-shot NAS as a recovery of boolean functions from their sparse Fourier expansions is not new either.\\n',\n",
       "  '0.92: (the only novelty; was; the framing of One-shot NAS as a recovery of boolean functions from their sparse Fourier expansions)\\n'],\n",
       " 410: ['That is said, I am open to be proven wrong on this point!\\n',\n",
       "  '0.87: (I; to be proven; wrong on this point!)\\n'],\n",
       " 411: ['Results\\n',\n",
       "  'The experiment section is not self-content, the readers is refered a couple of times to other papers to get details that are critical to reproducibility and understanding.\\n'],\n",
       " 412: ['Overall, the search strategy of CoNAS seems parameter efficient, fast and competitive.\\n',\n",
       "  '0.85: (the search strategy of CoNAS; seems; Overall, parameter efficient, fast and competitive.)\\n'],\n",
       " 413: ['Also, small ablation studies showing the effect of the different parameters of CoNAS were very informative and well-appreciated.\\n',\n",
       "  '1.00: (small ablation studies; showing; the effect of the different parameters of CoNAS)\\n'],\n",
       " 414: ['However, the search space is different between CoNAS and the others methods for some experiments, making it difficult to decide if the search strategy of CoNAS is definitely competitive compared to other methods or not.\\n',\n",
       "  '1.00: (the search space; is; different between CoNAS and the others methods for some experiments,)\\n'],\n",
       " 415: ['Points of improvement:\\n', '1 - Structure of the paper\\n'],\n",
       " 416: ['2 - Clarify novelty compared to HARMONICA ( not the application domain please)\\n',\n",
       "  '0.88: (2 - Clarify novelty; compared; to HARMONICA ( not the application domain please))\\n'],\n",
       " 417: ['3 - demonstrate that with the same search space your method is competitive.\\n',\n",
       "  '0.97: (3; demonstrate; that with the same search space your method is competitive.)\\n'],\n",
       " 418: ['4 - Does m=1000 in your experiments satisfies theorem 3.2?\\n',\n",
       "  '0.97: (4 m=1000 in your experiments; satisfies; theorem 3.2?)\\n'],\n",
       " 419: ['What is the value of d in your experiments?\\n',\n",
       "  '0.96: (What; is; the value of d in your experiments?)\\n'],\n",
       " 420: ['Can you provide supporting experiments that answer those questions?\\n',\n",
       "  '0.99: (supporting experiments; answer; those questions?)\\n'],\n",
       " 421: ['Preliminary decision:\\n', 'For now, I will say *weak reject*\\n'],\n",
       " 422: ['This paper proposes a new algorithm for one-shot neural architecture search (NAS) via compressive sensing.\\n',\n",
       "  '1.00: (This paper; proposes; a new algorithm for one-shot neural architecture search (NAS) via compressive sensing.)\\n'],\n",
       " 423: ['The authors propose a new search strategy, as well as a slightly different search space compared to DARTS [1], ProxylessNAS [2], etc.\\n',\n",
       "  '0.92: (The authors; propose; a new search strategy, as well as a slightly different search space)\\n'],\n",
       " 424: ['They use architecture samples from the one-shot model evaluated with the search parameters as a surrogate of the true objective in order to speed-up the search.\\n',\n",
       "  '1.00: (They; use; architecture samples from the one-shot model)\\n'],\n",
       " 425: ['Afterwards, these surrogate function evaluations are used to compute Fourier coefficients which are eventually used to optimize the vector of binary parameters encoding the architecture.\\n',\n",
       "  '1.00: (these surrogate function evaluations; are used; to compute Fourier coefficients Afterwards,)\\n'],\n",
       " 426: ['Overall, I think the proposed algorithm is interesting and of practical usefulness.\\n',\n",
       "  '1.00: (I; think; the proposed algorithm is interesting and of practical usefulness.)\\n'],\n",
       " 427: ['However, in terms of novelty, this work seems more to be an application of Harmonica [6] to the NAS problem (with small modifications in order to make it applicable).\\n',\n",
       "  '0.99: (this work; seems; more)\\n'],\n",
       " 428: ['In page 10 you state some of the differences of your method with Harmonica.\\n',\n",
       "  '1.00: (you; state; some of the differences of your method with Harmonica. In page 10)\\n'],\n",
       " 429: ['I agree that the number of function evaluations you use (coming from the one-shot model) is larger and computationally less expensive to obtain, however this does not guarantee that these are a good surrogate of the true objective that NAS aims to minimize, ie the validation/test accuracy of final (stand-alone) architectures .\\n',\n",
       "  '0.08: (use NAS; is aims to minimize,; larger and computationally less expensive obtain, ie the validation/test accuracy of final (stand-alone) architectures)\\n'],\n",
       " 430: ['The empirical evaluations of their algorithm seem to outperform/be competitive compared to other NAS methods on all benchmarks used in the paper, however only DARTS is evaluated on their search space and the other results are taken from the corresponding papers.\\n',\n",
       "  '0.45: (The empirical evaluations of their algorithm the other results; are taken; from the corresponding papers.)\\n'],\n",
       " 431: ['The paper is well-written and -structured with the caveat of being more than the recommended 8 pages.\\n',\n",
       "  '0.01: (The paper; is; well-written and -structured with the caveat of being more than the recommended 8 pages.)\\n'],\n",
       " 432: ['I will adjust my score depending on the authors responses concerning the following questions/issues:\\n',\n",
       "  '1.00: (I; will adjust; my score depending on the authors responses)\\n'],\n",
       " 433: ['1) The correlation between the architectures evaluated using the one-shot weights and retrained from scratch, seems to be of crucial importance in your method, since you directly use the one-shot weights to collect the measurements, similarly to Random Search with weight sharing [3], ENAS [4] or Bender et al [5].\\n',\n",
       "  '0.99: (The correlation between the architectures; evaluated; )\\n'],\n",
       " 434: ['What is the correlation of these measurements with the stand-alone architectures trained from scratch using the final evaluation settings?\\n',\n",
       "  '1.00: (the stand-alone architectures; trained; from scratch)\\n'],\n",
       " 435: ['How did you tune the p in the Bernoulli distribution during the one-shot weight updates.\\n',\n",
       "  '0.96: (you; tune; the p in the Bernoulli distribution during the one-shot weight updates.)\\n'],\n",
       " 436: ['According to Bender et al [5] the ScheduledDropPath probability is an important hyperparameter affecting the aforementioned correlation.\\n',\n",
       "  '1.00: (the ScheduledDropPath probability; is; an important hyperparameter affecting the aforementioned correlation.)\\n'],\n",
       " 437: ['2) What is the main motivation for using 5 operations in the operation set and not 8 as in DARTS [1] for example?\\n',\n",
       "  '0.67: (the main motivation for using 5 operations in the operation; set; not in)\\n'],\n",
       " 438: ['Does the main contribution in the competitive results come from the different search space or the search method?\\n',\n",
       "  '1.00: (the main contribution in the competitive results; come; from the different search space or the search method?)\\n'],\n",
       " 439: ['3) Is there any reference or proof for the correctness of Theorem 3.2?\\n',\n",
       "  '0.97: (3); Is; there any reference or proof for the correctness of Theorem 3.2?)\\n'],\n",
       " 440: ['4) I think there are some parts that can be moved in the Supplementary, such as the pseudocode for the proposed algorithm or Figure 3, and some other parts that can be compressed, such as the Related Work section.\\n',\n",
       "  '1.00: (some parts; can be moved; in the Supplementary,)\\n'],\n",
       " 441: ['References\\n', '[1] Hanxiao Liu, Karen Simonyan, and Yiming Yang.\\n'],\n",
       " 442: ['DARTS: Differentiable architecture search.\\n', 'In ICLR, 2019.\\n'],\n",
       " 443: ['[2] Han Cai, Ligeng Zhu, Song Han.\\n',\n",
       "  'ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware.\\n'],\n",
       " 444: ['[3] LIAM LI, AMEET TALWALKAR.\\n',\n",
       "  'Random Search and Reproducibility for Neural Architecture Search.\\n'],\n",
       " 445: ['[4] Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean.\\n',\n",
       "  '0.00: (Y. Zoph, Quoc V. Le,; is Dean. of; Jeff)\\n'],\n",
       " 446: ['Efficient Neural Architecture Search via Parameter Sharing.\\n',\n",
       "  'In ICML, 2018\\n'],\n",
       " 447: ['[5] Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, Quoc Le.\\n',\n",
       "  'Understanding and Simplifying One-Shot Architecture Search.\\n'],\n",
       " 448: ['[6] Elad Hazan, Adam Klivans, Yang Yuan.\\n',\n",
       "  'Hyperparameter Optimization: A Spectral Approach\\n'],\n",
       " 449: ['Overall, the paper is well-written and the proposed model is quite intuitive.\\n',\n",
       "  '1.00: (the proposed model; is; quite intuitive.)\\n'],\n",
       " 450: ['Specifically, the idea is to represent entailment as a product of continuous functions over possible worlds.\\n',\n",
       "  '1.00: (the idea; is; to represent entailment as a product of continuous functions over possible worlds.)\\n'],\n",
       " 451: ['Specifically, the idea is to generate possible worlds, and compute the functions that encode entailment in those worlds.\\n',\n",
       "  '1.00: (the idea; is; to generate possible worlds, and compute the functions)\\n'],\n",
       " 452: ['The functions themselves are designed as tree neural networks to take advantage of logical structure.\\n',\n",
       "  '0.99: (The functions; are designed; as tree neural networks to take advantage of logical structure.)\\n'],\n",
       " 453: ['Several different encoding benchmarks of the entailment task are designed to compare against the performance of the proposed model, using a newly created dataset.\\n',\n",
       "  '1.00: (Several different encoding benchmarks of the entailment task; are designed; to compare against the performance of the proposed model,)\\n'],\n",
       " 454: ['The results seem very impressive with > 99% accuracy on tests sets.\\n',\n",
       "  '0.92: (The results; seem; very impressive with > 99% accuracy on tests sets.)\\n'],\n",
       " 455: ['One weakness with the paper was that it was only tested on 1 dataset.\\n',\n",
       "  '1.00: (One weakness with the paper; was; that it was only tested on 1 dataset.)\\n'],\n",
       " 456: ['Also, should some form of cross-validation be applied to smooth out variance in the evaluation results.\\n',\n",
       "  '0.02: (some form of cross-validation; be applied smooth out; to variance in the evaluation results.)\\n'],\n",
       " 457: ['I am not sure if there are standard \"shared\" datasets for this task, which would make the results much stronger.\\n',\n",
       "  '1.00: (I; am not; sure if there are standard \"shared\" datasets for this task,)\\n'],\n",
       " 458: ['Also how about the tradeoff, i.e., does training time significantly increase when we \"imagine\" more worlds.\\n',\n",
       "  'Also, in general, a discussion on the efficiency of training the proposed model as compared to TreeNN would be helpful.\\n'],\n",
       " 459: ['The size of the world vectors, I would believe is quite important, so maybe a more detailed analysis on how this was chosen is important to replicate the results.\\n',\n",
       "  '1.00: (I; would believe; )\\n'],\n",
       " 460: ['This problem, I think, is quite related to model counting.\\n',\n",
       "  '1.00: (I; think,; is quite related to model counting.)\\n'],\n",
       " 461: ['There has been a lot of work on model counting.\\n',\n",
       "  '0.92: (a lot of work model; on; counting.)\\n'],\n",
       " 462: ['a discussion on how this relates to those lines of work would be interesting.\\n',\n",
       "  '1.00: (this; relates; to those lines of work)\\n'],\n",
       " 463: ['After revision\\n',\n",
       "  'I think the authors have improved the experiments substantially.\\n'],\n",
       " 464: ['SUMMARY\\n',\n",
       "  'The paper is fairly broad in what it is trying to achieve, but the approach is well thought out.\\n'],\n",
       " 465: ['The purpose of the paper is to investigate the effectiveness of prior machine learning methods with predicting logical entailment and then provide a new model designed for the task.\\n',\n",
       "  '1.00: (The purpose of the paper; is; to investigate the effectiveness of prior machine learning methods with predicting logical entailment and then provide a new model)\\n'],\n",
       " 466: ['Explicitly, the paper asks the following questions: \"Can neural networks understand logical formula well enough to detect entailment?\\n',\n",
       "  '0.98: (neural networks; to detect; entailment?)\\n'],\n",
       " 467: ['\", and \"Which architectures are best at inferring, encoding, and relating features in a purely structural sequence-based problem?\".\\n',\n",
       "  '0.98: (architectures; are; best at inferring, encoding, and relating features in a purely structural sequence-based problem?\".)\\n'],\n",
       " 468: ['The goals of the paper is to understand the learning bias of current architectures when they are tasked with learning logical entailment.\\n',\n",
       "  '0.70: (The goals of the paper; is; to understand the learning bias of current architectures with learning logical entailment.)\\n'],\n",
       " 469: ['The proposed network architecture, PossibleWorldNet, is then viewed as an improvement on an earlier architecture TreeNet.\\n',\n",
       "  '0.98: (The proposed network architecture,; is viewed; as an improvement on an earlier architecture TreeNet. then)\\n'],\n",
       " 470: ['POSITIVES\\n', 'The structure of this paper was very well done.\\n'],\n",
       " 471: ['The paper attempts to do a lot, and succeeds on most fronts.\\n',\n",
       "  '0.97: (The paper; succeeds; a lot, on most fronts.)\\n'],\n",
       " 472: ['The generated dataset used for testing logical entailment is given a constructive description which allows for future replication.\\n',\n",
       "  '1.00: (The generated dataset; used; for testing logical entailment)\\n'],\n",
       " 473: ['The baseline benchmark networks are covered in depth and the reader is provided with a deep understanding on the limitations of some networks with regard to exploiting structure in data.\\n',\n",
       "  '1.00: (The baseline benchmark networks; are covered; in depth)\\n'],\n",
       " 474: ['The PossibleWorldNets is also given good coverage, and the equations provided show the means by which it operates.\\n',\n",
       "  '1.00: (The PossibleWorldNets; is also given; good coverage,)\\n'],\n",
       " 475: [' A clear methodological approach to the research.\\n',\n",
       "  'The paper covers how they created a dataset which can be used for logical entailment learning, and then explains clearly all the previous network models which will be used in testing as well as their proposed model.\\n'],\n",
       " 476: [' The background information regarding each model was exceptionally thorough.\\n',\n",
       "  '0.82: (The background information regarding each model; was; exceptionally thorough.)\\n'],\n",
       " 477: ['The paper went into great depth describing the pros and cons of earlier network models and why they may struggle with recognizing logical entailment.\\n',\n",
       "  '1.00: (The paper; went; into great depth)\\n'],\n",
       " 478: [' The section describing the creation of a dataset captures the basis for the research, learning logical entailment.\\n',\n",
       "  '1.00: (The section; describing; the creation of a dataset)\\n'],\n",
       " 479: ['They describe the creation of the data, as well as the means by which they increase the difficulty for learning.\\n',\n",
       "  '0.87: (They; describe; the creation of the data, as well as the means)\\n'],\n",
       " 480: [' The paper provides an in depth description of their PossibleWorldNet model, and during experimentation we see clear evidence of the models capabilities.\\n',\n",
       "  '1.00: (The paper; provides; an in depth description of their PossibleWorldNet model,)\\n'],\n",
       " 481: ['NEGATIVES\\n',\n",
       "  'One issue I had with the paper is regarding the creation of the logical entailment dataset.\\n'],\n",
       " 482: ['Not so much for how they explained the process of creating the dataset, that was very thorough, but the fact that this dataset was the only means to test the previous network models and their new proposed network model.\\n',\n",
       "  '0.99: (they; explained; the process of creating the dataset,)\\n'],\n",
       " 483: ['I wonder if it would be better to find non-generated datasets which may contain data that have entailment relationships.\\n',\n",
       "  '0.84: (I; wonder; if it would be better to find non-generated datasets data entailment)\\n'],\n",
       " 484: ['It is questionable if their hand crafted network model is learned best on their hand crafted dataset.\\n',\n",
       "  '1.00: (It; is; questionable)\\n'],\n",
       " 485: ['The use of a singular dataset for learning logical entailment.\\n',\n",
       "  'The dataset was also created by the researchers for the express purpose of testing neural network capacity to learn logical entailment.\\n'],\n",
       " 486: ['I am hesitant to say their proposed network is an incredible achievement since PossibleWorldNet effectively beat out other methods on a dataset that they created expressly for it.\\n',\n",
       "  '0.85: (I; am; hesitant to say their proposed network is an incredible achievement since PossibleWorldNet effectively beat out other methods on a dataset)\\n'],\n",
       " 487: ['RELATED WORK\\n',\n",
       "  'The paper has an extensive section dedicated to covering related work.\\n'],\n",
       " 488: ['I would say the research involved was very thorough and the researchers understood how their method was different as well as how it was improving on earlier approaches.\\n',\n",
       "  '0.98: (the research; involved; )\\n'],\n",
       " 489: ['CONCLUSION\\n',\n",
       "  \"Given the thorough investigation into previous networks' capabilities in logical entailment learning, I would accept this paper as a valid scientific contribution.\\n\"],\n",
       " 490: ['The paper performs a thorough analysis on the limitations that previous networks face with regard to exploiting structure from data.\\n',\n",
       "  '1.00: (The paper; performs; a thorough analysis on the limitations)\\n'],\n",
       " 491: [\"The paper also covers results of the experiments by not only pointing out their proposed network's success, but by analyzing why certain earlier network models were able to achieve competitive learning results.\\n\",\n",
       "  '1.00: (The paper; covers; results of the experiments)\\n'],\n",
       " 492: ['The structure of the PossibleWorldNet was also explained well, and during ex- perimentation demonstrated its ability to learn structure from data.\\n',\n",
       "  '1.00: (The structure of the PossibleWorldNet; was explained well,; )\\n'],\n",
       " 493: ['The paper would have been improved through testing of multiple datasets, and not just on there self generated dataset, but the contribution of their research on their network and older networks is still justification enough for this paper.\\n',\n",
       "  '0.86: (The paper; would have been improved; through testing of multiple datasets, on)\\n'],\n",
       " 494: ['This is a wonderful and a self-contained paper.\\n',\n",
       "  '1.00: (This; is; a wonderful and a self-contained paper.)\\n'],\n",
       " 495: ['In fact, it introduces a very important problem and it solves it.\\n',\n",
       "  '1.00: (it; introduces; a very important problem)\\n'],\n",
       " 496: ['The major point of the paper is demonstrating that it is possible to model logical entailment in neural networks.\\n',\n",
       "  '1.00: (The major point of the paper; is demonstrating; that it is possible to model logical entailment in neural networks.)\\n'],\n",
       " 497: ['Hence, a corpus and a NN model are introduced.\\n',\n",
       "  '1.00: (a corpus and a NN model; are introduced.; )\\n'],\n",
       " 498: ['The corpus is used to demonstrate that the model, named PossibleWorld, is nearly perfect for the task.\\n',\n",
       "  '1.00: (The corpus; is used; to demonstrate that the model, named PossibleWorld, is nearly perfect for the task.)\\n'],\n",
       " 499: ['A comparative analysis is done with respect to state of the art recurrent NN.\\n',\n",
       "  '1.00: (A comparative analysis; is done; with respect to state of the art recurrent NN.)\\n'],\n",
       " 500: ['So far, so good.\\n', 'Yet, what is the take home message?\\n'],\n",
       " 501: ['In my opinion, the message is that generic NN should not be used for specific formal tasks whereas specific neural networks that model the task are desirable.\\n',\n",
       "  '0.81: (specific neural networks; model are; the task desirable.)\\n'],\n",
       " 502: ['This seems to be a trivial claim, but, since the PossibleWorld nearly completely solves the task, it is worth to be investigated.\\n',\n",
       "  '1.00: (This; seems; )\\n'],\n",
       " 503: ['The point that the paper leaves unexplained is: what is in the PossibleWorld Network that captures what we need?\\n',\n",
       "  '1.00: (the paper; leaves; unexplained)\\n'],\n",
       " 504: ['The description of the network is in fact very criptic.\\n',\n",
       "  '1.00: (The description of the network; is; very criptic.)\\n'],\n",
       " 505: ['No examples are given and a major effort is required to the reader.\\n',\n",
       "  '1.00: (No examples; are given; )\\n'],\n",
       " 506: ['Can you provide examples and insights on why this is THE needed model?\\n',\n",
       "  '0.96: (this; is; THE needed model?)\\n'],\n",
       " 507: ['Finally, the paper does not discuss a large body of research that has been done in the past by Plate.\\n',\n",
       "  '1.00: (the paper; does not discuss; a large body of research Finally,)\\n'],\n",
       " 508: ['Plate has investigated how symbolic predicates can be described in distributed representations.\\n',\n",
       "  '1.00: (Plate; has investigated; how symbolic predicates can be described in distributed representations.)\\n'],\n",
       " 509: ['This is strictly related to the problem this paper investigates.\\n',\n",
       "  '1.00: (This; is strictly related; to the problem)\\n'],\n",
       " 510: ['As discussed in \"Symbolic, Distributed and Distributional Representations for Natural Language Processing in the Era of Deep Learning: a Survey\", 2017, the link between symbolic and distributed representations has to be better investigated in order to propose innovative NN models.\\n',\n",
       "  '0.82: (2017, the link between symbolic and distributed representations; to be; better investigated in order)\\n'],\n",
       " 511: ['Your paper can be one of the first NN model that takes advantage of this strict link.\\n',\n",
       "  '1.00: (Your paper; can be; one of the first NN model)\\n'],\n",
       " 512: ['This paper provides a system to play CCP using some deep learning.\\n',\n",
       "  '1.00: (This paper; provides; a system to play CCP)\\n'],\n",
       " 513: ['The system consists of three modules - the bid module, which is rule based, and the policy and kicker networks, which are simple convolutional neural networks.\\n',\n",
       "  '0.55: (The system; consists; of three modules - bid module, which and the policy and kicker networks,)\\n'],\n",
       " 514: ['The authors use a dataset of 8 million game records consisting of 80 million state action pairs, and train the network in a supervised fashion.\\n',\n",
       "  '0.99: (8 million game records; consisting; of 80 million state action pairs,)\\n'],\n",
       " 515: ['The resulting model is able beat MicroWe, the current state of the art in playing CCP, and even are able to beat a few \"top amateur players\"\\n',\n",
       "  '0.98: (The resulting model; is; able beat MicroWe,)\\n'],\n",
       " 516: ['- Why is the bid module also not learned?\\n',\n",
       "  '0.96: (Why the bid module; also not learned?; is)\\n'],\n",
       " 517: ['It seems like the feature set for the bid module is fairly simple, and a linear or MLP can do fairly well compared to a rule based module.\\n',\n",
       "  '0.75: (the feature for the bid a linear or MLP; can do fairly well compared; to a rule based module.)\\n'],\n",
       " 518: [\"- It's not clear that separating the policy and kicker networks would be more advantageous than combining them.\\n\",\n",
       "  \"0.93: (It's; not; clear separating the policy and kicker networks)\\n\"],\n",
       " 519: ['Thousands of actions is not a too large number - language modeling work routinely deals with outputting many more classes than that.\\n',\n",
       "  '0.03: (Thousands of actions; is not; a too large number - language modeling work routinely deals with outputting many more classes than that.)\\n'],\n",
       " 520: ['- Were the convolutions chosen 1D, 2D, or 3D?\\n',\n",
       "  '0.98: (the convolutions; Were; chosen 1D, 2D, or 3D?)\\n'],\n",
       " 521: ['The figure seems to imply that the convolutions were over the XZ dimensions, with Y as the channel dimension.\\n',\n",
       "  '1.00: (The figure; seems; )\\n'],\n",
       " 522: ['If so, this doesn\\'t make too much sense to be, since the Z dimension is not uniform - the last index is all unseen cards, which is significantly more than the middle indices of \"what was played in this round\".\\n',\n",
       "  \"0.94: (this; doesn't make; too much sense to be,)\\n\"],\n",
       " 523: [\"There shouldn't be a lot of translational invariance in the Z dimension.\\n\",\n",
       "  \"0.95: (There; shouldn't be; a lot of translational invariance in the Z dimension.)\\n\"],\n",
       " 524: [\"I'm also not convinced that translational invariance is helpful in the X dimension.\\n\",\n",
       "  \"1.00: (I'm; also not; convinced that translational invariance is helpful in the X dimension.)\\n\"],\n",
       " 525: ['- There were no comparisons with baseline models or different model architectures.\\n',\n",
       "  '0.97: (comparisons; no; with baseline models or different model architectures.)\\n'],\n",
       " 526: ['I would like to see some results on the same structure, but with an Linear model, MLP or LSTM across the time dimension, or search through different types of convolutional networks.\\n',\n",
       "  '0.95: (I; would like; to see some results on the same structure, but with an Linear model, MLP or LSTM across the time dimension, or search through different types of convolutional networks.)\\n'],\n",
       " 527: ['- What hyperparameters were searched through in the learning process?\\n',\n",
       "  '0.92: (hyperparameters; were searched; through in the learning process?)\\n'],\n",
       " 528: ['- Missing citations for MicroWe being the best CCP AI, and citations for the accomplishments of the top amateur players.\\n',\n",
       "  '0.94: (Missing citations MicroWe; being; the best CCP AI,)\\n'],\n",
       " 529: ['- How far away are the top amateur players from professional players?\\n',\n",
       "  'Please provide some context on how far this system is from solving CCP.\\n'],\n",
       " 530: ['- Figure 3, 4 should just say #of games instead of \"iteration\"\\n',\n",
       "  '0.99: (Figure 3, 4; should just say; #of games instead of \"iteration\")\\n'],\n",
       " 531: ['This paper shows that one choice for a supervised learning system on a CCP game database can achieve amateur level human play.\\n',\n",
       "  '1.00: (This paper; shows; that one choice for a supervised learning system on a CCP game database can achieve amateur level human play.)\\n'],\n",
       " 532: ['It does not give insight to why the system was designed this way, why the model choices were made, and how good simpler baselines might be able to achieve.\\n',\n",
       "  '0.77: (It; does not give; insight to why the system was designed this way, why the model choices were made, and how good simpler baselines might be able to achieve.)\\n'],\n",
       " 533: ['The paper is not clearly written enough, and does not provide enough scientific value to be accepted to the conference.\\n',\n",
       "  '0.98: (The paper; is not clearly written; enough,)\\n'],\n",
       " 534: ['The authors propose a model that learns to play the China Competitive Poker game.\\n',\n",
       "  '1.00: (The authors; propose; a model that learns to play the China Competitive Poker game.)\\n'],\n",
       " 535: ['The model uses CNN to predict the actions, and is trained from actual human game records.\\n',\n",
       "  '0.93: (The model; is trained; from actual human game records.)\\n'],\n",
       " 536: ['The model is shown to beat the current best AI and human amateur players.\\n',\n",
       "  '1.00: (The model; is shown; )\\n'],\n",
       " 537: ['The performance is certainly strong (if it were true).\\n',\n",
       "  '0.95: (The performance; is certainly; strong (if it were true).)\\n'],\n",
       " 538: ['But given the double-blinded policy, there is literally no way to verify the correctness of the performance---in other words, the paper is currently not reproducible at all.\\n',\n",
       "  '0.81: (the paper; is not; currently reproducible at all.)\\n'],\n",
       " 539: ['So the following comments are based on the trust-worthiness of the paper.\\n',\n",
       "  '1.00: (the following comments; are based; on the trust-worthiness of the paper.)\\n'],\n",
       " 540: ['(1) immature writing: The writing lacks formality and looks like a final project report.\\n',\n",
       "  '1.00: (The writing; lacks; formality)\\n'],\n",
       " 541: ['For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway.\\n',\n",
       "  '0.66: (the super-short Section 2 related; anyway.; hard to believe that the works can be described within two paragraphs)\\n'],\n",
       " 542: ['Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3) There is a big room for improving the English writing.\\n',\n",
       "  '1.00: (someone; understands; the game of China Competitive Poker,)\\n'],\n",
       " 543: ['(2) ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices.\\n',\n",
       "  '0.98: (the model; should be; superior than other modeling choices.)\\n'],\n",
       " 544: ['For instance, what role does the neighboring connections of CNNs play?\\n',\n",
       "  '0.91: (what the neighboring connections of CNNs; does play?; role)\\n'],\n",
       " 545: ['What are the cons and pros of choosing CNNs?\\n',\n",
       "  '0.82: (the cons and; are of; pros choosing CNNs?)\\n'],\n",
       " 546: ['Are there strong motivations to design the model this way?\\n',\n",
       "  '0.94: (strong motivations; to design; there the model this way?)\\n'],\n",
       " 547: ['(3) many unanswered mysteries: why does the model trained with human records readily super-human?\\n',\n",
       "  '1.00: (the model; trained; with human records readily super-human?)\\n'],\n",
       " 548: ['Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance.\\n',\n",
       "  '0.90: (the typical performance; is bound; by the human-level performance. common imitation learning)\\n'],\n",
       " 549: ['Even though authors claimed in the response that there are \"many professional records\"---but how many is many?\\n',\n",
       "  '0.99: (how many; is; many?)\\n'],\n",
       " 550: ['Did the authors analyze the records and separate the professional versus amateur ones?\\n',\n",
       "  '0.98: (the authors; separate; the the professional versus amateur ones?)\\n'],\n",
       " 551: ['The authors introduce an algorithm in the subfield of conditional program generation that is able to create programs in a rich java like programming language.\\n',\n",
       "  '1.00: (The authors; introduce; an algorithm in the subfield of conditional program generation)\\n'],\n",
       " 552: ['In this setting, they propose an algorithm based on sketches- abstractions of programs that capture the structure but discard program specific information that is not generalizable such as variable names.\\n',\n",
       "  '0.96: (they; propose; an algorithm based on sketches- abstractions of programs that In this setting,)\\n'],\n",
       " 553: [\"Conditioned on information such as type specification or keywords of a method they generate the method's body from the trained sketches.\\n\",\n",
       "  \"1.00: (they; generate; the method's body from the trained sketches.)\\n\"],\n",
       " 554: ['Positives:\\n',\n",
       "  \" Novel algorithm and addition of rich java like language in subfield of 'conditional program generation' proposed\\n\"],\n",
       " 555: [' Very good abstract: It explains high level overview of topic and sets it into context plus gives a sketch of the algorithm and presents the positive results.\\n',\n",
       "  '0.99: (It; explains; high level overview of topic)\\n'],\n",
       " 556: [' Excellently structured and presented paper\\n',\n",
       "  ' Motivation given in form of relevant applications and mention that it is relatively unstudied\\n'],\n",
       " 557: [' The hypothesis/ the papers goal is clearly stated.\\n',\n",
       "  '0.93: (The hypothesis/ the papers goal; is clearly stated.; )\\n'],\n",
       " 558: [\"It is introduced with 'We ask' followed by two well formulated lines that make up the hypothesis.\\n\",\n",
       "  \"0.98: (It; is introduced; with 'We ask' followed by two well formulated lines)\\n\"],\n",
       " 559: ['It is repeated multiple times throughout the paper.\\n',\n",
       "  '1.00: (It; is repeated; multiple times throughout the paper.)\\n'],\n",
       " 560: ['Every mention introduces either a new argument on why this is necessary or sets it in contrast to other learners, clearly stating discrepancies.\\n',\n",
       "  '0.43: (Every mention; introduces; either a new argument on why this is necessary or sets it in contrast to)\\n'],\n",
       " 561: [' Explanations are exceptionally well done: terms that might not be familiar to the reader are explained.\\n',\n",
       "  '0.72: (Explanations; are exceptionally well done:; not be familiar to the reader)\\n'],\n",
       " 562: ['This is true for mathematical aspects as well as program generating specific terms.\\n',\n",
       "  '0.99: (This; is; true for mathematical aspects as well as program)\\n'],\n",
       " 563: ['Examples are given where appropriate in a clear and coherent manner\\n',\n",
       "  '1.00: (Examples; are given; where appropriate in a clear and coherent manner)\\n'],\n",
       " 564: [' Problem statement well defined mathematically and understandable for a broad audience\\n',\n",
       "  '0.96: (Problem statement; well defined mathematically understandable; for a broad audience)\\n'],\n",
       " 565: [' Mentioning of failures and limitations demonstrates a realistic view on the project\\n',\n",
       "  '1.00: (Mentioning of failures and limitations; demonstrates; a realistic view on the project)\\n'],\n",
       " 566: [' Complexity and time analysis provided\\n',\n",
       "  '1.00: (Complexity and time analysis; provided; )\\n'],\n",
       " 567: [\" Paper written so that it's easy for a reader to implement the methods\\n\",\n",
       "  \"0.94: (Paper; written; so that it's easy for a reader to implement the methods)\\n\"],\n",
       " 568: [' Detailed descriptions of all instantiations even parameters and comparison methods\\n',\n",
       "  ' System specified\\n'],\n",
       " 569: [' Validation method specified\\n',\n",
       "  '1.00: (Validation method; specified; )\\n'],\n",
       " 570: [' Data and repository, as well as cleaning process provided\\n',\n",
       "  '1.00: (Data and repository, as well as cleaning process; provided; )\\n'],\n",
       " 571: [' Every figure and plot is well explained and interpreted\\n',\n",
       "  '1.00: (Every figure and plot; is well explained; )\\n'],\n",
       " 572: [' Large successful evaluation section provided\\n',\n",
       "  '1.00: (Large successful evaluation section; provided; )\\n'],\n",
       " 573: [' Many different evaluation measures defined to measure different properties of the project\\n',\n",
       "  '1.00: (Many different evaluation measures; defined; to measure different properties of the project)\\n'],\n",
       " 574: [' Different observability modes\\n',\n",
       "  ' Evaluation against most compatible methods from other sources\\n'],\n",
       " 575: [' Results are in line with hypothesis\\n',\n",
       "  '1.00: (Results; are; in line with hypothesis)\\n'],\n",
       " 576: [' Thorough appendix clearing any open questions\\n',\n",
       "  '0.99: (Thorough; appendix; clearing any open questions)\\n'],\n",
       " 577: ['It would have been good to have a summary/conclusion/future work section\\n',\n",
       "  '0.96: (It; been; good to have a summary/conclusion/future work section)\\n'],\n",
       " 578: ['SUMMARY: ACCEPT.\\n',\n",
       "  'The authors present a very intriguing novel approach that in a clear and coherent way.\\n'],\n",
       " 579: ['The approach is thoroughly explained for a large audience.\\n',\n",
       "  '1.00: (The approach; is thoroughly explained; for a large audience.)\\n'],\n",
       " 580: ['The task itself is interesting and novel.\\n',\n",
       "  '1.00: (The task; is; interesting and novel.)\\n'],\n",
       " 581: ['The large evaluation section that discusses many different properties is a further indication that this approach is not only novel but also very promising.\\n',\n",
       "  '1.00: (The large evaluation section; discusses; many different properties)\\n'],\n",
       " 582: ['Even though no conclusive section is provided, the paper is not missing any information.\\n',\n",
       "  '1.00: (the paper; is not missing; any information.)\\n'],\n",
       " 583: ['This paper aims to synthesize programs in a Java-like language from a task description (X) that includes some names and types of the components that should be used in the program.\\n',\n",
       "  '0.99: (a task description; includes; some names and types of the components)\\n'],\n",
       " 584: ['The paper argues that it is too difficult to map directly from the description to a full program, so it instead formulates the synthesis in two parts.\\n',\n",
       "  '0.96: (it; instead formulates; the synthesis in two parts.)\\n'],\n",
       " 585: ['First, the description is mapped to a \"sketch\" (Y) containing high level program structure but no concrete details about, e.g., variable names.\\n',\n",
       "  '1.00: (the description; is mapped; First,)\\n'],\n",
       " 586: ['Afterwards, the sketch is converted into a full program (Prog) by stochastically filling in the abstract parts of the sketch with concrete instantiations.\\n',\n",
       "  '1.00: (the sketch; is converted; into a full program Afterwards,)\\n'],\n",
       " 587: ['The paper presents an abstraction method for converting a program into a sketch, a stochastic encoder-decoder model for converting descriptions to trees, and rejection sampling-like approach for converting sketches to programs.\\n',\n",
       "  '0.77: (The paper; presents; an abstraction method for converting a program into a sketch, a stochastic encoder-decoder model for converting descriptions to trees, and rejection sampling-like approach for converting sketches to programs.)\\n'],\n",
       " 588: ['Experimentally, it is shown that using sketches as an intermediate abstraction outperforms directly mapping to the program AST.\\n',\n",
       "  '0.87: (it using sketches as an intermediate abstraction; outperforms; directly mapping to the program AST.)\\n'],\n",
       " 589: ['The data is derived from an online repository of ~1500 Android apps, and from that were extracted ~150k methods, which makes the data very respectable in terms of realisticness and scale.\\n',\n",
       "  '0.97: (The data; is derived; from an online repository of ~1500 Android apps, and from)\\n'],\n",
       " 590: ['This is one of the strongest points of the paper.\\n',\n",
       "  '1.00: (This; is; one of the strongest points of the paper.)\\n'],\n",
       " 591: ['One point I found confusing is how exactly the Combinatorial Concretization step works.\\n',\n",
       "  '0.93: (One point I; found; confusing)\\n'],\n",
       " 592: ['Am I correct in understanding that this step depends only on Y, and that given Y, Prog is conditionally independent of X?\\n',\n",
       "  '0.72: (this step Prog; depends is; only on Y, given Y, conditionally independent of X?)\\n'],\n",
       " 593: ['If this is correct, how many Progs are consistent with a typical Y?\\n',\n",
       "  '1.00: (this; is; correct,)\\n'],\n",
       " 594: ['Some additional discussion of why no learning is required for the P(Prog | Y) step would be appreciated.\\n',\n",
       "  '1.00: (no learning; is required; for the P(Prog | Y) step)\\n'],\n",
       " 595: [\"I'm also curious whether using a stochastic latent variable (Z) is necessary.\\n\",\n",
       "  \"1.00: (I'm; also; curious whether using a stochastic latent variable (Z) is necessary.)\\n\"],\n",
       " 596: ['Would the approach work as well using a more standard encoder-decoder model with determinstic Z?\\n',\n",
       "  '0.91: (the approach; work as well using; a more standard encoder-decoder model with determinstic Z?)\\n'],\n",
       " 597: ['Some discussion of Grammar Variational Autoencoder (Kusner et al) would probably be appropriate.\\n',\n",
       "  '1.00: (Some discussion of Grammar Variational Autoencoder; would probably be; appropriate.)\\n'],\n",
       " 598: ['Overall, I really like the fact that this paper is aiming to do program synthesis on programs that are more like those found \"in the wild\".\\n',\n",
       "  '0.87: (I; is aiming; this paper to do program synthesis on programs)\\n'],\n",
       " 599: ['While the general pattern of mapping a specification to abstraction with a neural net and then mapping the abstraction to a full program with a combinatorial technique is not necessarily novel, I think this paper adds an interesting new take on the pattern (it has a very different abstraction than say, DeepCoder), and this paper is one of the more interesting recent papers on program synthesis using machine learning techniques, in my opinion.\\n',\n",
       "  '0.83: (the general pattern of mapping a specification to abstraction with a neural net and then mapping the abstraction to a full program with a combinatorial technique; is not necessarily; novel,)\\n'],\n",
       " 600: ['This is a very well-written and nicely structured paper that tackles the problem of generating/inferring code given an incomplete description (sketch) of the task to be achieved.\\n',\n",
       "  '0.73: (This; is; a very well-written and nicely structured paper that tackles the problem of generating/inferring code given an incomplete description (sketch) of the task)\\n'],\n",
       " 601: ['This is a novel contribution to existing machine learning approaches to automated programming that is achieved by training on a large corpus of Android apps.\\n',\n",
       "  '1.00: (This; is; a novel contribution to existing machine learning approaches to automated programming)\\n'],\n",
       " 602: ['The combination of the proposed technique and leveraging of real data are a substantial strength of the work compared to many approaches that have come previously.\\n',\n",
       "  '0.96: (The combination of the proposed technique and leveraging of real data; are; a substantial strength of the work to)\\n'],\n",
       " 603: ['This paper has many strengths:\\n',\n",
       "  '1.00: (This paper; has; many strengths:)\\n'],\n",
       " 604: ['1) The writing is clear, and the paper is well-motivated\\n',\n",
       "  '0.98: (1) The writing; is; clear,)\\n'],\n",
       " 605: ['2) The proposed algorithm is described in excellent detail, which is essential to reproducibility\\n',\n",
       "  '0.99: (The proposed algorithm; is described; in excellent detail,)\\n'],\n",
       " 606: ['3) As stated previously, the approach is validated with a large number of real Android projects\\n',\n",
       "  '1.00: (the approach; is validated; with a large number of real Android projects)\\n'],\n",
       " 607: ['4) The fact that the language generated is non-trivial (Java-like) is a substantial plus\\n',\n",
       "  '1.00: (the language; generated; )\\n'],\n",
       " 608: ['5) Good discussion of limitations\\n',\n",
       "  '0.90: (5) discussion of; Good; limitations)\\n'],\n",
       " 609: ['Overall, this paper is a valuable addition to the empirical software engineering community, and a nice break from more traditional approaches of learning abstract syntax trees.\\n',\n",
       "  '0.96: (Overall, this paper; is; a valuable addition to the empirical software engineering community,)\\n'],\n",
       " 610: [\"UPDATE: I have read the authors' rebuttal and also the other comments in this paper's thread.\\n\",\n",
       "  \"0.69: (I; have read; the authors' rebuttal and also the other comments in this paper's thread.)\\n\"],\n",
       " 611: ['My thoughts have not changed.\\n',\n",
       "  '1.00: (My thoughts; have not changed.; )\\n'],\n",
       " 612: ['The authors propose using a mixture prior rather than a uni-modal\\n',\n",
       "  '0.99: (The authors; propose; using a mixture prior rather than a uni-modal)\\n'],\n",
       " 613: ['prior for variational auto-encoders.\\n',\n",
       "  'They argue that the simple\\n'],\n",
       " 614: ['uni-modal prior \"hinders the overall expressivity of the learned model\\n',\n",
       "  'as it cannot possibly capture more complex aspects of the data\\n'],\n",
       " 615: ['distribution.\"\\n',\n",
       "  'I find the motivation of the paper suspicious because while the prior\\n'],\n",
       " 616: ['may be uni-modal, the posterior distribution is certainly not.\\n',\n",
       "  '1.00: (the posterior distribution; is certainly not.; )\\n'],\n",
       " 617: ['Furthermore, a uni-modal distribution on the latent variable space can\\n',\n",
       "  '0.97: (a uni-modal distribution on the latent variable space; is can; )\\n'],\n",
       " 618: ['certainly still lead to the capturing of complex, multi-modal data\\n',\n",
       "  '0.70: (certainly; lead; to the capturing of complex, multi-modal data still)\\n'],\n",
       " 619: ['distributions.\\n',\n",
       "  '(As the most trivial case, take the latent variable\\n'],\n",
       " 620: ['space to be a uniform distribution; take the likelihood to be a\\n',\n",
       "  '1.00: (space; to be; a uniform distribution;)\\n'],\n",
       " 621: [\"point mass given by applying the true data distribution's inverse CDF\\n\",\n",
       "  \"1.00: (point mass; given; by applying the true data distribution's inverse CDF)\\n\"],\n",
       " 622: ['to the uniform.\\n', 'Such a model can capture any distribution.)\\n'],\n",
       " 623: ['In addition, multi-modality is arguably an overfocused concept in the\\n',\n",
       "  '1.00: (multi-modality; is arguably; an overfocused concept in the)\\n'],\n",
       " 624: ['literature, where the (latent variable) space is hardly anymore worth\\n',\n",
       "  '0.98: (the (latent variable) space; is; hardly anymore worth literature,)\\n'],\n",
       " 625: ['capturing from a mixture of simple distributions when it is often a\\n',\n",
       "  '0.97: (it; is; often a)\\n'],\n",
       " 626: ['complex nonlinear space.\\n',\n",
       "  'It is unclear from the experiments how much\\n'],\n",
       " 627: [\"the influence of the prior's multimodality influences the posterior to\\n\",\n",
       "  \"1.00: (the influence of the prior's multimodality; influences; the posterior)\\n\"],\n",
       " 628: ['capture more complex phenomena, and whether this is any better than\\n',\n",
       "  '0.91: (this; is; any better than)\\n'],\n",
       " 629: ['considering a more complex (but still reparameterizable) distribution\\n',\n",
       "  'on the latent space.\\n'],\n",
       " 630: ['I recommend that this paper be rejected, and encourage the authors to\\n',\n",
       "  '0.97: (this paper; encourage; the authors to)\\n'],\n",
       " 631: ['more extensively study the effect of different priors.\\n',\n",
       "  '0.71: (more; extensively study; the effect of different priors.)\\n'],\n",
       " 632: [\"I'd also like to make two additional comments:\\n\",\n",
       "  \"0.99: (I'd; also like; to make two additional comments:)\\n\"],\n",
       " 633: ['While there is no length restriction at ICLR, the 14 page document can\\n',\n",
       "  '0.88: (the document; is can; 14 page)\\n'],\n",
       " 634: ['be significantly condensed without loss of describing their innovation\\n',\n",
       "  'or clarity.\\n'],\n",
       " 635: ['I recommend the authors do so.\\n',\n",
       "  '1.00: (I; recommend; the authors do so.)\\n'],\n",
       " 636: [\"Finally, I think it's important to note the controversy in this paper.\\n\",\n",
       "  \"1.00: (I; think; it's important to note the controversy in this paper. Finally,)\\n\"],\n",
       " 637: ['It was submitted with many significant incomplete details (e.g., no experiments,\\n',\n",
       "  '1.00: (It; was submitted; with many significant incomplete details)\\n'],\n",
       " 638: ['many missing citations, a figure placed inside that was pencilled in\\n',\n",
       "  '0.97: (a figure; placed; inside that was pencilled in)\\n'],\n",
       " 639: ['by hand, and several missing paragraphs).\\n',\n",
       "  '0.94: (by hand, several paragraphs).; missing; )\\n'],\n",
       " 640: ['These details were not\\n', '1.00: (These details; were not; )\\n'],\n",
       " 641: ['completed until roughly a week(?)\\n', 'later.\\n'],\n",
       " 642: ['I recommend the chairs discuss\\n',\n",
       "  '1.00: (I; recommend; the chairs discuss)\\n'],\n",
       " 643: ['this in light of what should be allowed next year.\\n',\n",
       "  '0.01: (this in light of what; should be allowed; next year.)\\n'],\n",
       " 644: ['The authors introduce some new prior and approximate posterior families for variational autoencoders, which are compatible with the reparameterization trick, as well as being capable of expressing multiple modes.\\n',\n",
       "  '1.00: (The authors; introduce; some new prior and approximate posterior families for variational autoencoders,)\\n'],\n",
       " 645: ['They also introduce a gating mechanism between prior and posterior.\\n',\n",
       "  '1.00: (They; introduce; a gating mechanism between prior and posterior.)\\n'],\n",
       " 646: ['They show improvements on bag of words document modeling, and dialogue response generation.\\n',\n",
       "  '1.00: (They; show; improvements on bag of words document modeling, and dialogue response generation.)\\n'],\n",
       " 647: ['The original abstract is overly strong in its assertion that a unimodal latent prior p(z) cannot fit a multimodal marginal int_z p(x|z)p(x)dz with a DNN response model p(x|z) (\"it cannot possibly capture more complex aspects of the data distribution\", \"critical restriction\", etc).\\n',\n",
       "  '0.70: (The original abstract; is; overly strong in its assertion that a unimodal latent prior p(z) cannot fit a multimodal marginal int_z p(x|z)p(x)dz DNN response model)\\n'],\n",
       " 648: ['While the assertion that a unimodal latent prior is necessary to model multimodal observations is false, there are sensible motivations for the piecewise constant prior and posterior.\\n',\n",
       "  '0.85: (the that a unimodal latent prior; is; necessary to model multimodal observations)\\n'],\n",
       " 649: ['For example, if we think of a VAE as a sort of regularized autoencoder where codes are constrained to \"fill up\" parts of the prior latent space, then there is a sphere-packing argument to be made that filling a Gaussian prior with Gaussian posteriors is a bad use of code space.\\n',\n",
       "  '1.00: (we; think; of a VAE as a sort of regularized autoencoder)\\n'],\n",
       " 650: [\"Although the authors don't explore this much, a hypercube-based tiling of latent code space is a sensible idea.\\n\",\n",
       "  \"1.00: (the authors; don't explore; this much,)\\n\"],\n",
       " 651: ['As stated, I found the message of the paper to be quite sloppy with respect to the concept of \"multi-modality.\"\\n',\n",
       "  '1.00: (I; found; the message of the paper to be quite sloppy with respect to the concept of \"multi-modality.\")\\n'],\n",
       " 652: ['There are 3 types of multimodality at play here: multimodality in the observed marginal distribution p(x), which can be captured by any deep latent Gaussian model, multimodality in the prior p(z), which makes sense in some situations (eg: a model of MNIST digits could have 10 prior modes corresponding to latent codes for each digit class), and multimodality in the posterior z for a given observation x_i, q(z_i|x_i).\\n',\n",
       "  '0.29: (10 prior modes; corresponding; to latent codes for each digit class),)\\n'],\n",
       " 653: ['The final type of multimodality is harder to argue for, except in so far as it allows the expression of flexibly shaped distributions without highly separated modes.\\n',\n",
       "  '1.00: (The final type of multimodality; is; harder to argue for,)\\n'],\n",
       " 654: [\"I believe flexible posterior approximations are important to enable fine-grained and efficient tiling of latent space, but I don't think these need to have multiple strong modes.\\n\",\n",
       "  '0.85: (flexible posterior approximations; to; are important enable fine-grained and efficient tiling of latent space,)\\n'],\n",
       " 655: ['I would be interested to see experiments demonstrating otherwise for real world data.\\n',\n",
       "  '0.94: (I; would be; interested to see experiments otherwise for real world data.)\\n'],\n",
       " 656: ['I think this paper should be more clear about the different types of multi-modality and which parts of their analysis demonstrate which ones.\\n',\n",
       "  '0.76: (I; think; this paper should be more clear about the different types of multi-modality and which parts of their analysis demonstrate which ones.)\\n'],\n",
       " 657: ['I also found it unsatisfactory that the piecewise variable analysis did not show different components of the multi-modal prior corresponding to different words, but rather just a separation between the Gaussian and the piecewise variables.\\n',\n",
       "  '0.97: (I; found; it unsatisfactory that the piecewise variable analysis did not show different components of the multi-modal prior)\\n'],\n",
       " 658: ['As I mention in my earlier questions, I found it surprising that the learned variance and mean for the Gaussian prior helps so dramatically with G-NVDM likelihood when the powerful networks transforming to and from latent space should make it scale-invariant.\\n',\n",
       "  '1.00: (I; mention; in my earlier questions,)\\n'],\n",
       " 659: ['Explicitly separating out the contributions of a reimplemented base model, prior-posterior interpolation and the learned prior parameters would strengthen these experiments.\\n',\n",
       "  '0.00: (Explicitly separating out the contributions of a reimplemented base model, prior-posterior interpolation and the learned prior parameters; would strengthen; these experiments.)\\n'],\n",
       " 660: ['Overall, the very strong improvements on the text modeling task over NVDM seem hard to understand, and I would like to see an ablation analysis of all the differences between that model and the proposed one.\\n',\n",
       "  '0.77: (the very strong improvements on the text modeling task over NVDM I; to would like; hard understand, to see an ablation analysis of all the differences between that model and the proposed one.)\\n'],\n",
       " 661: ['The fact that adding more constant components helps for document modeling is interesting, and it would be nice to see more qualitative analysis of what the prior modes represent.\\n',\n",
       "  '0.93: (adding; helps; more constant components for document modeling)\\n'],\n",
       " 662: ['I also would be surprised if posterior modes were highly separated, and if they were it would be interesting to explore if they corresponded to eg: ambiguous word-senses.\\n',\n",
       "  '1.00: (I; would be; surprised)\\n'],\n",
       " 663: ['The experiments on dialog modeling are mostly negative results, quantitatively.\\n',\n",
       "  '0.97: (The experiments on dialog modeling; are quantitatively.; mostly negative results,)\\n'],\n",
       " 664: ['The observation that the the piecewise constant variables encode time-related words and the Gaussian variables encode sentiment is interesting, especially since it occurs in both sets of experiments.\\n',\n",
       "  '0.96: (the the piecewise constant variables; encode; time-related words and the Gaussian variables encode sentiment)\\n'],\n",
       " 665: ['This is actually quite interesting, and I would be interested in seeing analysis of why this is the case.\\n',\n",
       "  '1.00: (This; is actually; quite interesting,)\\n'],\n",
       " 666: ['As above, I would like to see an analysis of the sorts of words that are encoded in the different prior modes and whether they correspond to eg: groups of similar holidays or days.\\n',\n",
       "  '0.77: (words; are encoded; in the different prior modes and whether they correspond to eg:)\\n'],\n",
       " 667: ['In conclusion, I think the piecewise constant variational family is a good idea, although it is not well-motivated by the paper.\\n',\n",
       "  '0.93: (it; is not; well-motivated by the paper.)\\n'],\n",
       " 668: ['The experimental results are very good for document modeling, but without ablation analysis against the baseline it is hard to see why they should be with such a small modification in G-NVDM.\\n',\n",
       "  '0.85: (The experimental results; are; very good for document modeling, but ablation analysis against the baseline)\\n'],\n",
       " 669: ['The fact that H-NVDM performs better is interesting, though.\\n',\n",
       "  '1.00: (H-NVDM; performs better; )\\n'],\n",
       " 670: ['This paper should better motivate the need for different types of multi-modality, and demonstrate that those sorts of things are actually being captured by the model.\\n',\n",
       "  '0.90: (This paper; should better; motivate the need for different types of multi-modality, and demonstrate)\\n'],\n",
       " 671: ['As it is, the paper introduces an interesting variational family and shows that it performs better for some tasks, but the motivation and analysis is not clearly focused.\\n',\n",
       "  '1.00: (it; is,; )\\n'],\n",
       " 672: ['To demonstrate that this is a broadly applicable family, it would also be good to do experiments on a more standard datasets like MNIST.\\n',\n",
       "  '0.95: (it; would also be; good to do experiments on a more standard datasets like MNIST.)\\n'],\n",
       " 673: ['Even without an absolute log-likelihood improvement, if the method yielded interpretable multiple modes this would be a valuable contribution.\\n',\n",
       "  '1.00: (the method; yielded; interpretable multiple modes)\\n'],\n",
       " 674: ['This paper proposes a piecewise constant parameterisation for neural variational models so that it could explore the multi-modality of the latent variables and develop more powerful neural models.\\n',\n",
       "  '0.97: (This paper; proposes; a piecewise constant parameterisation for neural variational models so that it could explore the multi-modality of the latent variables and develop more powerful neural models.)\\n'],\n",
       " 675: ['The experiments of neural variational document models and variational hierarchical recurrent encoder-decoder models show that the introduction of the piecewise constant distribution helps achieve better perplexity on modelling documents and seemly better performance on modelling dialogues.\\n',\n",
       "  '0.60: (The experiments of neural variational document models and variational hierarchical recurrent encoder-decoder models; show; that the introduction of the piecewise constant distribution helps achieve better perplexity on modelling documents and seemly better performance on modelling dialogues.)\\n'],\n",
       " 676: ['The idea of having a piecewise constant prior for latent variables is interesting, but the paper is not well-written (even 14 pages long) and the design of the experiments fails to demonstrate the most of the claims.\\n',\n",
       "  '1.00: (The idea of having a piecewise constant prior for latent variables; is; interesting,)\\n'],\n",
       " 677: ['The detailed comments are as follows:\\n',\n",
       "  '1.00: (The detailed comments; are; as follows:)\\n'],\n",
       " 678: ['--The author explains the limitations of the VAEs with standard Gaussian prior in the last paragraph of 3.1 and the last paragraph of 5.1) Hence, a multimodal prior would help the VAEs overcome the issues of optimisation.\\n',\n",
       "  '0.96: (author; explains; the limitations of the VAEs with standard Gaussian prior)\\n'],\n",
       " 679: ['However, there is a lack of evidence showing the multimodality of the prior helps break the bottleneck.\\n',\n",
       "  '1.00: (evidence; showing; the multimodality of the prior)\\n'],\n",
       " 680: ['--In the last paragraph of 6.1, the author claimed the decoder parameter matrix is directly affected by the latent variables.\\n',\n",
       "  '1.00: (the author; claimed; the decoder parameter matrix is directly affected by the latent variables. the last paragraph of 6.1,)\\n'],\n",
       " 681: ['But what the connects the decoder is a combination of a piecewise constant and Gaussian latent variables.\\n',\n",
       "  '0.96: (what the connects the decoder; is; a combination of a piecewise constant and Gaussian latent variables.)\\n'],\n",
       " 682: ['No matter what is discovered in the experiments, it only shows z=<z_gaussian, z_piecewise> is multimodal.\\n',\n",
       "  '0.91: (it; only shows; what is discovered in the experiments, z=<z_gaussian, z_piecewise> is multimodal.)\\n'],\n",
       " 683: ['However, z=<z_gaussian1, z_gaussian2> can be multimodal as well.\\n',\n",
       "  '0.91: (z=<z_gaussian1, z_gaussian2>; can be as; multimodal well.)\\n'],\n",
       " 684: ['None of the claims in this paragraph stands.\\n',\n",
       "  '1.00: (None of the claims in this paragraph; stands.; )\\n'],\n",
       " 685: ['--In the quantitative evaluation of NVDM, there is an incremental model from z=z_gaussian to z=<z_gaussian, z_piecewise>.\\n',\n",
       "  'As the prior is learned together with the variational posterior, a more flexible prior would alleviate the regularisation imposed by the KL term.\\n'],\n",
       " 686: ['Certainly, more parameters are applied as well, so a fair comparison would at least be z=<z_gaussian, z_piecewise> and z=<z_gaussian1, z_gaussian2> which equals to a double sized z_gaussian.\\n',\n",
       "  '0.86: (more parameters; are applied as well,; least z=<z_gaussian,)\\n'],\n",
       " 687: ['--The results shown in Table 3 are implausible.\\n',\n",
       "  '1.00: (results; shown; in Table 3)\\n'],\n",
       " 688: ['I cannot believe the author used gradients to evaluate the model.\\n',\n",
       "  '1.00: (I; cannot believe; the author used gradients to evaluate the model.)\\n'],\n",
       " 689: ['--Equation 5 is confusing, adding a multiplication sign might help.\\n',\n",
       "  '0.95: (5; is; confusing, adding a multiplication sign)\\n'],\n",
       " 690: ['--3.1 can be deleted because people attending ICLR are familiar with VAEs.\\n',\n",
       "  '1.00: (people; attending; ICLR)\\n'],\n",
       " 691: ['Typos:\\n',\n",
       "  'as well as the well as the generated prior-> as well as the generated prior\\n'],\n",
       " 692: ['This paper proposes a novel approach with the hypothesis that the reliable features can guide the less reliable ones.\\n',\n",
       "  '0.85: (This paper; proposes; a novel approach with the hypothesis that the reliable features can guide the less reliable ones.)\\n'],\n",
       " 693: ['This approach is applied to the object detection task and show consistent performance improvements.\\n',\n",
       "  '1.00: (This approach; is applied; to the object detection task)\\n'],\n",
       " 694: ['pros)\\n', '(+) This paper is well-written and easy to follow.\\n'],\n",
       " 695: ['(+) The base idea that divides the learned features into two sets; the reliable feature set and the less reliable one is very interesting and looks novel.\\n',\n",
       "  '0.93: (the reliable feature set and the less reliable one; is; very interesting novel.)\\n'],\n",
       " 696: ['Plus, the hypothesis, which is that reliable features can guide the features in the less reliable set is also interesting.\\n',\n",
       "  '0.81: (the hypothesis, can guide; is; that reliable features the features in the less reliable set)\\n'],\n",
       " 697: ['(+) The performance improvements are quite large.\\n',\n",
       "  '1.00: (The performance improvements; are; quite large.)\\n'],\n",
       " 698: ['(+) Extensive ablative studies are provided to support the proposed method well.\\n',\n",
       "  '1.00: (Extensive ablative studies; are provided; to support the proposed method well.)\\n'],\n",
       " 699: ['cons)\\n',\n",
       "  '(-) The method of obtaining the representative in buffer B is not clearly presented.\\n'],\n",
       " 700: ['(-) The overall training and inference procedure are not clearly presented.\\n',\n",
       "  '1.00: (The overall training and inference procedure; are not clearly presented.; )\\n'],\n",
       " 701: ['(-) Some notations and descriptions are vague and confusing.\\n',\n",
       "  '1.00: (Some notations and descriptions; are; vague and confusing.)\\n'],\n",
       " 702: ['(-) More than two datasets are necessary to show the effectiveness of the methods\\n',\n",
       "  '0.97: (More than two datasets; to show; the effectiveness of the methods)\\n'],\n",
       " 703: ['comments)\\n', '- What is the higher level feature map P_m?\\n'],\n",
       " 704: ['and How did you choose the higher level feature map at the m-th level in option (b) and (c) in Section 3.3.\\n',\n",
       "  '0.88: (you; choose; the higher level feature map at the m-th level in option)\\n'],\n",
       " 705: ['- What is the meaning of the \"past\" features in Section 3.2?\\n',\n",
       "  '0.97: (What; is; the meaning of the \"past\" features in Section 3.2?)\\n'],\n",
       " 706: ['- It is better to show the exact architecture of the make-up module and the critic module.\\n',\n",
       "  '0.94: (It; is better; to show the exact architecture of the make-up module and the critic module.)\\n'],\n",
       " 707: ['- Can this method apply to the other backbones such as VGG or ResNets without FPN?\\n',\n",
       "  '1.00: (this method; apply; to the other backbones such as VGG or ResNets without FPN?)\\n'],\n",
       " 708: ['- The sentences at the bottom of p.4 starting with \"Note that only~\" looks ambiguous.\\n',\n",
       "  '0.99: (The sentences at the bottom of p.4; starting; with \"Note that only~\" looks ambiguous.)\\n'],\n",
       " 709: ['- f_critic^j may be the j-th element of F_critic, please denote what f_critic^j stands for.\\n',\n",
       "  '0.81: (f_critic^j element F_critic,; be denote; the j-th of what f_critic^j stands for.)\\n'],\n",
       " 710: ['Even if the paper needs to be revised for better readability, I think this paper is above the standard of ICLR because the idea is interesting and novel.\\n',\n",
       "  '0.97: (the paper; to be revised; for better readability,)\\n'],\n",
       " 711: ['Furthermore, the experimental studies are properly designed and well support the main idea.\\n',\n",
       "  '1.00: (the experimental studies; are properly designed; )\\n'],\n",
       " 712: [\"I am leaning toward acceptance, but I would like to see the other reviewers' comments.\\n\",\n",
       "  '1.00: (I; am leaning; toward acceptance,)\\n'],\n",
       " 713: ['This paper aims to facilitate feature learning in NN models by exploiting more from reliable examples.\\n',\n",
       "  '1.00: (This paper; aims; to facilitate feature learning in NN models by exploiting more from reliable examples.)\\n'],\n",
       " 714: ['This is very similar to self-paced learning where the model learns from the easier samples at first and proceeds to learn from difficult and challenging samples.\\n',\n",
       "  '1.00: (This; is; very similar to self-paced learning)\\n'],\n",
       " 715: ['The authors should discuss their difference with self-paced learning.\\n',\n",
       "  '1.00: (The authors; should discuss; their difference with self-paced learning.)\\n'],\n",
       " 716: ['The method is positioned as a general one for feature learning.\\n',\n",
       "  '1.00: (The method; is positioned; as a general one for feature learning.)\\n'],\n",
       " 717: ['I do not know the reason why the authors only apply for object detection on a very specific dataset.\\n',\n",
       "  '1.00: (I; do not know; the reason why the authors only apply for object detection on a very specific dataset.)\\n'],\n",
       " 718: ['It is expected to see whether the proposed method is also effective for image classification.\\n',\n",
       "  '1.00: (It; is expected; )\\n'],\n",
       " 719: ['More datasets for evaluation are needed, even only for the object detection application.\\n',\n",
       "  '1.00: (More datasets for evaluation; are needed,; )\\n'],\n",
       " 720: ['OVERVIEW:\\n',\n",
       "  'The authors tackle the problem of detecting small/low resolution objects in an image.\\n'],\n",
       " 721: ['Their key idea is that detecting bigger objects is an easier task and can be used to guide the detection of smaller objects.\\n',\n",
       "  '0.90: (Their key idea; is; that detecting bigger objects is an easier task and can be used to guide the detection of smaller objects.)\\n'],\n",
       " 722: ['This is done using the \"Feature Intertwiner\" which consists of two branches, one for the larger objects (more reliable set that is also easier to detect) and one for the smaller objects (less reliable set).\\n',\n",
       "  '1.00: (This; is done; )\\n'],\n",
       " 723: ['The second branch contains a make-up layer learned during training (which acts as the guidance from the more reliable set) that helps compensate details needed for detection.\\n',\n",
       "  '1.00: (The second branch; contains; a make-up layer learned during training (which acts as the guidance from the more reliable set))\\n'],\n",
       " 724: ['The authors define a class buffer that contains representative elements of object features from the reliable set for every category & scale and an intertwiner loss that computes the L2 loss between the features from the less reliable set & the class buffer.\\n',\n",
       "  '1.00: (The authors; define; a class buffer that contains representative elements of object features from the reliable set for every category & scale and an intertwiner loss)\\n'],\n",
       " 725: ['They also use an Optimal Transport procedure with a Sinkhorn divergence loss between object features from both sets.\\n',\n",
       "  '0.98: (They; also use; an Optimal Transport procedure with a Sinkhorn divergence loss between object features from both sets.)\\n'],\n",
       " 726: ['The overall loss of the system is now a sum of the detection loss, the intertwiner loss and the optimal transport loss.\\n',\n",
       "  '1.00: (The overall loss of the system; is; now a sum of the detection loss, the intertwiner loss and the optimal transport loss.)\\n'],\n",
       " 727: ['They evaluate their model on the COCO Object detection challenge showing state-of-the-art performance.\\n',\n",
       "  '0.97: (They; evaluate; their model on the COCO Object detection challenge)\\n'],\n",
       " 728: ['They also provide thorough ablation analysis of various design choices.\\n',\n",
       "  '1.00: (They; provide; thorough ablation analysis of various design choices.)\\n'],\n",
       " 729: ['The qualitative result in Fig.1 showing well clustered features for both high & low resolution objects via t-SNE is a nice touch.\\n',\n",
       "  '0.91: (The qualitative result in Fig.1; showing; well clustered features for both high & low resolution objects via t-SNE)\\n'],\n",
       " 730: ['COMMENTS:\\n',\n",
       "  'Clarity - The paper is well written and easy to follow.\\n'],\n",
       " 731: ['Originality & Significance - The paper tackles an important problem and provides a novel solution.\\n',\n",
       "  '1.00: (The paper; tackles; an important problem)\\n'],\n",
       " 732: ['Quality - The paper is complete in that it tackles an important problem, provides a novel solution and demonstrates via thorough experiments the improvement achieved using their approach.\\n',\n",
       "  '0.98: (Quality The paper; is; complete in)\\n'],\n",
       " 733: ['QUESTIONS:\\n',\n",
       "  '1) The Class Buffer seems very restricted in having a single element per object category per scale to represent all features.\\n'],\n",
       " 734: ['The advantage of forcing such a representation is tight clustering in the feature space.\\n',\n",
       "  '0.98: (The advantage of forcing such a representation; is; tight clustering in the feature space.)\\n'],\n",
       " 735: [\"But, wouldn't a dictionary approach with multiple elements give more flexibility to the model and learn a richer feature representation at the cost of not-so-good clustering ?\\n\",\n",
       "  '0.76: (a dictionary approach with multiple elements; learn; a richer feature representation at the cost of not-so-good clustering)\\n'],\n",
       " 736: ['2) Any comment on why you drop performance for couch ?\\n',\n",
       "  '1.00: (you; drop; performance for couch)\\n'],\n",
       " 737: ['(and baseball bat + bedroll)\\n',\n",
       "  '3) In Table 4 of Appendix where you compare with more object detection results, I find it interesting that Mask RCNN, updated results has a might higher AP_S (43.5) compared to you (27.2) and everyone else.\\n'],\n",
       " 738: ['I was expecting you to be the best under that metric due to the explicit design for small objects.\\n',\n",
       "  '1.00: (I; was expecting; you to be the best under that metric due to the explicit design for small objects.)\\n'],\n",
       " 739: ['They (MaskRCNN, updated results) are also significantly better than the rest under AP_M but worse under AP_L.\\n',\n",
       "  '0.02: (They (MaskRCNN, updated results); are also worse; significantly better than the rest under AP_M but under AP_L.)\\n'],\n",
       " 740: ['Can you explain this behavior ?\\n',\n",
       "  '1.00: (you; explain; this behavior)\\n'],\n",
       " 741: ['Is the ResNeXt backbone that much better for small objects ?\\n',\n",
       "  '0.96: (the ResNeXt; Is; backbone that much better for small objects)\\n'],\n",
       " 742: ['This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) current SOTA models.\\n',\n",
       "  '0.93: (This paper; proposes; a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) current SOTA models.)\\n'],\n",
       " 743: ['The idea is based on using a large mixture of experts (MoE) (ie small networks), where only a few of them are adaptively activated via a gating network.\\n',\n",
       "  '0.94: (The idea; is based; on using a large mixture of experts (MoE) (ie small networks),)\\n'],\n",
       " 744: ['While the idea seems intuitive, the main novelty in the paper is in designing the gating network which is encouraged to achieve two objectives: utilizing all available experts (aka importance), and distributing computation fairly across them (aka load).\\n',\n",
       "  '0.99: (the idea; seems; intuitive,)\\n'],\n",
       " 745: ['Additionally, the paper introduces two techniques for increasing the batch-size passed to each expert, and hence maximizing parallelization in GPUs.\\n',\n",
       "  '0.82: (the paper; introduces; two techniques for increasing the batch-size passed to each and hence maximizing parallelization in GPUs.)\\n'],\n",
       " 746: ['Experiments applying the proposed approach on RNNs in language modelling task show that it can beat SOTA results with significantly less computation, which is a result of selectively using much more parameters.\\n',\n",
       "  '0.99: (significantly less computation,; is; a result of selectively using much more parameters.)\\n'],\n",
       " 747: ['Results on machine translation show that a model with more than 30x number of parameters can beat SOTA while incurring half of the effective computation.\\n',\n",
       "  '0.68: (Results on machine translation; show; that a model with more than 30x number of parameters can beat SOTA while incurring half of the effective computation.)\\n'],\n",
       " 748: ['I have the several comments on the paper:\\n',\n",
       "  '1.00: (I; have; the several comments on the paper:)\\n'],\n",
       " 749: ['- I believe that the authors can do a better job in their presentation.\\n',\n",
       "  '1.00: (I; believe; that the authors can do a better job in their presentation.)\\n'],\n",
       " 750: ['The paper currently is at 11 pages (which is too long in my opinion), but I find that Section 3.2 (the crux of the paper) needs better motivation and intuitive explanation.\\n',\n",
       "  '0.84: (The paper; is; at 11 pages is too long in my opinion), currently)\\n'],\n",
       " 751: ['For example, equation 8 deserves more description than currently devoted to it.\\n',\n",
       "  '1.00: (equation 8; deserves; more description than currently devoted to it.)\\n'],\n",
       " 752: ['Additional space can be easily regained by moving details in the experiments section (eg: architecture and training details) to the appendix for the curious readers.\\n',\n",
       "  '1.00: (Additional space; can be easily regained; )\\n'],\n",
       " 753: ['Experiment section can be better organized by finishing on experiment completely before moving to the other one.\\n',\n",
       "  '0.88: (Experiment section; can be better; organized by finishing on experiment completely before moving to the other one.)\\n'],\n",
       " 754: ['There are also some glitches in the writing, eg: the end of Section 3.1)\\n',\n",
       "  '1.00: (some glitches in the writing,; eg:; )\\n'],\n",
       " 755: ['- The paper is missing some important references in conditional computation (eg: https://arxiv.org/pdf/1308.3432.pdf) which deal with very similar issues in deep learning.\\n',\n",
       "  '0.95: (The paper; is missing; some important references in conditional computation (eg: https://arxiv.org/pdf/1308.3432.pdf))\\n'],\n",
       " 756: ['- One very important lesson from the conditional computation literature is that while we can in theory incur much less computation, in practice (especially with the current GPU architectures) the actual time does not match the theory.\\n',\n",
       "  '0.64: (One very important lesson from the conditional computation literature; is; that while we can in theory incur much less computation, in practice (especially with the current GPU architectures) the actual time does not match the theory.)\\n'],\n",
       " 757: ['This can be due to inefficient branching in GPUs.\\n',\n",
       "  '1.00: (This; can be; due to inefficient branching in GPUs.)\\n'],\n",
       " 758: ['It would be nice if the paper includes a discussion of how their model (and perhaps implementation) deal with this problem, and why it scales well in practice.\\n',\n",
       "  '1.00: (It; would be; nice)\\n'],\n",
       " 759: ['- Table 1 and Table 3 contain repetitive information, and I think they should be combined in one (maybe moving Table 3 to appendix).\\n',\n",
       "  '1.00: (Table 1 and Table 3; contain; repetitive information,)\\n'],\n",
       " 760: ['One thing I do not understand is how does the number of ops/timestep relate to the training time.\\n',\n",
       "  '0.98: (One thing; do not understand; I)\\n'],\n",
       " 761: ['This also related to the pervious comment.\\n',\n",
       "  '0.98: (This; also related; to the pervious comment.)\\n'],\n",
       " 762: ['Paper Strengths:\\n',\n",
       "  '-- Elegant use of MoE for expanding model capacity and enabling training large models necessary for exploiting very large datasets in a computationally feasible manner\\n'],\n",
       " 763: ['-- The effective batch size for training the MoE drastically increased also\\n',\n",
       "  '0.98: (The effective batch size for training the MoE; drastically increased also; )\\n'],\n",
       " 764: ['-- Interesting experimental results on the effects of increasing the number of MoEs, which is expected.\\n',\n",
       "  '0.83: (the of MoEs,; is expected.; number)\\n'],\n",
       " 765: ['Paper Weaknesses:\\n',\n",
       "  '--- there are many different ways of increasing model capacity to enable the exploitation of very large datasets; it would be very nice to discuss the use of MoE and other alternatives in terms of computational efficiency and other factors.\\n'],\n",
       " 766: ['This paper describes a method for greatly expanding network model size (in terms of number of stored parameters) in the context of a recurrent net, by applying a Mixture of Experts between recurrent net layers that is shared between all time steps.\\n',\n",
       "  '0.74: (This paper; describes; a method for greatly expanding network model size (in terms of number of stored parameters) in the context of a recurrent net, by applying a Mixture of Experts between recurrent net layers)\\n'],\n",
       " 767: ['By process features from all timesteps at the same time, the effective batch size to the MoE is increased by a factor of the number of steps in the model; thus even for sparsely assigned experts, each expert can be used on a large enough sub-batch of inputs to remain computationally efficient.\\n',\n",
       "  '0.30: (each expert; can be used to remain; on a large enough sub-batch of inputs computationally efficient.)\\n'],\n",
       " 768: ['Another second technique that redistributes elements within a distributed model is also described, further increasing per-expert batch sizes.\\n',\n",
       "  '1.00: (Another second technique; redistributes; elements within a distributed model)\\n'],\n",
       " 769: ['Experiments are performed on language modeling and machine translation tasks, showing significant gains by increasing the number of experts, compared to both SoA as well as explicitly computationally-matched baseline systems.\\n',\n",
       "  '0.99: (Experiments; are performed; on language modeling and machine translation tasks,)\\n'],\n",
       " 770: ['An area that falls a bit short is in presenting plots or statistics on the real computational load and system behavior.\\n',\n",
       "  '1.00: (An area; falls; a bit short)\\n'],\n",
       " 771: ['While two loss terms were employed to balance the use of experts, these are not explored in the experiments section.\\n',\n",
       "  '0.99: (two loss terms; were employed; to balance the use of experts,)\\n'],\n",
       " 772: ['It would have been nice to see the effects of these more, along with the effects of increasing effective batch sizes, eg: measurements of the losses over the course of training, compared to the counts/histogram distributions of per-expert batch sizes.\\n',\n",
       "  '0.90: (It; to see; the effects of these more, along with the effects of increasing effective batch sizes,)\\n'],\n",
       " 773: ['Overall I think this is a well-described system that achieves good results, using a nifty placement for the MoE that can overcome what otherwise might be a disadvantage for sparse computation.\\n',\n",
       "  '0.99: (a well-described system; achieves; good results,)\\n'],\n",
       " 774: ['Small comment:\\n',\n",
       "  \"I like Figure 3, but it's not entirely clear whether datapoints coincide between left and right plots.\\n\"],\n",
       " 775: ['The H-H line has 3 points on left but 5 on the right?\\n',\n",
       "  '0.99: (The H-H line; has; 3 points on left but 5 on the right?)\\n'],\n",
       " 776: ['Also would be nice if the colors matched between corresponding lines.\\n',\n",
       "  '1.00: (the colors; matched; between corresponding lines.)\\n'],\n",
       " 777: ['This paper proposes learning on the fly to represent a dialog as a graph (which acts as the memory), and is first demonstrated on the bAbI tasks.\\n',\n",
       "  '0.85: (a graph; acts; dialog as the memory),)\\n'],\n",
       " 778: ['Graph learning is part of the inference process, though there is long term representation learning to learn graph transformation parameters and the encoding of sentences as input to the graph.\\n',\n",
       "  '1.00: (Graph learning; is; part of the inference process,)\\n'],\n",
       " 779: ['This seems to be the first implementation of a differentiable memory as graph: it is much more complex than previous approaches like memory networks without significant gain in performance in bAbI tasks, but it is still very preliminary work, and the representation of memory as a graph seems much more powerful than a stack.\\n',\n",
       "  '0.92: (This; to be; the first implementation of a differentiable memory as graph:)\\n'],\n",
       " 780: ['Clarity is a major issue, but from an initial version that was constructive and better read by a computer than a human, the author proposed a hugely improved later version.\\n',\n",
       "  '1.00: (Clarity; is; a major issue,)\\n'],\n",
       " 781: ['This original, technically accurate (within what I understood) and thought provoking paper is worth publishing.\\n',\n",
       "  '1.00: (I; understood); )\\n'],\n",
       " 782: ['The preliminary results do not tell us yet if the highly complex graph-based differentiable memory has more learning or generalization capacity than other approaches.\\n',\n",
       "  '0.98: (The preliminary results; do not tell; us yet)\\n'],\n",
       " 783: ['The performance on the bAbI task is comparable to the best memory networks, but still worse than more traditional rule induction (see http://www.public.asu.edu/~cbaral/papers/aaai2016-sub.pdf).\\n',\n",
       "  '0.67: (The performance on the bAbI task; is still worse; comparable to the best memory networks, than more traditional rule induction)\\n'],\n",
       " 784: ['This is still clearly promising.\\n',\n",
       "  '1.00: (This; is; still clearly promising.)\\n'],\n",
       " 785: ['The sequence of transformation in algorithm 1 looks sensible, though the authors do not discuss any other operation ordering.\\n',\n",
       "  '1.00: (The sequence of transformation in algorithm 1; looks; sensible,)\\n'],\n",
       " 786: ['In particular, it is not clear to me that you need the node state update step T_h if you have the direct reference update step T_h,direct.\\n',\n",
       "  '0.96: (you; have; the direct reference update step T_h,direct.)\\n'],\n",
       " 787: [\"It is striking that the only trick that is essential for proper performance is the direct reference' , which actually has nothing to do with the graph building process, but is rather an attention mechanism for the graph input: attention is focused on words that are relevant to the node type rather than the whole sentence.\\n\",\n",
       "  '0.98: (the only trick; is; essential for proper performance)\\n'],\n",
       " 788: [\"So the question ''how useful are all these graph operations'' remain.\\n\",\n",
       "  \"0.98: (the question ''how useful; are; all these graph operations'')\\n\"],\n",
       " 789: ['A much simpler version of a similar trick may have been proposed in the context of memory networks, also for ICLR\\'17 (see match type in \"LEARNING END-TO-END GOAL-ORIENTED DIALOG\" by Bordes et al)\\n',\n",
       "  '1.00: (A much simpler version of a similar trick; may have been proposed; in the context of memory networks,)\\n'],\n",
       " 790: ['The authors also mention the time and size needed to train the model: is the issue arising for learning, inference or both?\\n',\n",
       "  '0.98: (the time and size; needed; to train the model:)\\n'],\n",
       " 791: ['A description of the actual implementation would help (no pointer to open source code is provide).\\n',\n",
       "  '0.90: (A description of the actual implementation; would help; pointer to open source code is provide).)\\n'],\n",
       " 792: ['The author mentions Theano in one of my questions: how are the transformations compiled in advance as units?\\n',\n",
       "  '0.98: (the transformations; compiled; in advance as units?)\\n'],\n",
       " 793: ['How is the gradient back-propagated through the graph is this one is only described at runtime?\\n',\n",
       "  '0.80: (How is the gradient back-propagated through the graph; is; one is at runtime?)\\n'],\n",
       " 794: [\"Typo: in the appendices B.2 and B.2.1, the right side of the equation that applies the update gate has h'_nu while it should be h_nu.\\n\",\n",
       "  '0.99: (the the equation; applies; the update gate)\\n'],\n",
       " 795: ['In the references, the author could mention the pioneering work of Lee Giles on representing graphs with RNNs.\\n',\n",
       "  '1.00: (the author; could mention; the pioneering work of Lee Giles on representing graphs with RNNs. In the references,)\\n'],\n",
       " 796: ['Revision: I have improved my rating for the following reasons:\\n',\n",
       "  '1.00: (I; have improved; my rating for the following reasons:)\\n'],\n",
       " 797: ['- Pointers to an highly readable and well structured Theano source is provided.\\n',\n",
       "  '0.94: (Pointers to an highly readable and well structured Theano source; is provided.; )\\n'],\n",
       " 798: ['- The delta improvement of the paper has been impressive over the review process, and I am confident this will be an impactful paper.\\n',\n",
       "  '0.00: (The delta improvement of the paper; has been; impressive over the review process,)\\n'],\n",
       " 799: ['- Much simpler alternatives approaches such as Memory Networks seem to be plateauing for problems such as dialog modeling, we need alternatives.\\n',\n",
       "  '1.00: (Much simpler alternatives approaches such as Memory Networks; to be plateauing; for problems such as dialog modeling,)\\n'],\n",
       " 800: ['- The architecture is this work is still too complex, but this is often as we start with DNNs, and then find simplifications that actually improve performance\\n',\n",
       "  '0.74: (The architecture; is; often performance)\\n'],\n",
       " 801: ['The main contribution of this paper seems to be an introduction of a set of differential graph transformations which will allow you to learn graph->graph classification tasks using gradient descent.\\n',\n",
       "  '1.00: (The main contribution of this paper; seems; )\\n'],\n",
       " 802: ['This maps naturally to a task of learning a cellular automaton represented as sequence of graphs.\\n',\n",
       "  '1.00: (This; maps naturally; to a task of learning a cellular automaton)\\n'],\n",
       " 803: ['In that task, the graph of nodes grows at each iteration, with nodes pointing to neighbors and special nodes 0/1 representing the values.\\n',\n",
       "  '1.00: (the graph of nodes; grows; at each iteration, In that task,)\\n'],\n",
       " 804: ['Proposed architecture allows one to learn this sequence of graphs, although in the experiment, this task (Rule 30) was far from solved.\\n',\n",
       "  '1.00: (this task; was; far from solved. in the experiment,)\\n'],\n",
       " 805: ['This idea is combined with ideas from previous papers (GGS-NN) to allow the model to produce textual output rather than graph output, and use graphs as intermediate representation, which allows it to beat state of the art on BaBi tasks.\\n',\n",
       "  '1.00: (This idea; is combined; with ideas from previous papers)\\n'],\n",
       " 806: ['The paper proposes an extension of the Gated Graph Sequence Neural Network by including in this model the ability to produce complex graph transformations.\\n',\n",
       "  '1.00: (The paper; proposes; an extension of the Gated Graph Sequence Neural Network)\\n'],\n",
       " 807: ['The underlying idea is to propose a method that will be able build/modify a graph-structure as an internal representation for solving a problem, and particularly for solving question-answering problems in this paper.\\n',\n",
       "  '1.00: (The underlying idea; is; to propose a method)\\n'],\n",
       " 808: ['The author proposes 5 different possible differentiable transformations that will be learned on a training set, typically in a supervised fashion where the state of the graph is given at each timestep.\\n',\n",
       "  '1.00: (The author; proposes; 5 different possible differentiable transformations that will be learned on a training set, typically in a supervised fashion)\\n'],\n",
       " 809: ['A particular occurence of the model is presented that takes a sequence as an input a iteratively update an internal graph state to a final prediction, and which can be applied for solving QA tasks (eg: BaBi) with interesting results.\\n',\n",
       "  '1.00: (A particular occurence of the model; is presented; )\\n'],\n",
       " 810: ['The approach in this paper is really interesting since the proposed model is able to maintain a representation of its current state as a complex graph, but still keeping the property of being differentiable and thus easily learnable through gradient-descent techniques.\\n',\n",
       "  '0.98: (The approach in this paper; is; really interesting since)\\n'],\n",
       " 811: ['It can be seen as a succesfull attempt to mix continuous and symbolic representations.\\n',\n",
       "  '1.00: (It; can be seen; as a succesfull attempt)\\n'],\n",
       " 812: [\"It moreover seems more general that the recent attempts made to add some 'symbolic' stuffs in differentiable models (Memory networks, NTM, etc...) since the shape of the state is not fixed here and can evolve.\\n\",\n",
       "  '0.77: (the shape of the state; can evolve.; )\\n'],\n",
       " 813: ['My main concerns is about the way the model is trained i.e by providing the state of the graph at each timestep which can be done for particular tasks (eg: Babi) only, and cannot be the solution for more complex problems.\\n',\n",
       "  '1.00: (My main concerns; is; about the way)\\n'],\n",
       " 814: ['My other concern is about the whole content of the paper that would perhaps best fit a journal format and not a conference format, making the article still difficult to read due to its density.\\n',\n",
       "  '1.00: (My other concern; is; about the whole content of the paper)\\n'],\n",
       " 815: ['The paper shows a different approach to a ternary quantization of weights.\\n',\n",
       "  '1.00: (The paper; shows; a different approach to a ternary quantization of weights.)\\n'],\n",
       " 816: ['Strengths:\\n',\n",
       "  '1)The paper shows performance improvements over existing solutions\\n'],\n",
       " 817: ['2)The idea of learning the quantization instead of using pre-defined human-made algorithm is nice and very much in the spirit of modern machine learning.\\n',\n",
       "  '0.98: (2)The idea of learning the quantization instead of using pre-defined human-made algorithm; is; nice and very much in the spirit of modern machine learning.)\\n'],\n",
       " 818: ['Weaknesses:\\n', '1)The paper is very incremental.\\n'],\n",
       " 819: ['2)The paper is addressed to a very narrow audience.\\n',\n",
       "  '1.00: (paper; is addressed; to a very narrow audience.)\\n'],\n",
       " 820: ['The paper very clearly assumes that the reader is familiar with the previous work on the ternary quantization.\\n',\n",
       "  '1.00: (The paper; very clearly assumes; that the reader is familiar with the previous work on the ternary quantization.)\\n'],\n",
       " 821: ['It is \"what is new in the topic\" update, not really a standalone paper.\\n',\n",
       "  '0.97: (It; is; \"what is new in the topic\" update, not really a standalone paper.)\\n'],\n",
       " 822: ['The description of the main algorithm is very concise, to say the least, and is probably clear to those who read some of the previous work on this narrow subject, but is unsuitable for a broader deep learning audience.\\n',\n",
       "  '0.93: (The description of the main algorithm; is; very concise, to say the least,)\\n'],\n",
       " 823: ['3)There is no convincing motivation for the work.\\n',\n",
       "  'What is presented is an engineering gimmick, that would be cool and valuable if it really is used in production, but is that really needed for anything?\\n'],\n",
       " 824: ['Are there any practical applications that require this refinement?\\n',\n",
       "  '1.00: (any practical applications; require; this refinement?)\\n'],\n",
       " 825: ['I do not find the motivation \"it is related to mobile, therefore it is cool\" sufficient.\\n',\n",
       "  '0.80: (I; do not find; the motivation \"it is related to mobile, therefore it is cool\" sufficient.)\\n'],\n",
       " 826: ['This paper is a small step further in a niche research, as long as the authors do not provide a sufficient practical motivation for pursuing this particular topic with the next step on a long list of small refinements, I do not think it belongs in ICLR with a broad and diversified audience.\\n',\n",
       "  '0.99: (the authors; do not provide; a sufficient practical motivation for pursuing this particular topic with the next step on a long list of small refinements,)\\n'],\n",
       " 827: ['Also - the code was not released is my understanding.\\n',\n",
       "  '1.00: (the code; was not released; )\\n'],\n",
       " 828: ['This paper presents new way for compressing CNN weights.\\n',\n",
       "  '1.00: (This paper; presents; new way for compressing CNN weights.)\\n'],\n",
       " 829: ['In particular this paper uses a new neural network quantization method that compresses network weights to ternary values.\\n',\n",
       "  '0.99: (this paper; uses; a new neural network quantization method that compresses network weights to ternary values. particular)\\n'],\n",
       " 830: ['The group has recently published multiple paper on this topic, and this one offers possibly the lowest returns I have seen.\\n',\n",
       "  '0.99: (The group; has published; multiple paper recently on this topic,)\\n'],\n",
       " 831: ['Only a fraction of percentage in ImageNet.\\n',\n",
       "  'Results on AlexNet are of very little interest now, given the group already showed this kind of older style-network can be compressed by large amounts.\\n'],\n",
       " 832: ['I also would have liked to see this group release code for the compression, and also report data on the amount of effort required to compress: flops, time, number of passes, required original dataset, etc.\\n',\n",
       "  '0.93: (I; would have liked; to see this group release code for the compression, and also report data on the amount of effort)\\n'],\n",
       " 833: ['This data is important to decide if a compression is worth the effort.\\n',\n",
       "  '1.00: (This data; is; important to decide if a compression is worth the effort.)\\n'],\n",
       " 834: ['This work presents a novel ternary weight quantization approach which quantizes weights to either 0 or one of two layer specific learned values.\\n',\n",
       "  '1.00: (This work; presents; a novel ternary weight quantization approach which quantizes weights to either 0 or one of two layer specific learned values.)\\n'],\n",
       " 835: ['Unlike past work, these quantized values are separate and learned stochastically alongside all other network parameters.\\n',\n",
       "  '0.94: (these quantized values; are; separate and learned stochastically alongside all other network parameters.)\\n'],\n",
       " 836: ['This approach achieves impressive quantization results while retaining or surpassing corresponding full-precision networks on CIFAR10 and ImageNet.\\n',\n",
       "  '1.00: (This approach; achieves; impressive quantization results while retaining or surpassing corresponding full-precision networks on CIFAR10 and ImageNet.)\\n'],\n",
       " 837: ['- Overall well written and algorithm is presented clearly.\\n',\n",
       "  '1.00: (Overall well written and algorithm; is presented clearly.; )\\n'],\n",
       " 838: ['- Approach appears to work well in the experiments, resulting in good compression without loss (and sometimes gain!)\\n',\n",
       "  '1.00: (Approach; appears; )\\n'],\n",
       " 839: ['of performance.\\n',\n",
       "  '- I enjoyed the analysis of sparsity (and how it changes) over the course of training, though it is uncertain if any useful conclusion can be drawn from it.\\n'],\n",
       " 840: ['Some points:\\n',\n",
       "  '- The energy analysis in Table 3 assumes dense activations due to the unpredictability of sparse activations.\\n'],\n",
       " 841: ['Can the authors provide average activation sparsity for each network to help verify this assumption.\\n',\n",
       "  '0.95: (each network; to; help verify this assumption.)\\n'],\n",
       " 842: ['Even if the assumption does not hold, relatively close values for average activation between the networks would make the comparison more convincing.\\n',\n",
       "  '0.95: (relatively close values for average activation between the networks; would make; the comparison more convincing.)\\n'],\n",
       " 843: ['- In section 5.1.1, the authors suggest having a fixed t (threshold parameter set at 0.05) for all layers allows for varying sparsity (owed to the relative magnitude of different layer weights with respect to the maximum).\\n',\n",
       "  '0.96: (parameter; set; at 0.05))\\n'],\n",
       " 844: ['In Section 5.1.2 paragraph 2, this is further developed by suggesting additional sparsity can be achieved by allowing each layer a different values of t. How are these values set?\\n',\n",
       "  '0.77: (this; is further developed; In Section 5.1.2 paragraph 2, by suggesting additional sparsity can be achieved)\\n'],\n",
       " 845: ['Does this multiple threshold style network appear in any of the tables or figures?\\n',\n",
       "  '1.00: (this multiple threshold style network; appear; in any of the tables or figures?)\\n'],\n",
       " 846: ['Can it be added?\\n', '0.93: (it; be; Can added?)\\n'],\n",
       " 847: ['- The authors claim \"ii) Quantized weights play the role of \"learning rate multipliers\" during back propagation.\"\\n',\n",
       "  '1.00: (The authors; claim; Quantized weights play the role of \"learning rate multipliers\" during back propagation.\")\\n'],\n",
       " 848: ['as a benefit of using trained quantization factors.\\n',\n",
       "  '0.88: (using; of; trained quantization factors.)\\n'],\n",
       " 849: ['Why is this a benefit?\\n',\n",
       "  '- Figure and table captions are not very descriptive.\\n'],\n",
       " 850: ['Preliminary Rating:\\n',\n",
       "  'I think this is an interesting paper with convincing results but is somewhat lacking in novelty.\\n'],\n",
       " 851: ['Minor notes:\\n', '1.00: (Minor; notes:; )\\n'],\n",
       " 852: ['- Table 3 lists FLOPS rather than Energy for the full precision model.\\n',\n",
       "  '0.98: (Table 3 lists; FLOPS; rather than Energy for the full precision model.)\\n'],\n",
       " 853: ['Why?\\n', \"- Section 5 'speeding up'\\n\"],\n",
       " 854: ['- 5.1.1 figure reference error last line\\n',\n",
       "  '0.90: (5.1.1; last; figure reference error line)\\n'],\n",
       " 855: ['This paper studies in depth the idea of quantizing down convolutional layers to 3 bits, with a different positive and negative per-layer scale.\\n',\n",
       "  '0.98: (This paper; studies; in depth the idea of quantizing down convolutional layers to 3 bits, with a different positive and negative per-layer scale.)\\n'],\n",
       " 856: ['It goes on to provide an exhaustive analysis of performance (essentially no loss) on real benchmarks (this paper is remarkably MNIST-free).\\n',\n",
       "  '0.99: (It; goes on; )\\n'],\n",
       " 857: [\"The relevance of this paper is that it likely provides a lower bound on quantization approaches that don't sacrifice any performance, and hence can plausibly become the approach of choice for resource-constrained inference, and might suggest new hardware designs to take advantage of the proposed structure.\\n\",\n",
       "  \"0.44: (The relevance of this paper; is; that it likely provides a lower bound on quantization approaches that don't sacrifice any performance, and hence can plausibly become the approach of choice for resource-constrained inference, and might suggest new hardware designs to take)\\n\"],\n",
       " 858: ['Furthermore, the paper provides power measurements, which is really the main metric that anyone working seriously in that space cares about.\\n',\n",
       "  '0.96: (the paper; provides; power measurements, which is really the main metric seriously)\\n'],\n",
       " 859: [\"(Nit: I don't see measurements for the full-precision baseline).\\n\",\n",
       "  \"0.93: (I; don't see; measurements for the full-precision baseline).)\\n\"],\n",
       " 860: ['I would have loved to see a SOTA result on ImageNet and a result on a strong LSTM baseline to be fully convinced.\\n',\n",
       "  '0.84: (a SOTA result on ImageNet and a result on a strong LSTM baseline; to be convinced.; fully)\\n'],\n",
       " 861: ['I would have also liked to see discussion of the wall time to result using this training procedure.\\n',\n",
       "  '0.82: (I; would have also liked; to see discussion of the wall time to result using this training procedure.)\\n'],\n",
       " 862: ['This paper creates a layered representation in order to better learn segmentation from unlabeled images.\\n',\n",
       "  '1.00: (This paper; creates; a layered representation in order)\\n'],\n",
       " 863: ['It is well motivated, as Figure 1 clearly shows the idea that if the segmentation was removed properly, the result would still be a natural image.\\n',\n",
       "  '0.96: (It; is motivated,; well)\\n'],\n",
       " 864: ['However, the method itself as described in the paper leaves many questions about whether they can achieve the proposed goal.\\n',\n",
       "  '0.98: (the method; as described; in the paper)\\n'],\n",
       " 865: ['I cannot see from the formulation why would this model work as it is advertised.\\n',\n",
       "  '0.83: (I it; cannot see is advertised.; from the formulation why would this model work)\\n'],\n",
       " 866: ['The formulation (3-4) looks like a standard GAN, with some twist about measuring the GAN loss in the z space (this has been used in eg: PPGN and CVAE-GAN).\\n',\n",
       "  '1.00: (The formulation; looks; like a standard GAN,)\\n'],\n",
       " 867: [\"I don't see any term that would guarantee:\\n\",\n",
       "  \"1.00: (I; don't see; any term that would guarantee:)\\n\"],\n",
       " 868: ['1) Each layer is a natural image.\\n',\n",
       "  '0.96: (1) Each layer; is; a natural image.)\\n'],\n",
       " 869: ['This was advertised in the paper, but the loss function is only on the final product G_K.\\n',\n",
       "  '1.00: (This; was advertised; in the paper,)\\n'],\n",
       " 870: ['The way it is written in the paper, the result of each layer does not need to go through a discriminator.\\n',\n",
       "  '1.00: (it; is written; in the paper,)\\n'],\n",
       " 871: ['Nothing seems to have been done to ensure that each layer outputs a natural image.\\n',\n",
       "  '1.00: (Nothing; seems; )\\n'],\n",
       " 872: ['2) None of the layers is degenerate.\\n',\n",
       "  '0.98: (2) None of the layers; is; degenerate.)\\n'],\n",
       " 873: ['There does not seem to be any constraint either regularizing the content in each layer, or preventing any layer to be non-degenerate.\\n',\n",
       "  '0.62: (any constraint either; regularizing; the content in each layer, any layer to be)\\n'],\n",
       " 874: ['3) The mask being contiguous.\\n',\n",
       "  '1.00: (The mask; being; contiguous.)\\n'],\n",
       " 875: [\"I don't see any term ensuring the mask being contiguous, I imagine normally without such terms doing such kinds of optimization would lead to a lot of fragmented small areas being considered as the mask.\\n\",\n",
       "  '0.86: (any term; ensuring; the mask contiguous,)\\n'],\n",
       " 876: ['The claim that this paper is for unsupervised semantic segmentation is overblown.\\n',\n",
       "  '1.00: (this paper; is; for unsupervised semantic segmentation)\\n'],\n",
       " 877: ['A major problem is that when conducting experiments, all the images seem to be taken from a single category, this implicitly uses the label information of the category.\\n',\n",
       "  '0.84: (all the images; to be taken; from a single category,)\\n'],\n",
       " 878: ['In that regard, this cannot be viewed as an unsupervised algorithm.\\n',\n",
       "  '1.00: (this; cannot be viewed; as an unsupervised algorithm. In that regard,)\\n'],\n",
       " 879: ['Even with that, the results definitely looked too good to be true.\\n',\n",
       "  '0.92: (the results; definitely looked; too good to be true. Even with that,)\\n'],\n",
       " 880: ['I have a really difficult time believing why such a standard GAN optimization would not generate any of the aforementioned artifacts and would perform exactly as the authors advertised.\\n',\n",
       "  '0.23: (such a standard GAN optimization; have would; a really difficult time believing why and perform exactly the authors advertised.)\\n'],\n",
       " 881: ['Even if it does work as advertised, the utilization of implicit labels would make it subject to comparisons with a lot of weakly-supervised learning papers with far better results than shown in this paper.\\n',\n",
       "  '0.98: (the utilization of implicit labels; would make; it subject to comparisons with a lot of weakly-supervised learning papers with far better results)\\n'],\n",
       " 882: ['Hence I am pretty sure that this is not up to the standards of ICLR.\\n',\n",
       "  '1.00: (I; am; pretty sure that this is not up to the standards of ICLR.)\\n'],\n",
       " 883: ['I have read the rebuttal and still not convinced.\\n',\n",
       "  '1.00: (I; have read; the rebuttal)\\n'],\n",
       " 884: [\"I don't think the authors managed to convince me that this method would work the way it's advertised.\\n\",\n",
       "  \"0.97: (I; don't think; the authors managed to convince me that this method would work the)\\n\"],\n",
       " 885: ['I also agree with Reviewer 2 that there is a lack of comparison against baselines.\\n',\n",
       "  '1.00: (I; agree; with Reviewer 2)\\n'],\n",
       " 886: ['Paper summary: The paper proposes a generative model that decomposes images into multiple layers.\\n',\n",
       "  '0.99: (The paper; proposes; a generative model that decomposes images into multiple layers.)\\n'],\n",
       " 887: ['The proposed approach is GAN-based, where the objective of the GAN is to distinguish real images from images formed by combining the layers.\\n',\n",
       "  '0.95: (The proposed approach; is; GAN-based, images)\\n'],\n",
       " 888: ['Some of the layers correspond to objects that are common in specific scene categories.\\n',\n",
       "  '1.00: (Some of the layers; correspond; to objects)\\n'],\n",
       " 889: ['The method has been tested on kitchen and bedroom scenes.\\n',\n",
       "  '1.00: (The method; has been tested; on kitchen and bedroom scenes.)\\n'],\n",
       " 890: ['Paper Strengths:\\n', '+ The idea of the paper is interesting.\\n'],\n",
       " 891: ['#ERROR!\\n', 'Paper Weaknesses:\\n'],\n",
       " 892: ['- The evaluation of the model is not great: (1) It would be interesting to combine bedroom and kitchen images and train jointly to see what it learns.\\n',\n",
       "  '0.50: (The evaluation of the model to; is not combine train jointly; great: images to see what it learns.)\\n'],\n",
       " 893: ['(2) It would be good to see how the performance changes for different number of layers.\\n',\n",
       "  '0.94: (It; would be; good to see how the performance changes for different number of layers.)\\n'],\n",
       " 894: ['(3) Regarding the fine-tuning baselines, the comparison is a bit unfair since the proposed method performs pooling over images, while the baseline (average mask) is not translation invariant.\\n',\n",
       "  '0.85: (the comparison; is; a bit unfair since the proposed method performs)\\n'],\n",
       " 895: ['- It is unclear why \"contiguous\" masks are generated (e.g., in figure 4).\\n',\n",
       "  '0.94: (It; is; unclear why \"contiguous\")\\n'],\n",
       " 896: ['Is there any constraint in the optimization?\\n',\n",
       "  'This should be explained in the rebuttal.\\n'],\n",
       " 897: ['- The method should not be called \"unsupervised\" since it knows the label for the scene category.\\n',\n",
       "  '0.99: (The method; should not be called; since)\\n'],\n",
       " 898: ['Also, it should not be called \"semantic segmentation\" since there is no semantics associated to the object.\\n',\n",
       "  '0.97: (it; should not be called; \"semantic segmentation\" no)\\n'],\n",
       " 899: ['It is just a binary foreground/background mask.\\n',\n",
       "  '1.00: (It; is; just a binary foreground/background mask.)\\n'],\n",
       " 900: ['- The plots in Figure 5 are a bit strange.\\n',\n",
       "  '1.00: (The plots in Figure 5; are; a bit strange.)\\n'],\n",
       " 901: ['The precision increases uniformly as the recall goes up, which is weird.\\n',\n",
       "  '0.97: (The precision; increases uniformly; as the recall goes up, which)\\n'],\n",
       " 902: ['It should be explained in the rebuttal why that happens.\\n',\n",
       "  '1.00: (It; should be explained; in the rebuttal)\\n'],\n",
       " 903: ['- Similar to most GAN-based models, the generated images are not that appealing.\\n',\n",
       "  '0.95: (the generated images; are not; that appealing. Similar to most GAN-based models,)\\n'],\n",
       " 904: ['- The claim about object removal should be toned down.\\n',\n",
       "  '1.00: (The claim about object removal; should be toned down.; )\\n'],\n",
       " 905: ['The method is not able to remove any object from a scene.\\n',\n",
       "  '1.00: (The method; is not; able to remove any object from a scene.)\\n'],\n",
       " 906: ['Only, the learned layers can be removed.\\n',\n",
       "  '0.99: (the learned layers; can be removed.; Only,)\\n'],\n",
       " 907: ['This paper proposes a neural network architecture around the idea of layered scene composition.\\n',\n",
       "  '1.00: (This paper; proposes; a neural network architecture around the idea of layered scene composition.)\\n'],\n",
       " 908: ['Training is cast in the generative adversarial framework; a subnetwork is reused to generate and compose (via an output mask) multiple image layers; the resulting image is fed to a discriminator.\\n',\n",
       "  '1.00: (a subnetwork; to generate; )\\n'],\n",
       " 909: ['An encoder is later trained to map real images into the space of latent codes for the generator, allowing the system to be applied to real image segmentation tasks.\\n',\n",
       "  '1.00: (An encoder; is trained; to map real images into the space of latent codes for the generator, later)\\n'],\n",
       " 910: ['The idea is interesting and different from established approaches to segmentation.\\n',\n",
       "  '1.00: (The idea; is; interesting and different from established approaches to segmentation.)\\n'],\n",
       " 911: ['Visualization of learned layers for several scene types (Figures 3, 7) shows that the network does learn a reasonable compositional scene model.\\n',\n",
       "  '1.00: (Visualization of learned layers for several scene types; shows; that the network does learn a reasonable compositional scene model.)\\n'],\n",
       " 912: ['Experiments evaluate the ability to port the model learned in an unsupervised manner to semantic segmentation tasks, using a limited amount of supervision for the end task.\\n',\n",
       "  '0.90: (Experiments; evaluate; the ability to port the model learned in an unsupervised manner to semantic segmentation tasks,)\\n'],\n",
       " 913: ['However, the included experiments are not nearly sufficient to establish the effectiveness of the proposed method.\\n',\n",
       "  '1.00: (the included experiments; are not; nearly sufficient to establish the effectiveness of the proposed method.)\\n'],\n",
       " 914: ['Only two scene types (bedroom, kitchen) and four object classes (bed, window, appliance, counter) are used for evaluation.\\n',\n",
       "  '0.05: (Only two scene types (bedroom, kitchen) and four object classes; are used; for evaluation.)\\n'],\n",
       " 915: ['This is far below the norm for semantic segmentation work in computer vision.\\n',\n",
       "  '1.00: (This; is; far below the norm for semantic segmentation work in computer vision.)\\n'],\n",
       " 916: ['How does the method work on established semantic segmentation datasets with many classes, such as PASCAL?\\n',\n",
       "  'Even the ADE20K dataset, from which this paper samples, is substantially larger and has an established benchmarking methodology (see http://placeschallenge.csail.mit.edu/).\\n'],\n",
       " 917: ['An additional problem is that performance is not compared to any external prior work.\\n',\n",
       "  '0.06: (An additional problem; is; that performance is not compared to any external prior work.)\\n'],\n",
       " 918: ['Only simple baselines (eg: autoencoder, kmeans) implemented by this paper are included.\\n',\n",
       "  '1.00: (Only simple baselines; implemented; by this paper)\\n'],\n",
       " 919: ['The range of prior work on semantic segmentation is extensive.\\n',\n",
       "  '1.00: (The range of prior work on semantic segmentation; is; extensive.)\\n'],\n",
       " 920: ['How well does the approach compare to supervised CNNs on an established segmentation task?\\n',\n",
       "  '0.80: (How the approach; compare supervised; to CNNs on an established segmentation task?)\\n'],\n",
       " 921: ['Note that the proposed method need not necessarily outperform supervised approaches, but the reader should be provided with some idea of the size of the gap between this unsupervised method and the state-of-the-art supervised approach.\\n',\n",
       "  '0.99: (the reader; should be provided; with some idea of the size of the gap between this unsupervised method and the state-of-the-art supervised approach.)\\n'],\n",
       " 922: ['In summary, the proposed method may be promising, but far more experiments are needed.\\n',\n",
       "  '0.99: (the proposed method; may be; promising, In summary,)\\n'],\n",
       " 923: [\"The system described works comparably to bi-directional LSTM baseline for NMT, and CNN's are naturally parallelizable.\\n\",\n",
       "  '0.88: (The system; described works comparably; to bi-directional LSTM baseline for)\\n'],\n",
       " 924: [\"Key ideas include the use of two stacked CNN's (one for each of encoding and decoding) for translation, with res connections and position embeddings.\\n\",\n",
       "  \"1.00: (Key ideas; include; the use of two stacked CNN's (one for each of encoding and decoding) for translation, with res connections and position embeddings.)\\n\"],\n",
       " 925: [\"The use of CNN's for translation has been attempted previously (as described by the authors), but presumably it is the authors' combination of various architectural choices (attention, position embeddings, etc) that make the present system competitive with RNN's, whereas earlier attempts were not.\\n\",\n",
       "  \"1.00: (The use of CNN's for translation; has been attempted; previously)\\n\"],\n",
       " 926: [\"They describe system's sensitivity to some of these choices (eg: experiments to choose appropriate number of layers in each of the CNN's).\\n\",\n",
       "  \"1.00: (They; describe; system's sensitivity to some of these choices)\\n\"],\n",
       " 927: ['The experimental results are well reported in detail.\\n',\n",
       "  '0.01: (The experimental results; are well reported; in detail.)\\n'],\n",
       " 928: ['One or two figures would definitely be required to help clarify the architecture.\\n',\n",
       "  '1.00: (One or two figures; would definitely be required; to help clarify the architecture.)\\n'],\n",
       " 929: ['This paper is less about new ways of learning representations than about the combination of choices made (over the set of existing techniques) in order to get the good results that they do on the reported NMT tasks.\\n',\n",
       "  '1.00: (This paper; is; less about new ways of learning representations than about the combination of choices)\\n'],\n",
       " 930: ['In this respect, while I am fairly confident that the paper represents good work in machine learning, I am not quite as confident about its fit for this particular conference.\\n',\n",
       "  '1.00: (I; am; fairly confident that the paper represents good work in machine learning,)\\n'],\n",
       " 931: ['This paper is the first (I believe) to establish a simple yet important result that Convnets for NMT encoders can be competitive to RNNs.\\n',\n",
       "  '0.92: (This paper; is; the first (I believe) to establish a simple yet important result encoders)\\n'],\n",
       " 932: ['The authors present a convincing set of results over many translation tasks and compare with very competitive baselines.\\n',\n",
       "  '1.00: (The authors; present; a convincing set of results over many translation tasks)\\n'],\n",
       " 933: ['I also appreciate the detailed report on training and generation speed.\\n',\n",
       "  '1.00: (I; appreciate; the detailed report on training and generation speed.)\\n'],\n",
       " 934: [\"I find it's very interesting when position embeddings turn out to be hugely important (beside residual connections); unfortunately, there is little analysis to shed more lights on this aspect and perhaps compare other ways of capturing positions (a wild guess might be to use embeddings that represent some form of relative positions).\\n\",\n",
       "  \"0.72: (it's position embeddings little analysis; turn to be; hugely important (beside residual connections);)\\n\"],\n",
       " 935: ['The only concern I have (similar to the other reviewer) is that this paper perhaps fits better in an NLP conference.\\n',\n",
       "  '0.98: (The only concern I; have; )\\n'],\n",
       " 936: [\"One minor comment: it's slight strange that this well-executed paper doesn't have a single figure on the proposed architecture :) It will also be even better to draw a figure for the biLSTM architecture as well (it does take some effort to understand the last paragraph in Section 2, especially the part on having a linear layer to compute z).\\n\",\n",
       "  \"0.98: (this well-executed paper; doesn't have; a single figure on the proposed architecture)\\n\"],\n",
       " 937: ['The paper reports a very clear and easy to understand result that a convolutional network can be used instead of the recurrent encoder for neural machine translation.\\n',\n",
       "  '1.00: (The paper; reports; a very clear and easy to understand result that a convolutional network can be used instead of the recurrent encoder for neural machine translation.)\\n'],\n",
       " 938: ['Apart from the known architectural elements, such as convolution, pooling, residual connections, position embeddings, the paper features one unexpected architectural twist: two stacks of convolutions, one for computing alignment and another for computing the representations.\\n',\n",
       "  '0.95: (the paper; features; one unexpected architectural twist: two stacks of convolutions, one for computing alignment and another for computing the representations.)\\n'],\n",
       " 939: ['The empirical evidence that this was necessary is provided, however the question of *why* it is necessary remains open.\\n',\n",
       "  '1.00: (this; was; necessary)\\n'],\n",
       " 940: ['The experimental evaluation is very extensive and leaves no doubt that the proposed approach works well.\\n',\n",
       "  '1.00: (The experimental evaluation; is; very extensive)\\n'],\n",
       " 941: ['The convnet-based model was faster at evaluation, but it is not very clear what is the main speed-up factor.\\n',\n",
       "  '1.00: (The convnet-based model; was; faster at evaluation,)\\n'],\n",
       " 942: [\"It's however hard to argue against the fact that the speed advantage of convnets is likely to increase if a more parallel implementation is considered.\\n\",\n",
       "  '0.99: (the speed advantage of convnets; is; likely to increase)\\n'],\n",
       " 943: ['My main concern is whether or not the paper is appropriate for ICLR, because the contribution is quite incremental and rather application-specific.\\n',\n",
       "  '0.99: (the contribution; is; quite incremental and rather application-specific.)\\n'],\n",
       " 944: ['ACL, EMNLP and other NLP conferences would be a better venue, I think.\\n',\n",
       "  '0.07: (ACL, EMNLP and other NLP conferences would be a better venue,; think.; I)\\n'],\n",
       " 945: ['In this paper, the authors propose a dynamic convolution model by exploiting the inter-scene similarity.\\n',\n",
       "  '1.00: (the authors; propose; a dynamic convolution model In this paper,)\\n'],\n",
       " 946: ['The computation cost is reduced significantly by reusing the feature map.\\n',\n",
       "  '1.00: (The computation cost; is reduced; significantly)\\n'],\n",
       " 947: ['In general, the paper is present clearly, but the technical contribution is rather incremental.\\n',\n",
       "  '0.99: (the paper; is clearly,; present)\\n'],\n",
       " 948: ['I have several concerns:\\n', '1.00: (I; have; several concerns:)\\n'],\n",
       " 949: ['1)The authors should further clarify their advantages over the popular framework of CNN+LSTM.\\n',\n",
       "  '1.00: (authors; should clarify; their advantages over the popular framework of CNN+LSTM.)\\n'],\n",
       " 950: ['Actually, I did not see it.\\n', '1.00: (I; did not see; it.)\\n'],\n",
       " 951: ['2) What is the difference between the proposed method and applying incremental learning on CNN?\\n',\n",
       "  '0.95: (2) What; is; the difference between the proposed method and applying incremental learning on CNN?)\\n'],\n",
       " 952: ['3)The proposed method reduced the computation in which phase, training or tesing?\\n',\n",
       "  '1.00: (proposed method; reduced; the computation in which phase, training or tesing?)\\n'],\n",
       " 953: ['4)The experimental section is rather weak.\\n',\n",
       "  '1.00: (experimental section; is; rather weak.)\\n'],\n",
       " 954: ['The authors should make more comprehensive evaluation on the larger dataset.\\n',\n",
       "  '1.00: (The authors; should make; more comprehensive evaluation on the larger dataset.)\\n'],\n",
       " 955: ['Currently, the authors only use some small dataset with short videos, which makes the acceleration unnecessary.\\n',\n",
       "  '0.88: (the authors; only use; some small dataset with short videos, which makes acceleration unnecessary. Currently,)\\n'],\n",
       " 956: ['Summary - This paper proposes a technique to reduce the compute cost when applying recognition models in surveillance models.\\n',\n",
       "  '1.00: (This paper; proposes; a technique to reduce the compute cost)\\n'],\n",
       " 957: ['The core idea is to analytically compute the pixels that changed across frames and only apply the convolution operation to those pixels.\\n',\n",
       "  '0.96: (The core idea; is; to analytically compute the pixels that changed across frames and only apply the convolution operation to those pixels.)\\n'],\n",
       " 958: ['The authors term this as dynamic convolution and evaluate this method on the SSD architecture across datasets like PETS, AVSS, VIRAT.\\n',\n",
       "  '1.00: (The authors; term; this as dynamic convolution)\\n'],\n",
       " 959: ['Paper strengths\\n',\n",
       "  '- The problem of reducing computational requirements when using CNNs for video analysis is well motivated.\\n'],\n",
       " 960: ['- The authors analyze a standard model on benchmark datasets which makes it easier to understand and place their results in context.\\n',\n",
       "  '1.00: (The authors; analyze; a standard model on benchmark datasets)\\n'],\n",
       " 961: ['Paper weaknesses\\n',\n",
       "  '- A simple baseline that only processes a frame if \\\\sum_{ij} D_{ij} exceeds a threshold is never mentioned or compared against.\\n'],\n",
       " 962: ['In general, the paper does not compare against any other existing work which reduces compute for video analysis, e.g., tracking.\\n',\n",
       "  '1.00: (the paper; does not compare; against any other existing work)\\n'],\n",
       " 963: ['This makes it harder to appreciate the contribution or practical benefit of using this method.\\n',\n",
       "  '1.00: (This; makes; it harder to appreciate the contribution or practical benefit of using this method.)\\n'],\n",
       " 964: ['- The paper has many spelling and grammar mistakes - \"siliarlity\", \"critiria\" etc.\\n',\n",
       "  '0.97: (The paper; has; many spelling and grammar mistakes - \"siliarlity\", \"critiria\" etc.)\\n'],\n",
       " 965: ['- Continuous convolutions - It is not clear to me what is meant by this term.\\n',\n",
       "  '0.93: (Continuous convolutions It; is not; clear to me what is meant by this term.)\\n'],\n",
       " 966: ['It is used many times and there is an entire section of results on it (Table 6), but without clearly understanding this concept, I cannot fully appreciate the results.\\n',\n",
       "  '1.00: (It; is used; many times)\\n'],\n",
       " 967: ['- Section 5.2 - what criteria or metric is used to compute scene similarity?\\n',\n",
       "  '0.96: (Section 5.2 - what criteria or metric; is used; to compute scene similarity?)\\n'],\n",
       " 968: ['- Overall, I think this paper can be substantially improved in terms of providing details on the proposed approach and comparing against baselines to demonstrate that Dynamic-Convolutions are helpful.\\n',\n",
       "  '1.00: (I; think; this paper can be substantially improved in terms of providing details on the proposed approach and comparing against baselines)\\n'],\n",
       " 969: ['- Design decisions such as cell-based convolution (Figure 3) are never evaluated empirically.\\n',\n",
       "  '1.00: (Design decisions such as cell-based convolution; are never evaluated empirically.; )\\n'],\n",
       " 970: ['The paper addresses the problem of computational inefficiency in video surveillance understanding approaches.\\n',\n",
       "  '1.00: (The paper; addresses; the problem of computational inefficiency in video surveillance understanding approaches.)\\n'],\n",
       " 971: ['It suggests an approach called Dynamic Convolution consists of Frame differencing, Prediction, and Dyn-Convolution steps.\\n',\n",
       "  '0.99: (an approach; called; Dynamic Convolution)\\n'],\n",
       " 972: ['The idea is to reuse some of the convolutional feature maps, and frame features particularly when there is a significant similarity among the frames.\\n',\n",
       "  '0.28: (The idea; is; to reuse some of the convolutional feature maps, and frame features particularly there is a significant similarity among the frames.)\\n'],\n",
       " 973: ['The paper evaluates the results on 4 public datasets.\\n',\n",
       "  '1.00: (The paper; evaluates; the results on 4 public datasets.)\\n'],\n",
       " 974: ['However, it just compares the approach to a baseline, which is indeed applying convnet on all frames.\\n',\n",
       "  '1.00: (it; just compares; the approach to a baseline,)\\n'],\n",
       " 975: ['- State of the art is not well-studied in the paper.\\n',\n",
       "  '0.98: (State of the art; is not; well-studied in the paper.)\\n'],\n",
       " 976: ['Video understanding approaches usually are not just applying convnet on all frames.\\n',\n",
       "  '0.99: (Video understanding approaches; are not just applying; convnet on all frames. usually)\\n'],\n",
       " 977: ['Many of the approaches on video analysis, select a random set of frames (or just a single frame) [5], and extract the features for them.\\n',\n",
       "  '0.99: (Many of the approaches on video analysis,; select; a random set of frames (or just a single frame))\\n'],\n",
       " 978: ['There is another set of work on attention, that try to extracts the most important spatio-temporal [1-4] information to solve a certain task.\\n',\n",
       "  '1.00: (another set of work on attention,; try; to extracts the most important spatio-temporal [1-4] information)\\n'],\n",
       " 979: ['These approaches are usually computationally less expensive than applying convnet on all video frames.\\n',\n",
       "  '0.99: (These approaches; are; usually computationally less expensive than applying convnet on all video frames.)\\n'],\n",
       " 980: ['I suggest the authors compare their model with these approaches. [1] Spatially Adaptive Computation Time for Residual Networks., Figurnov et al\\n',\n",
       "  '1.00: (I; suggest; the authors compare their model with these approaches.)\\n'],\n",
       " 981: ['[2] Recurrent Models of Visual Attention, Mnih et al\\n',\n",
       "  '0.95: (Recurrent Models of Visual Attention,; et al; Mnih)\\n'],\n",
       " 982: ['[3] Action recognition using visual attention, Sharma et al\\n',\n",
       "  '1.00: (Action recognition; using; visual attention,)\\n'],\n",
       " 983: ['[4] End-to-end learning of action detection from frame glimpses in videos, Yeung et al\\n',\n",
       "  '[5] Two-Stream Convolutional Networks for Action Recognition in Videos, Simonyan et al\\n'],\n",
       " 984: ['- In addition, car and pedestrian detection performance is part of the evaluation process.\\n',\n",
       "  '1.00: (car and pedestrian detection performance; is; part of the evaluation process.)\\n'],\n",
       " 985: ['In this case, the approach should be also compared to the state-of-the-art tracking approaches (that are cheaper to acquire) in terms of computational efficiency and performance.\\n',\n",
       "  '0.98: (the approach; should be also compared; to the state-of-the-art tracking approaches In this case,)\\n'],\n",
       " 986: ['- The writing of the paper should also improve to make the paper more understandable and easier to follow.\\n',\n",
       "  '0.87: (The writing of the paper; should also improve; to make the paper more understandable and easier to follow.)\\n'],\n",
       " 987: ['Some examples: 1.\\n', 'Unnecessary information can be summarized.\\n'],\n",
       " 988: [\"For example, many details on the computational costs in abstract and the introduction can just simply be replaced by stating that ''these approaches are computationally costly''.\\n\",\n",
       "  \"1.00: (many details on the computational costs in abstract and the introduction; can just simply be replaced; by stating that ''these approaches are computationally costly''.)\\n\"],\n",
       " 989: ['2\\n',\n",
       "  \"Using present tense for the SoTA approaches is more common.''ShuffleNet (Zhang et al (2017)) proposed two new strategies''.\\n\"],\n",
       " 990: ['3\\n',\n",
       "  \"Long sentences are difficult to follow: ''In real surveillance video application, although the calculation reduction on convolution is the main concern of speeding up the overall processing time, the data transfer is another important factor which contributes to the time''\\n\"],\n",
       " 991: ['+ The problem of large-scale video understanding is an important and interesting problem to tackle.\\n',\n",
       "  '1.00: (The problem of large-scale video understanding; is; an important and interesting problem to tackle.)\\n'],\n",
       " 992: ['In this paper, the authors associated with the generalization gap of robust adversarial training with the distance between the test point and the manifold of training data.\\n',\n",
       "  '1.00: (the authors; associated; with the generalization gap of robust adversarial training with the distance between the test point and the manifold of training data. In this paper,)\\n'],\n",
       " 993: [\"A so-called 'blind-spot attack' is proposed to show the weakness of robust adversarial training.\\n\",\n",
       "  \"1.00: (A so-called 'blind-spot attack'; is proposed; to show the weakness of robust adversarial training.)\\n\"],\n",
       " 994: ['Although the paper contains interesting ideas and empirical results, I have several concerns about the current version.\\n',\n",
       "  '1.00: (the paper; contains; interesting ideas and empirical results,)\\n'],\n",
       " 995: ['a) In the paper, the authors mentioned that \"This simple metric is non-parametric and we found that the results are not sensitive to the selection of k\".\\n',\n",
       "  '0.93: (the authors; mentioned; that \"This simple metric is non-parametric and we found that the results are not sensitive to the selection of k\". In the paper,)\\n'],\n",
       " 996: ['Can authors provide more details, e.g., empirical results, about it?\\n',\n",
       "  '0.96: (authors; provide; more details, e.g., empirical results, about it?)\\n'],\n",
       " 997: ['What is its rationale?\\n',\n",
       "  'b) In the paper, \"We find that these blind-spots are prevalent and can be easily found without resorting to complex\\n'],\n",
       " 998: ['generative models like in Song et al (2018).\\n',\n",
       "  '0.98: (generative models like in Song; et; al (2018).)\\n'],\n",
       " 999: ['For the MNIST dataset which Madry et al (2018) demonstrate the strongest defense results so far, we propose a simple transformation to find the blind-spots in this model.\"\\n',\n",
       "  '0.98: (the MNIST dataset; demonstrate; the strongest defense results so far,)\\n'],\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
